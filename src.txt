================================================================================
File: ./unit_test.py
--------------------------------------------------------------------------------
# %% [markdown]
# ### è¿™ä¸ª notebook ç”¨æ¥è¯»å–æ–‡ä»¶ï¼Œå¹¶æµ‹è¯•ä¸€äº›æ–¹æ³•

# %%
import os
import numpy as np


def get_all_py_files(root_dir: str) -> list:
    """
    è·å–æŒ‡å®šç›®å½•åŠå…¶å­ç›®å½•ä¸‹çš„æ‰€æœ‰ .py æ–‡ä»¶è·¯å¾„ã€‚

    Args:
        root_dir (str): èµ·å§‹ç›®å½•è·¯å¾„ã€‚

    Returns:
        list: åŒ…å«æ‰€æœ‰ .py æ–‡ä»¶å®Œæ•´è·¯å¾„çš„åˆ—è¡¨ã€‚
    """
    py_files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if file.endswith(".py"):
                py_files.append(os.path.join(dirpath, file))
    return py_files


def write_all_py_contents_to_output(
    py_files: list, output_path: str = "src.txt"
) -> None:
    """
    å°†æ‰€æœ‰ .py æ–‡ä»¶çš„å†…å®¹å†™å…¥ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ä¸­ï¼Œå¹¶æ‰“å°æ–‡ä»¶åä½œä¸ºåˆ†éš”ã€‚

    Args:
        py_files (list): .py æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
        output_path (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
    """
    with open(output_path, "w", encoding="utf-8") as out_file:
        for path in py_files:
            out_file.write(f"{'=' * 80}\n")
            out_file.write(f"File: {path}\n")
            out_file.write(f"{'-' * 80}\n")
            try:
                with open(path, "r", encoding="utf-8") as f:
                    out_file.write(f.read())
            except Exception as e:
                out_file.write(f"âš ï¸ Error reading {path}: {e}\n")
            out_file.write("\n\n")


if True:
    root_directory = "."  # å½“å‰ç›®å½•
    all_py_files = get_all_py_files(root_directory)
    write_all_py_contents_to_output(all_py_files)
    print(f"ğŸ“„ æ‰€æœ‰ Python æ–‡ä»¶å†…å®¹å·²å†™å…¥ src.txtï¼ˆå…± {len(all_py_files)} ä¸ªæ–‡ä»¶ï¼‰")


# %%
import importlib
from utility import set_random_seed


def reload_components():
    """
    é‡æ–°åŠ è½½ä»¥ä¸‹æ¨¡å—ï¼Œä»¥ä¾¿åœ¨å¼€å‘è¿‡ç¨‹ä¸­å³æ—¶ç”Ÿæ•ˆï¼š
      - data.load_market_data
      - tokenizer.AlphaTokenizer
      - combination.AlphaCombinationModel
      - envs.AlphaGenerationEnv
      - generator.RLAlphaGenerator
    """
    import data, tokenizer, combination, alpha_generation_env, generator

    importlib.reload(data)
    importlib.reload(tokenizer)
    importlib.reload(combination)
    importlib.reload(alpha_generation_env)
    importlib.reload(generator)

    # é‡æ–°ç»‘å®šåˆ°æœ¬åœ°åç§°ï¼ˆå¯é€‰ï¼‰
    from data import load_market_data
    from tokenizer import AlphaTokenizer
    from combination import AlphaCombinationModel
    from alpha_generation_env import AlphaGenerationEnv
    from generator import RLAlphaGenerator

    return {
        "load_market_data": load_market_data,
        "AlphaTokenizer": AlphaTokenizer,
        "AlphaCombinationModel": AlphaCombinationModel,
        "AlphaGenerationEnv": AlphaGenerationEnv,
        "RLAlphaGenerator": RLAlphaGenerator,
    }


components = reload_components()


# %% [markdown]
# ### 1.æµ‹è¯• AlphaCombinationModel._compute_alpha_from_expr

# %%
from combination import AlphaCombinationModel
from data import load_market_data

df = load_market_data()
model = AlphaCombinationModel()
model.inject_data(df, target_col="target")

# è¡¨è¾¾å¼ï¼šclose çš„ 100 ç§’å‡å€¼
expr = "close 100 ts_mean"
alpha = model._compute_alpha_from_expr(expr)

print("alpha shape:", alpha.shape)
print("alpha sample:", alpha[~np.isnan(alpha)][:5])


# %% [markdown]
# ###  2. æµ‹è¯• AlphaCombinationModel.add_alpha_expr

# %%
ic = model.add_alpha_expr("high low sub 100 ts_max")
print("è¯¥å› å­çš„ IC ä¸ºï¼š", ic)
print("å½“å‰æ± ä¸­å› å­æ•°ï¼š", len(model.alphas))


# %% [markdown]
# ### 3. æµ‹è¯• AlphaTokenizer.encode / decode

# %%
from tokenizer import AlphaTokenizer

tokenizer = AlphaTokenizer()

expr = "close 5 ts_mean"
ids = tokenizer.encode(expr)
decoded = tokenizer.decode(ids)

print("Token IDs:", ids)
print("Decoded expr:", decoded)


# %% [markdown]
# ### 4. æµ‹è¯• AlphaGenerationEnv.reset / step

# %%
from alpha_generation_env import AlphaGenerationEnv
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from data import load_market_data

df = load_market_data()
combo = AlphaCombinationModel()
combo.inject_data(df, target_col="target")
tokenizer = AlphaTokenizer()
env = AlphaGenerationEnv(combo, tokenizer)

obs = env.reset()
print("åˆå§‹çŠ¶æ€ token IDs:", obs)

valid = env.valid_actions()
action = valid[1]
obs2, reward, done, info = env.step(action)
print("æ–°çŠ¶æ€:", obs2)
print("Reward:", reward, "Done:", done)


# %% [markdown]
# ### 5. æµ‹è¯• PolicyNetwork / ValueNetwork è¾“å‡ºç»´åº¦

# %%
import torch
from generator import PolicyNetwork, ValueNetwork

vocab_size = 50
seq_len = 6
hidden_dim = 64
device = "cpu"

x = torch.randint(0, vocab_size, (1, seq_len))  # batch_size=1
policy = PolicyNetwork(vocab_size, hidden_dim).to(device)
value = ValueNetwork(vocab_size, hidden_dim).to(device)

h0_p = policy.init_hidden(1, device)
logits, _ = policy(x, h0_p)
print("Policy logits shape:", logits.shape)  # åº”ä¸º (1, vocab_size)

h0_v = value.init_hidden(1, device)
v, _ = value(x, h0_v)
print("Value estimate shape:", v.shape)  # åº”ä¸º (1,)


# %% [markdown]
# ### 6. æµ‹è¯• RLAlphaGenerator._collect_trajectories

# %%
from generator import RLAlphaGenerator
from alpha_generation_env import AlphaGenerationEnv
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from data import load_market_data
from utility import set_random_seed

# reload_components()

set_random_seed(10)

df = load_market_data()
combo = AlphaCombinationModel()
combo.inject_data(df, "target")
tokenizer = AlphaTokenizer()
env = AlphaGenerationEnv(combo, tokenizer, max_len=20)

cfg = dict(
    vocab_size=tokenizer.vocab_size,
    hidden_dim=64,
    batch_size=1280,
    device="cpu",
)

agent = RLAlphaGenerator(env, cfg)

s, a, logp, ret, adv = agent._collect_trajectories()
print("Sample states shape:", s.shape)
print("Sample actions shape:", a.shape)
print("Sample rewards (returns):", ret.shape, ret)


# %%


================================================================================
File: ./alpha_generation_env.py
--------------------------------------------------------------------------------
# alpha_generation_env.py
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from typing import List
from operators import FUNC_MAP


class AlphaGenerationEnv:
    """
    è‡ªå®šä¹‰å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼šç”Ÿæˆé€†æ³¢å…°è¡¨è¾¾å¼ï¼ˆRPNï¼‰çš„åºåˆ—å†³ç­–è¿‡ç¨‹ã€‚

    - **çŠ¶æ€**ï¼šå½“å‰å·²ç”Ÿæˆçš„ token ID åˆ—è¡¨
    - **åŠ¨ä½œ**ï¼šä¸‹ä¸€ä¸ª token çš„ ID
    - **å¥–åŠ±**ï¼šç»„åˆæ¨¡å‹è¯„ä¼°çš„å•å› å­ IC
    - **ç»ˆæ­¢æ¡ä»¶**ï¼šç”Ÿæˆ `[SEP]` æˆ–è¾¾åˆ° `max_len`
    """

    def __init__(
        self, combo_model: AlphaCombinationModel, tokenizer: AlphaTokenizer, max_len=20
    ):
        """
        åˆå§‹åŒ–ç¯å¢ƒã€‚

        å‚æ•°
        ----------
        combo_model : AlphaCombinationModel
            è´Ÿè´£å› å­æ± ç®¡ç†ä¸ IC è®¡ç®—çš„ç»„åˆæ¨¡å‹ã€‚
        tokenizer : AlphaTokenizer
            RPN â†” token åºåˆ—è½¬æ¢å™¨ã€‚
        max_len : int, å¯é€‰
            ç”Ÿæˆåºåˆ—çš„æœ€â¼¤é•¿åº¦ï¼ˆå« `[BOS]` ä¸ `[SEP]`ï¼‰ï¼Œé»˜è®¤ 20ã€‚
        """
        self.combo_model = combo_model
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.reset()

    def reset(self):
        """
        é‡æ–°å¼€å§‹ä¸€æ¡æ–°åºåˆ—ã€‚

        è¿”å›
        ----------
        List[int]
            ä»…åŒ…å« `[BOS]` çš„åˆå§‹åºåˆ—ã€‚
        """
        self.sequence: List[int] = [self.tokenizer.bos_token_id]
        self.done: bool = False
        self._stack_types: List[str] = []
        return self._get_obs()

    def step(self, action: int):
        """
        æ‰§è¡Œä¸€æ­¥ç”Ÿæˆå¹¶è¿”å›ç¯å¢ƒè½¬ç§»ç»“æœã€‚

        å‚æ•°
        ----------
        action : int
            é€‰å®šçš„ token IDã€‚

        è¿”å›
        ----------
        obs : List[int]
            æ–°çš„ token åºåˆ—ã€‚
        reward : float
            è‹¥å·²ç»“æŸåˆ™ä¸ºè¯¥è¡¨è¾¾å¼çš„å•å› å­ ICï¼Œå¦åˆ™ä¸º 0ã€‚
        done : bool
            æ˜¯å¦åˆ°è¾¾ç»ˆæ­¢çŠ¶æ€ã€‚
        info : dict
            é¢„ç•™è°ƒè¯•ä¿¡æ¯ï¼Œå½“å‰ä¸ºç©ºå­—å…¸ã€‚
        """

        # â€”â€” è®°å½•å‰ä¸€æ—¶åˆ»çš„ info â€”â€”
        info = {
            "prev_stack_types": self._stack_types.copy(),
            "prev_depth": len(self._stack_types),
            "prev_valid_actions": self.valid_actions(),
            "action_id": action,
            "action_token": self.tokenizer.id_to_token[action],
        }

        # â€”â€” æ‰§è¡ŒåŠ¨ä½œï¼šæ›´æ–° sequence & stack_types â€”â€”
        self.sequence.append(action)
        tok = info["action_token"]
        if tok in self.tokenizer.operand_type_map:
            self._stack_types.append(self.tokenizer.operand_type_map[tok])
        elif tok in FUNC_MAP:
            _, arity, _ = FUNC_MAP[tok]
            for _ in range(arity):
                self._stack_types.pop()
            self._stack_types.append("Series")
        else:
            pass

        # â€”â€” å†è¡¥å……ä¾èµ–äºâ€œåâ€çŠ¶æ€çš„ info â€”â€”
        info.update(
            {
                "new_stack_types": self._stack_types.copy(),
                "new_depth": len(self._stack_types),
                "remaining": self.max_len - len(self.sequence),
            }
        )

        # â€”â€” è®¡ç®— reward & done â€”â€”
        reward = 0.0
        if action == self.tokenizer.sep_token_id or len(self.sequence) >= self.max_len:
            expr = self.tokenizer.decode(self.sequence, remove_special_tokens=True)
            try:
                reward = self.combo_model.evaluate_alpha(expr)
            except ValueError as e:
                reward = -1.0
                info["error"] = str(e)
            self.done = True

        obs = self._get_obs()
        return obs, reward, self.done, info

    def _get_obs(self):
        """
        è·å–å½“å‰è§‚æµ‹å€¼ï¼ˆtoken åºåˆ—ï¼‰ã€‚

        è¿”å›
        ----------
        List[int]
            å½“å‰ç”Ÿæˆåºåˆ—ï¼ˆå« `[BOS]`ï¼Œå¯èƒ½å« `[SEP]`ï¼‰ã€‚
        """
        return self.sequence

    def valid_actions(self) -> List[int]:
        """
        è·å–å½“å‰çŠ¶æ€ä¸‹æ‰€æœ‰åˆæ³•åŠ¨ä½œçš„ token IDã€‚

        æ ¹æ®å½“å‰è¡¨è¾¾å¼çš„æ ˆçŠ¶æ€ä¸å‰©ä½™æ­¥æ•°ï¼Œç­›é€‰å‡ºèƒ½å¤Ÿæ„æˆ
        åˆæ³•é€†æ³¢å…°è¡¨è¾¾å¼çš„ä¸‹ä¸€ä¸ª tokenã€‚

        åŒ…å«å¦‚ä¸‹åˆæ³•æ€§æ£€æŸ¥ï¼š
        - æ ˆæ·±æ˜¯å¦æ»¡è¶³æ“ä½œç¬¦çš„å‚æ•°éœ€æ±‚ï¼›
        - æ ˆé¡¶å‚æ•°ç±»å‹æ˜¯å¦ä¸æ“ä½œç¬¦å®šä¹‰åŒ¹é…ï¼›
        - å‰©ä½™æ­¥æ•°æ˜¯å¦è¶³å¤Ÿå®Œæˆè¡¨è¾¾å¼é—­åˆï¼›
        - å¯¹äºæ“ä½œæ•°ï¼Œä¿è¯ä¸ä¼šè¶…å‡ºæœ€å¤§é•¿åº¦é™åˆ¶ã€‚

        è¿”å›
        ----------
        List[int]
            æ‰€æœ‰åˆæ³• token çš„ ID åˆ—è¡¨ã€‚
        """
        depth = len(self._stack_types)
        remaining = self.max_len - len(self.sequence)

        if remaining == 1:
            return [self.tokenizer.sep_token_id] if depth == 1 else []

        valid = []
        
        if depth == 1:
            valid.append(self.tokenizer.sep_token_id)

        for tok_id, tok in self.tokenizer.id_to_token.items():
            if tok in ("[PAD]", "[BOS]", "[SEP]"):
                continue

            # æ—¶é—´åºåˆ—ç®—å­å‰ï¼Œåªæœ‰æ•´å‹å¸¸é‡æ‰åˆæ³•
            if tok in FUNC_MAP and tok.startswith("ts_"):
                last_tok = self.tokenizer.id_to_token[self.sequence[-1]]
                last_type = self.tokenizer.operand_type_map.get(last_tok)
                if last_type != "Scalar_INT":
                    continue
                if last_tok == "CONST_1":
                    continue
                if tok == "ts_kurt" and last_tok == "CONST_3":
                    continue

            if tok in FUNC_MAP:
                fn, arity, param_types = FUNC_MAP[tok]
                if depth < arity:
                    continue
                if not all(
                    _type_compatible(g, r)
                    for g, r in zip(self._stack_types[-arity:], param_types)
                ):
                    continue
                if depth - arity + 1 >= remaining:
                    continue
                valid.append(tok_id)
            else:
                # å¸¸é‡ä¸èƒ½è¿ç€å¸¸é‡
                if depth > 0 \
                and self.tokenizer.operand_type_map[tok].startswith("Scalar") \
                and self._stack_types[-1].startswith("Scalar"):
                    continue
                if depth + 1 < remaining:
                    valid.append(tok_id)
        return valid


def _type_compatible(given: str, required: str) -> bool:
    if given == required:
        return True
    if required == "Any":
        return True
    if given == "Scalar_INT" and required == "Scalar_FLOAT":
        return True
    return False


================================================================================
File: ./utility.py
--------------------------------------------------------------------------------
# utility.py
import numpy as np
import pandas as pd
import os
import random
import torch


def zscore_normalize(alpha: np.ndarray) -> pd.Series:
    """
    å¯¹å› å­åºåˆ—è¿›è¡ŒZ-scoreæ ‡å‡†åŒ–ã€‚

    è¯¥å‡½æ•°å¯¹è¾“å…¥æ•°ç»„è¿›è¡Œå»å‡å€¼é™¤ä»¥æ ‡å‡†å·®å¤„ç†ï¼Œ
    å¹¶å°†ç»“æœé™åˆ¶ä¸ºæœ‰é™å€¼ï¼Œæ‰€æœ‰NaNæˆ–æ— ç©·å€¼æ›¿æ¢ä¸º0ã€‚

    Args:
        alpha (np.ndarray): åŸå§‹å› å­å€¼æ•°ç»„ï¼Œdtypeå¯åŒ…å«NaNã€‚

    Returns:
        pd.Series: æ ‡å‡†åŒ–åçš„åºåˆ—ï¼Œé•¿åº¦ä¸è¾“å…¥ç›¸åŒï¼Œæ— NaNã€‚
    """
    a = np.asarray(alpha, dtype=np.float64)
    mean = np.nanmean(a)
    std = np.nanstd(a)
    if std == 0 or np.isnan(std):
        return pd.Series(np.zeros_like(a))
    with np.errstate(invalid="ignore", divide="ignore"):
        z = (a - mean) / std
    z = np.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)
    return pd.Series(z)


def winsorize(
    alpha: np.ndarray, lower_quantile: float = 0.01, upper_quantile: float = 0.99
) -> pd.Series:
    """
    å¯¹å› å­åºåˆ—è¿›è¡Œæˆªå°¾å¤„ç†ï¼Œé™åˆ¶æç«¯å€¼ã€‚

    ä½¿ç”¨æŒ‡å®šä¸Šä¸‹åˆ†ä½æ•°è®¡ç®—é˜ˆå€¼ï¼Œå¹¶å°†è¶…å‡ºèŒƒå›´çš„å€¼è£å‰ªåˆ°è¾¹ç•Œï¼Œ
    æ‰€æœ‰NaNæˆ–æ— ç©·å€¼æ›¿æ¢ä¸ºå¯¹åº”è¾¹ç•Œå€¼ã€‚

    Args:
        alpha (np.ndarray): åŸå§‹å› å­å€¼æ•°ç»„ã€‚
        lower_quantile (float): ä¸‹åˆ†ä½ç‚¹ï¼Œé»˜è®¤0.01ã€‚
        upper_quantile (float): ä¸Šåˆ†ä½ç‚¹ï¼Œé»˜è®¤0.99ã€‚

    Returns:
        pd.Series: æˆªå°¾åçš„åºåˆ—ï¼Œé•¿åº¦ä¸è¾“å…¥ç›¸åŒï¼Œæ— NaNã€‚
    """
    a = np.asarray(alpha, dtype=float)
    with np.errstate(invalid="ignore", over="ignore"):
        lower = np.nanpercentile(a, lower_quantile * 100)
        upper = np.nanpercentile(a, upper_quantile * 100)
        clipped = np.clip(a, lower, upper)
    clipped = np.nan_to_num(clipped, nan=lower, posinf=upper, neginf=lower)
    return pd.Series(clipped)


def information_coefficient(factor: np.ndarray, target: np.ndarray) -> float:
    """
    è®¡ç®—å› å­ä¸ç›®æ ‡çš„Pearsonç›¸å…³ç³»æ•°ï¼ˆä¿¡æ¯ç³»æ•°ï¼‰ã€‚

    è‹¥è¾“å…¥é•¿åº¦ä¸åŒ¹é…æˆ–æœ‰æ•ˆæ ·æœ¬å°‘äº2ï¼Œè¿”å›0ï¼›
    è‹¥ä»»æ„æ–¹å·®ä¸º0ï¼Œè¿”å›0ã€‚

    Args:
        factor (np.ndarray): å› å­å€¼æ•°ç»„ã€‚
        target (np.ndarray): ç›®æ ‡å€¼æ•°ç»„ï¼ˆæœªæ¥æ”¶ç›Šï¼‰ã€‚

    Returns:
        float: Pearsonç›¸å…³ç³»æ•°ï¼ŒèŒƒå›´[-1,1]ï¼Œæˆ–0è¡¨ç¤ºæ— æ•ˆã€‚
    """
    if len(factor) != len(target):
        raise ValueError("Factor and target length mismatch")
    mask = np.isfinite(factor) & np.isfinite(target)
    if mask.sum() < 2:
        return 0.0
    f, t = factor[mask], target[mask]
    if np.std(f) == 0 or np.std(t) == 0:
        return 0.0
    return float(np.corrcoef(f, t)[0, 1])


def set_random_seed(seed: int = 42):
    """
    å›ºå®šå…¨å±€éšæœºæ•°ç§å­ï¼Œç¡®ä¿å®éªŒå¯å¤ç°ã€‚

    Args:
        seed (int): éšæœºæ•°ç§å­ï¼Œé»˜è®¤42ã€‚
    """
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


================================================================================
File: ./__init__.py
--------------------------------------------------------------------------------


================================================================================
File: ./combination.py
--------------------------------------------------------------------------------
# combination.py
import numpy as np
from utility import zscore_normalize, winsorize, information_coefficient
from scipy.optimize import minimize
from typing import List, Dict, Union, Tuple, Callable
import operators
import pandas as pd

class AlphaCombinationModel:
    """
    å› å­çº¿æ€§ç»„åˆç®¡ç†å™¨ï¼Œå®ç°è®ºæ–‡ä¸­ç®—æ³•1çš„æ ¸å¿ƒæ€æƒ³ã€‚

    åŠŸèƒ½:
      - ç»´æŠ¤ä¸€ä¸ªæœ€å¤šåŒ…å« `max_pool_size` æ¡å½’ä¸€åŒ–å› å­åºåˆ—çš„å› å­æ± ã€‚
      - æ¯å½“æœ‰æ–°å› å­ç”Ÿæˆæ—¶ï¼Œæ‰§è¡Œæˆªå°¾ï¼ˆWinsorizeï¼‰å’Œ Z-score æ ‡å‡†åŒ–ï¼Œå¹¶è®¡ç®—è¯¥å› å­çš„å•å› å­ ICï¼ˆInformation Coefficientï¼‰ã€‚
      - å°†æ–°å› å­åŠ å…¥å› å­æ± åï¼Œé€šè¿‡å‡¸ä¼˜åŒ–ï¼ˆSLSQPï¼‰æ±‚è§£æœ€ä¼˜çº¿æ€§æƒé‡ï¼Œä»¥æœ€å¤§åŒ–ç»„åˆ ICã€‚
      - è‹¥å› å­æ± è¶…è¿‡ä¸Šé™ï¼Œåˆ™å‰”é™¤å¯¹ç»„åˆè´¡çŒ®åº¦æœ€å°çš„å› å­ã€‚
      - åœ¨å¤šæ¬¡è®¡ç®—ä¸­å¯¹æ ‡å‡†åŒ–åºåˆ—ã€IC å€¼ã€æœ€ä¼˜æƒé‡ç­‰ä¸­é—´ç»“æœè¿›è¡Œç¼“å­˜ï¼Œä»¥å‡å°‘é‡å¤å¼€é”€ã€‚

    Attributes:
        max_pool_size (int): å› å­æ± æœ€å¤§å®¹é‡ã€‚è¶…è¿‡åå°†åˆ é™¤è´¡çŒ®æœ€å°çš„å› å­ã€‚
        alphas (List[np.ndarray]): åŸå§‹å› å­åºåˆ—åˆ—è¡¨ã€‚
        norm_alphas (List[np.ndarray]): å½’ä¸€åŒ–åçš„å› å­åºåˆ—åˆ—è¡¨ã€‚
        ic_list (List[float]): å¯¹åº”æ¯æ¡å› å­çš„å•å› å­ IC åˆ—è¡¨ã€‚
        weights (List[float]): å½“å‰ç»„åˆä¸­å„å› å­çš„çº¿æ€§æƒé‡ã€‚
        expr_list (List[str]): ä¿å­˜æ¯æ¡å› å­å¯¹åº”çš„ RPN è¡¨è¾¾å¼ã€‚
        _cache (Dict): ç¼“å­˜ç”¨äºå­˜å‚¨ä¸­é—´è®¡ç®—ç»“æœã€‚
        data (pd.DataFrame): æ³¨å…¥çš„è¡Œæƒ…æ•°æ®ã€‚
        _target (np.ndarray): æ³¨å…¥çš„ç›®æ ‡åˆ—ï¼ˆæœªæ¥æ”¶ç›Šï¼‰æ•°ç»„ã€‚
    """
    def __init__(self, max_pool_size: int = 50):
        """
        åˆå§‹åŒ– AlphaCombinationModelã€‚

        Args:
            max_pool_size (int): å› å­æ± çš„æœ€å¤§å®¹é‡ï¼Œä¸Šé™å†…ä¼˜å…ˆä¿ç•™è´¡çŒ®åº¦é«˜çš„å› å­ã€‚
        """
        self.max_pool_size = max_pool_size
        self.alphas = []         # åŸå§‹å› å­åºåˆ—åˆ—è¡¨
        self.norm_alphas = []    # å½’ä¸€åŒ–åçš„å› å­åºåˆ—åˆ—è¡¨
        self.ic_list = []        # å¯¹åº”çš„å•å› å­ IC å€¼åˆ—è¡¨
        self.weights = []        # å½“å‰ç»„åˆçš„çº¿æ€§æƒé‡åˆ—è¡¨
        self._cache = {}         # ç¼“å­˜å­—å…¸ï¼Œç”¨äºå­˜å‚¨ä¸­é—´ç»“æœ
        self.expr_list = []      # æ–°å¢ï¼šå¯¹åº”æ¯æ¡å› å­çš„ RPN è¡¨è¾¾å¼å­—ç¬¦ä¸²

    def inject_data(self, df: pd.DataFrame, target_col: str) -> None:
        """
        æ³¨å…¥å¸‚åœºè¡Œæƒ…æ•°æ®å’Œç›®æ ‡åºåˆ—ï¼Œç”¨äº IC è®¡ç®—ä¸æƒé‡ä¼˜åŒ–ã€‚

        Args:
            df (pd.DataFrame): è¡Œæƒ…ç‰¹å¾è¡¨ï¼ŒåŒ…å«åŸºç¡€å­—æ®µå’Œç›®æ ‡åˆ—ã€‚
            target_col (str): DataFrame ä¸­ä»£è¡¨æœªæ¥æ”¶ç›Šçš„åˆ—åï¼Œç”¨äº IC è®¡ç®—ã€‚

        Raises:
            ValueError: å½“ target_col ä¸åœ¨ df åˆ—æ—¶æŠ›å‡ºã€‚
        """
        # TODO: éœ€è¦æ›´ç»†è‡´çš„è®­ç»ƒé›† / éªŒè¯é›† åˆ†å‰²é€»è¾‘ï¼Œæ·»åŠ æ–°çš„æ•°æ®é›†ä½œä¸ºéªŒè¯é›† etc
        self.data: pd.DataFrame = df
        self._target = df[target_col].values.astype(np.float64)

    def update_with(self, new_alpha: np.ndarray, expr: str):
        """
        å°†æ–°å› å­åŠ å…¥æ± ä¸­å¹¶æ›´æ–°ç»„åˆï¼š
          1. å¯¹åŸå§‹å› å­åºåˆ—åš winsorize å’Œ z-score æ ‡å‡†åŒ–ã€‚
          2. è®¡ç®—å¹¶ç¼“å­˜è¯¥å› å­çš„ ICã€‚
          3. æ·»åŠ è‡³å› å­æ± åï¼Œé‡ä¼˜åŒ–çº¿æ€§æƒé‡ã€‚
          4. è¶…å‡ºå®¹é‡æ—¶å‰”é™¤è´¡çŒ®æœ€å°çš„å› å­ã€‚

        Args:
            new_alpha (np.ndarray): æ–°å› å­çš„åŸå§‹åºåˆ—æ•°æ®ï¼Œé•¿åº¦ä¸æ³¨å…¥çš„è¡Œæƒ…ä¸€è‡´ã€‚
            expr (str): ç”Ÿæˆè¯¥å› å­çš„ RPN è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œç”¨äºè®°å½•åŠç¼“å­˜é”®ã€‚
        """
        norm = winsorize(zscore_normalize(new_alpha))
        key = ('ic', tuple(norm))
        if key in self._cache:
            ic = self._cache[key]
        else:
            target = self._load_validation_target()
            ic = information_coefficient(norm, target)
            self._cache[key] = ic

        # æ›´æ–°å› å­æ± 
        self.alphas.append(new_alpha)
        self.norm_alphas.append(norm)
        self.ic_list.append(ic)
        self.expr_list.append(expr)          # è®°å½•è¡¨è¾¾å¼

        # è‹¥æ˜¯é¦–å› å­ç›´æ¥èµ‹æƒ 1ï¼›å¦åˆ™é‡ä¼˜åŒ–æƒé‡
        if len(self.norm_alphas) == 1:
            self.weights = [1.0]
        else:
            self._reoptimize_weights()

        # è¶…é™æ—¶å‰”é™¤è´¡çŒ®æœ€å°å› å­
        if len(self.alphas) > self.max_pool_size:
            contrib = [abs(w * ic) for w, ic in zip(self.weights, self.ic_list)]
            idx = contrib.index(min(contrib))
            for lst in (self.alphas, self.norm_alphas, self.ic_list, self.weights):
                lst.pop(idx)

    def add_alpha_expr(self, expr: str) -> float:
        """
        æ ¹æ® RPN è¡¨è¾¾å¼è®¡ç®—æ–°å› å­ï¼Œå¹¶å°†å…¶åŠ å…¥å› å­æ± ã€‚

        Args:
            expr (str): RPN æ ¼å¼çš„è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ "close 5 ts_mean"ã€‚

        Returns:
            float: è¯¥å› å­çš„å• IC å€¼ï¼Œå¯ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„ rewardã€‚

        Raises:
            ValueError: å½“è¡¨è¾¾å¼æ ¼å¼é”™è¯¯æˆ–è¿ç®—å¤±è´¥æ—¶ã€‚
        """
        new_alpha = self._compute_alpha_from_expr(expr)
        ic = self.evaluate_alpha(expr)                  # é‡Œé¢è‡ªå¸¦ç¼“å­˜
        self.update_with(new_alpha, expr)
        return ic

    def _reoptimize_weights(self):
        """
        ä½¿ç”¨å‡¸ä¼˜åŒ–ï¼ˆSLSQPï¼‰åœ¨å½“å‰å› å­æ± ä¸Šæ±‚è§£æœ€ä¼˜çº¿æ€§æƒé‡ï¼Œ
        ç›®æ ‡ï¼šæœ€å¤§åŒ–ç»„åˆåºåˆ—ä¸ç›®æ ‡çš„ Pearson ç›¸å…³ç³»æ•°ï¼ˆICï¼‰ï¼Œ
        çº¦æŸï¼šæƒé‡ç»å¯¹å€¼ä¹‹å’Œç­‰äº 1ï¼ˆL1 å½’ä¸€åŒ–ï¼‰ã€‚
        """
        A = np.vstack(self.norm_alphas).T
        target = self._load_validation_target()

        def objective(w):
            combo = A.dot(w)
            ic = np.corrcoef(combo, target)[0, 1]
            return -np.nan_to_num(ic)

        cons = ({'type': 'eq', 'fun': lambda w: np.sum(np.abs(w)) - 1})
        x0 = np.ones(A.shape[1]) / A.shape[1]
        res = minimize(objective, x0, constraints=cons, method='SLSQP')
        self.weights = res.x.tolist()
        self._cache['weights'] = res.x.copy()

    def evaluate_alpha(self, expr: str) -> float:
        """
        ç›´æ¥æ ¹æ® RPN è¡¨è¾¾å¼è®¡ç®—å¹¶è¿”å›å•å› å­ ICï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚
        å¦‚æœä¸­é—´ä»»ä½•ä¸€æ­¥äº§ç”Ÿäº† warningï¼Œåœ¨ç¼“å­˜å®Œ IC ä¹‹åç»Ÿä¸€æŠ›é”™ã€‚
        """
        new_alpha = self._compute_alpha_from_expr(expr)
        new_alpha = np.nan_to_num(new_alpha, nan=0.0)
        norm = self._maybe_normalize(new_alpha)

        if np.all(np.isnan(new_alpha)):
            return -1.0

        key = ('expr_ic', expr)
        if key not in self._cache:
            target = self._load_validation_target()
            ic = information_coefficient(norm, target)
            self._cache[key] = ic

        return self._cache[key]

    def score(self) -> float:
        """
        è®¡ç®—å½“å‰å› å­ç»„åˆåœ¨éªŒè¯é›†ä¸Šçš„åŠ æƒ ICã€‚

        Returns:
            float: ç»„åˆå› å­çš„ Pearson IC å€¼ã€‚
        """
        A = np.vstack(self.norm_alphas).T
        combo = A.dot(np.array(self.weights))
        target = self._load_validation_target()
        return information_coefficient(combo, target)

    def _load_validation_target(self) -> np.ndarray:
        """
        è·å–æ³¨å…¥çš„ç›®æ ‡åºåˆ—æ•°ç»„ï¼ˆæœªæ¥æ”¶ç›Šæˆ–æ–¹å‘ï¼‰ã€‚

        Returns:
            np.ndarray: ç›®æ ‡åºåˆ—æ•°å€¼æ•°ç»„ã€‚

        Raises:
            AttributeError: è‹¥æœªè°ƒç”¨ `inject_data` æ³¨å…¥æ•°æ®æ—¶ã€‚
        """
        if not hasattr(self, "_target"):
            raise AttributeError("è¯·å…ˆè°ƒç”¨ inject_data() æ³¨å…¥è¡Œæƒ…å’Œç›®æ ‡åºåˆ—")
        return self._target

    def _compute_alpha_from_expr(self, expr: str) -> np.ndarray:
        """
        è§£æé€†æ³¢å…°è¡¨è¾¾å¼ï¼ˆRPNï¼‰ï¼Œæ‰§è¡Œç®—å­è¿ç®—ï¼Œç”ŸæˆåŸå§‹å› å­åºåˆ—ã€‚

        Args:
            expr (str): å½¢å¦‚ "close 5 ts_mean" çš„ RPN è¡¨è¾¾å¼å­—ç¬¦ä¸²ã€‚

        Returns:
            np.ndarray: è®¡ç®—å¾—åˆ°çš„å› å­å€¼æ•°ç»„ï¼Œdtype=float64ã€‚

        Raises:
            AttributeError: è‹¥æœªæ³¨å…¥ `data` æ—¶è°ƒç”¨ã€‚
            ValueError: è¡¨è¾¾å¼æ ¼å¼é”™è¯¯ï¼ˆæœªçŸ¥ tokenã€å‚æ•°ä¸è¶³æˆ–æœ€ç»ˆæ ˆæ·± != 1ï¼‰ã€‚
        """
        if not hasattr(self, "data"):
            raise AttributeError(
                "AlphaCombinationModel éœ€å…ˆæ³¨å…¥è¡Œæƒ… DataFrame åˆ° self.data"
            )

        tokens: List[str] = expr.strip().split()
        stack: List[Union[pd.Series, float]] = []

        func_map: Dict[str, Tuple[Callable, int]] = operators.FUNC_MAP

        for tk in tokens:
            if tk in self.data.columns:
                stack.append(self.data[tk])
            elif _is_float(tk):
                val = float(tk)
                if val.is_integer():
                    stack.append(int(val))
                else:
                    stack.append(float(tk))
            elif tk in func_map:
                fn, arity, _ = func_map[tk]
                if len(stack) < arity:
                    raise ValueError(f"RPN è¡¨è¾¾å¼å‚æ•°ä¸è¶³ï¼š{tk}")
                args = [stack.pop() for _ in range(arity)][::-1] # æ³¨æ„ï¼šå¼¹æ ˆé¡ºåºéœ€åè½¬ä»¥ä¿æŒåŸæ¥é¡ºåº
                res = fn(*args)
                stack.append(res)
            else:
                raise ValueError(f"æœªçŸ¥ tokenï¼š{tk}")

        if len(stack) != 1:
            raise ValueError(f"RPN è¡¨è¾¾å¼æœ€ç»ˆæ ˆæ·±åº¦åº”ä¸º 1, è®¡ç®—æ—¶ä¸º: {len(stack)}")
        output = stack[0]
        if np.isscalar(output):
            series = pd.Series(output, index=self.data.index)
        elif isinstance(output, pd.Series):
            series = output.reindex(self.data.index)
        else:
            series = pd.Series(output, index=self.data.index)

        return series.values.astype(np.float64)
    
    def _maybe_normalize(self, alpha: np.ndarray) -> np.ndarray:
        """
        å¯¹åŸå§‹å› å­åºåˆ—æ‰§è¡Œæˆªå°¾ï¼ˆwinsorizeï¼‰å’Œ Z-score æ ‡å‡†åŒ–ã€‚

        Args:
            alpha (np.ndarray): åŸå§‹å› å­å€¼æ•°ç»„ã€‚

        Returns:
            np.ndarray: å½’ä¸€åŒ–åçš„å› å­åºåˆ—ã€‚
        """
        return winsorize(zscore_normalize(alpha))

        # === 1. RPN è§£æä¸æ‰§è¡Œ ====================================================

def _is_float(str) -> bool:
    """
    åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦å¯è½¬æ¢ä¸ºæµ®ç‚¹æ•°ã€‚

    Args:
        s (str): å¾…æ£€æµ‹å­—ç¬¦ä¸²ã€‚

    Returns:
        bool: è‹¥èƒ½å®‰å…¨è½¬æ¢ä¸º floatï¼Œåˆ™è¿”å› Trueï¼Œå¦åˆ™ Falseã€‚
    """
    try:
        float(str)
        return True
    except ValueError:
        return False

================================================================================
File: ./tokenizer.py
--------------------------------------------------------------------------------
# tokenizer.py
import operators
from typing import List, Dict

class AlphaTokenizer:
    """
    å°†é€†æ³¢å…°è¡¨è¾¾å¼ (RPN) ä¸ token åºåˆ—ç›¸äº’æ˜ å°„çš„åˆ†è¯å™¨ã€‚

    - **è¯è¡¨**ï¼šåŸºç¡€è¡Œæƒ…å­—æ®µã€å¸¸é‡æ¡¶ã€æ‰€æœ‰ç®—å­ä»¥åŠå››åˆ™è¿ç®—ç¬¦  
    - **ç‰¹æ®Šæ ‡è®°**ï¼š`[PAD]` å¡«å……ã€`[BOS]` åºåˆ—èµ·å§‹ã€`[SEP]` åºåˆ—ç»ˆæ­¢
    """
    def __init__(self, base_fields: List[str] = None, const_buckets: List[float] = None):
        """
        æ„é€ åˆ†è¯å™¨å¹¶è‡ªåŠ¨æ‰«æ `operators.py` ç”Ÿæˆå®Œæ•´è¯è¡¨ã€‚

        å‚æ•°
        ----------
        base_fields : list[str], å¯é€‰
            åŸºç¡€è¡Œæƒ…å­—æ®µåç§°åˆ—è¡¨ï¼Œé»˜è®¤ä¸º  
            ``['open', 'high', 'low', 'close', 'volume']``ã€‚
        const_buckets : list[float], å¯é€‰
            é¢„å®šä¹‰æµ®ç‚¹å¸¸é‡æ¡¶ï¼Œé»˜è®¤ä¸º  
            ``[1, 3, 5, 10, 20, 0.1, 0.5]``ã€‚
        """
        if base_fields is None:
            base_fields = ['open', 'high', 'low', 'close', 'volume']
        if const_buckets is None:
            const_buckets = [1, 3, 5, 10, 20, 0.1, 0.5]

        self.base_fields = base_fields
        self.const_buckets = const_buckets

        self.special_tokens = ['[PAD]', '[BOS]', '[SEP]']
        field_tokens = base_fields
        const_tokens = [f'CONST_{c}' for c in const_buckets]
        op_tokens: List = list(operators.FUNC_MAP.keys())
        
        self.vocab: List[str] = self.special_tokens + field_tokens + const_tokens + op_tokens

        self.token_to_id: Dict[str, int] = {tok: idx for idx, tok in enumerate(self.vocab)}
        self.id_to_token: Dict[int, str] = {idx: tok for tok, idx in self.token_to_id.items()}
        self.operand_type_map: dict[str, str] = {}

        for f in self.base_fields:
            self.operand_type_map[f] = "Series"
        for c in self.const_buckets:
            tok = f"CONST_{c}"
            # å…ˆæŠŠ c è½¬æˆ floatï¼Œå†çœ‹æ˜¯ä¸æ˜¯æ•´æ•°
            if float(c).is_integer():
                self.operand_type_map[tok] = "Scalar_INT"
            else:
                self.operand_type_map[tok] = "Scalar_FLOAT"

        self.pad_token_id = self.token_to_id['[PAD]']
        self.bos_token_id = self.token_to_id['[BOS]']
        self.sep_token_id = self.token_to_id['[SEP]']

    @property
    def vocab_size(self) -> int:
        """
        è¿”å›å½“å‰è¯è¡¨å¤§å°ã€‚

        è¿”å›
        ----------
        int
            ``len(self.vocab)``ã€‚
        """
        return len(self.vocab)

    def encode(self, expr: str, add_special_tokens: bool = True) -> List[int]:
        """
        å°† RPN å­—ç¬¦ä¸²ç¼–ç ä¸º token ID åºåˆ—ã€‚

        å‚æ•°
        ----------
        expr : str
            å½¢å¦‚ ``"close 5 ts_mean"`` çš„é€†æ³¢å…°è¡¨è¾¾å¼ã€‚
        add_special_tokens : bool, å¯é€‰
            æ˜¯å¦åœ¨é¦–å°¾åˆ†åˆ«åŠ å…¥ `[BOS]` ä¸ `[SEP]`ï¼Œé»˜è®¤ä¸º ``True``ã€‚

        è¿”å›
        ----------
        list[int]
            token ID åºåˆ—ã€‚
        """
        tokens = expr.strip().split()
        ids = []
        for tk in tokens:
            # åŸºç¡€å­—æ®µ
            if tk in self.token_to_id:
                ids.append(self.token_to_id[tk])
            # å¸¸é‡ï¼šåŠ¨æ€åŠ å…¥æœ€è¿‘çš„ bucket
            elif self._is_float(tk):
                val = float(tk)
                const_tok = self._map_to_const(val)
                ids.append(self.token_to_id[const_tok])
            else:
                raise ValueError(f"æœªçŸ¥ tokenï¼š{tk}")

        if add_special_tokens:
            ids = [self.bos_token_id] + ids + [self.sep_token_id]
        return ids

    def decode(self, ids: List[int], remove_special_tokens: bool = True) -> str:
        """
        å°† token ID åºåˆ—è¿˜åŸä¸º RPN å­—ç¬¦ä¸²ã€‚

        å‚æ•°
        ----------
        ids : list[int]
            ç¼–ç åçš„ token ID åˆ—è¡¨ã€‚
        remove_special_tokens : bool, å¯é€‰
            æ˜¯å¦å»é™¤ `[BOS]` / `[SEP]` / `[PAD]`ï¼Œé»˜è®¤ä¸º ``True``ã€‚

        è¿”å›
        ----------
        str
            é€†æ³¢å…°è¡¨è¾¾å¼ï¼Œå¸¸é‡ä¼šè¢«è¿˜åŸä¸ºåŸå§‹æ•°å­—å­—ç¬¦ä¸²ã€‚
        """
        toks = []
        for idx in ids:
            if remove_special_tokens and idx in [self.bos_token_id, self.sep_token_id, self.pad_token_id]:
                continue
            toks.append(self.id_to_token.get(idx, 'UNK'))
        toks = [self._const_to_str(tk) for tk in toks]
        return " ".join(toks)

    def _map_to_const(self, val: float) -> str:
        """
        å°†ä»»æ„æµ®ç‚¹æ•°æ˜ å°„åˆ°æœ€è¿‘çš„å¸¸é‡æ¡¶ï¼Œå¹¶è¿”å›å…¶ token åã€‚

        å‚æ•°
        ----------
        val : float
            åŸå§‹æµ®ç‚¹æ•°ã€‚

        è¿”å›
        ----------
        str
            å½¢å¦‚ ``"CONST_5"`` çš„ token åç§°ã€‚
        """
        closest = min(self.const_buckets, key=lambda x: abs(x - val))
        return f'CONST_{closest}'

    def _const_to_str(self, token: str) -> str:
        """
        å°†å¸¸é‡ token åæ¢å¤ä¸ºæ•°å­—å­—ç¬¦ä¸²ã€‚

        å‚æ•°
        ----------
        token : str
            å½¢å¦‚ ``"CONST_3"`` çš„ tokenã€‚

        è¿”å›
        ----------
        str
            ``"3"``ï¼›å¦‚æœä¼ å…¥éå¸¸é‡ tokenï¼Œåˆ™åŸæ ·è¿”å›ã€‚
        """
        if token.startswith('CONST_'):
            return token.split('_', 1)[1]
        return token

    def rpn_to_infix(self, rpn: str) -> str:
        """
        å°†é€†æ³¢å…°è¡¨è¾¾å¼ (RPN) è½¬æ¢ä¸ºå¯è¯»çš„ä¸­ç¼€è¡¨è¾¾å¼ã€‚

        å‚æ•°
        ----------
        rpn : str
            å½¢å¦‚ `"close 5 ts_mean high low sub mul"` çš„ RPN å¼å­—ç¬¦ä¸²ã€‚

        è¿”å›
        ----------
        str
            å¯¹åº”çš„ä¸­ç¼€è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ `"(ts_mean(close, 5) * (high - low))"`ã€‚
        """
        from operators import FUNC_MAP

        stack: List[str] = []
        tokens = rpn.strip().split()
        for tk in tokens:
            # æ“ä½œç¬¦
            if tk in FUNC_MAP:
                fn, arity, _ = FUNC_MAP[tk]
                if arity == 1:
                    a = stack.pop()
                    stack.append(f"{tk}({a})")
                elif arity == 2:
                    b = stack.pop()
                    a = stack.pop()
                    if tk == "add":
                        stack.append(f"({a} + {b})")
                    elif tk == "sub":
                        stack.append(f"({a} - {b})")
                    elif tk == "mul":
                        stack.append(f"({a} * {b})")
                    elif tk == "div":
                        stack.append(f"({a} / {b})")
                    else:
                        stack.append(f"{tk}({a}, {b})")
                else:
                    args = ", ".join(stack[-arity:])
                    stack = stack[:-arity]
                    stack.append(f"{tk}({args})")
            else:
                val = self._const_to_str(tk)
                stack.append(val)
        return stack[0] if stack else ""

    @staticmethod
    def _is_float(s: str) -> bool:
        """
        åˆ¤æ–­å­—ç¬¦ä¸²èƒ½å¦å®‰å…¨è½¬æ¢ä¸º `float`ã€‚

        å‚æ•°
        ----------
        s : str
            å¾…æ£€æµ‹å­—ç¬¦ä¸²ã€‚

        è¿”å›
        ----------
        bool
            å¯è½¬æ¢è¿”å› ``True``ï¼Œå¦åˆ™ ``False``ã€‚
        """
        try:
            float(s)
            return True
        except ValueError:
            return False



================================================================================
File: ./generator.py
--------------------------------------------------------------------------------
# generator.py
from typing import List, Tuple, Dict, Any
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from torch.distributions import Categorical
from alpha_generation_env import AlphaGenerationEnv


class PolicyNetwork(nn.Module):
    def __init__(self, vocab_size: int, hidden_dim: int, num_layers: int = 1) -> None:
        """
        ç­–ç•¥ç½‘ç»œï¼Œç”¨äºç”Ÿæˆä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒã€‚

        Args:
            vocab_size: token vocabulary å¤§å°ï¼Œå³åŠ¨ä½œç©ºé—´å¤§å°ã€‚
            hidden_dim: LSTM éšè—å±‚ç»´åº¦ã€‚
            num_layers: LSTM å±‚æ•°ã€‚
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.fc_logits = nn.Linear(hidden_dim, vocab_size)

    def forward(
        self, x: torch.Tensor, hidden: Tuple[torch.Tensor, torch.Tensor]
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
        """
        Args:
            x: è¾“å…¥ token åºåˆ—ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len)ã€‚
            hidden: LSTM çš„éšè—çŠ¶æ€ (h, c)ï¼Œå½¢çŠ¶ä¸º (num_layers, batch_size, hidden_dim)ã€‚

        Returns:
            logits: ä¸‹ä¸€ä¸ª token çš„ logitsï¼Œå½¢çŠ¶ä¸º (batch_size, vocab_size)ã€‚
            hidden: æ›´æ–°åçš„éšè—çŠ¶æ€ã€‚
        """
        emb = self.embedding(x)
        out, hidden = self.lstm(emb, hidden)
        logits = self.fc_logits(out[:, -1, :])
        return logits, hidden

    def init_hidden(
        self, batch_size: int, device: torch.device
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åˆå§‹åŒ–éšè—çŠ¶æ€ä¸ºå…¨é›¶ã€‚

        Args:
            batch_size: æ‰¹é‡å¤§å°ã€‚
            device: æ‰€åœ¨è®¾å¤‡ï¼ˆcpu æˆ– cudaï¼‰ã€‚

        Returns:
            åˆå§‹åŒ–çš„ (h, c) çŠ¶æ€ã€‚
        """
        num_layers = self.lstm.num_layers
        hidden_dim = self.lstm.hidden_size
        h0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        c0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        return (h0, c0)


class ValueNetwork(nn.Module):
    def __init__(self, vocab_size: int, hidden_dim: int, num_layers: int = 1) -> None:
        """
        ä»·å€¼ç½‘ç»œï¼Œç”¨äºä¼°è®¡å½“å‰ token åºåˆ—çš„çŠ¶æ€ä»·å€¼ V(s)

        Args:
            vocab_size: token vocabulary å¤§å°ã€‚
            hidden_dim: LSTM éšè—å±‚ç»´åº¦ã€‚
            num_layers: LSTM å±‚æ•°ã€‚
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.fc_value = nn.Linear(hidden_dim, 1)

    def forward(
        self, x: torch.Tensor, hidden: Tuple[torch.Tensor, torch.Tensor]
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
        """
        å‚æ•°:
            x: è¾“å…¥ token åºåˆ—ï¼Œå½¢çŠ¶ä¸º (batch_size, seq_len)ã€‚
            hidden: LSTM éšè—çŠ¶æ€ã€‚

        è¿”å›å€¼:
            value: æ¯ä¸ªåºåˆ—çš„çŠ¶æ€ä»·å€¼ï¼Œå½¢çŠ¶ä¸º (batch_size,)ã€‚
            hidden: æ›´æ–°åçš„éšè—çŠ¶æ€ã€‚
        """
        emb = self.embedding(x)
        out, hidden = self.lstm(emb, hidden)
        value = self.fc_value(out[:, -1, :]).squeeze(-1)
        return value, hidden

    def init_hidden(
        self, batch_size: int, device: torch.device
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        åŒ PolicyNetworkï¼Œåˆå§‹åŒ– LSTM éšè—çŠ¶æ€ã€‚
        """
        num_layers = self.lstm.num_layers
        hidden_dim = self.lstm.hidden_size
        h0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        c0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        return (h0, c0)


class RLAlphaGenerator:
    """
    ä½¿ç”¨ PPO åœ¨ `AlphaGenerationEnv` ä¸­è®­ç»ƒç­–ç•¥ç½‘ç»œï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜ IC çš„ Alpha è¡¨è¾¾å¼ã€‚
    """

    def __init__(self, env: AlphaGenerationEnv, config: Dict[str, Any]) -> None:
        """
        å‚æ•°:
            env: å¼ºåŒ–å­¦ä¹ ç¯å¢ƒï¼Œéœ€æ”¯æŒ reset(), step(action), valid_actions() æ¥å£ã€‚
            config: åŒ…å«ç½‘ç»œå’Œ PPO è¶…å‚æ•°çš„é…ç½®å­—å…¸ã€‚
        """
        self.env: AlphaGenerationEnv = env
        self.vocab_size = config["vocab_size"]
        self.hidden_dim = config.get("hidden_dim", 128)
        self.device = config.get("device", "cpu")

        self.policy_net = PolicyNetwork(self.vocab_size, self.hidden_dim).to(
            self.device
        )
        self.value_net = ValueNetwork(self.vocab_size, self.hidden_dim).to(self.device)

        self.policy_optimizer = torch.optim.AdamW(
            self.policy_net.parameters(), lr=config.get("lr_policy", 3e-4)
        )
        self.value_optimizer = torch.optim.AdamW(
            self.value_net.parameters(), lr=config.get("lr_value", 1e-3)
        )

        self.gamma = config.get("gamma", 1.0)
        self.clip_eps = config.get("clip_eps", 0.2)
        self.entropy_coef = config.get("entropy_coef", 0.01)
        self.value_coef = config.get("value_coef", 0.5)
        self.update_epochs = config.get("update_epochs", 4)
        self.batch_size = config.get("batch_size", 64)
        self.max_seq_len = config.get("max_seq_len", 20)
    
    def train(self, num_iterations: int) -> None:
        """
        ç”¨ PPO è®­ç»ƒç­–ç•¥ & ä»·å€¼ç½‘ç»œã€‚
        æ¯è½®ï¼š
          â‘  ä¸ç¯å¢ƒäº¤äº’ï¼Œé‡‡æ · batch_size æ­¥ï¼ˆæˆ–æ›´å¤šï¼‰å®Œæ•´ episode
          â‘¡ è®¡ç®—ä¼˜åŠ¿ (A = R - V) å¹¶æ ‡å‡†åŒ–
          â‘¢ å¯¹ç­–ç•¥ / ä»·å€¼ç½‘ç»œåšå¤šæ¬¡ epoch æ›´æ–°
        """
        for it in range(1, num_iterations + 1):
            # ------ é‡‡æ ·è½¨è¿¹ -------------------------------------------------
            states, actions, old_logps, returns, advantages = self._collect_trajectories()

            # Advantage æ ‡å‡†åŒ–ä»¥ç¨³å®šè®­ç»ƒ
            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)

            # æ‰“åŒ…æˆ DataLoaderï¼Œæ–¹ä¾¿å¤šè½® epoch shuffle
            ds = TensorDataset(states, actions, old_logps, returns, advantages)
            loader = DataLoader(ds, batch_size=self.batch_size, shuffle=True)

            for _ in range(self.update_epochs):
                for s, a, logp_old, ret, adv in loader:
                    s = s.to(self.device)
                    a = a.to(self.device)
                    logp_old = logp_old.to(self.device).detach()
                    ret = ret.to(self.device)
                    adv = adv.to(self.device)

                    # ----- 1. é‡æ–°è®¡ç®—ç­–ç•¥ & log Ï€(a|s) ---------------------
                    h0_p = self.policy_net.init_hidden(s.size(0), self.device)
                    logits, _ = self.policy_net(s, h0_p)
                    dist = Categorical(logits=logits)
                    logp = dist.log_prob(a)
                    entropy = dist.entropy().mean()

                    # ----- 2. è®¡ç®— PPO clip æŸå¤± ---------------------------
                    ratio = (logp - logp_old).exp()
                    pg_loss = -torch.min(
                        ratio * adv,
                        torch.clamp(ratio, 1 - self.clip_eps, 1 + self.clip_eps) * adv,
                    ).mean()

                    # ----- 3. è®¡ç®—ä»·å€¼å‡½æ•°æŸå¤± -----------------------------
                    h0_v = self.value_net.init_hidden(s.size(0), self.device)
                    value_pred, _ = self.value_net(s, h0_v)
                    value_loss = F.mse_loss(value_pred.squeeze(-1), ret)

                    # ----- 4. æ€»æŸå¤± & åå‘ä¼ æ’­ ----------------------------
                    loss = pg_loss + self.value_coef * value_loss - self.entropy_coef * entropy

                    self.policy_optimizer.zero_grad()
                    self.value_optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)
                    torch.nn.utils.clip_grad_norm_(self.value_net.parameters(), 1.0)
                    self.policy_optimizer.step()
                    self.value_optimizer.step()

            # ------ æ‰“å°ç›‘æ§ä¿¡æ¯ --------------------------------------------
            if it % 10 == 0:
                with torch.no_grad():
                    avg_ret = returns.mean().item()
                    combo_ic = self.env.combo_model.score()
                print(f"[Iter {it:04d}]  AvgReturn={avg_ret:+.4f}   ComboIC={combo_ic:+.4f}")

    def _collect_trajectories(
        self,
    ) -> Tuple[
        List[torch.Tensor], List[int], List[torch.Tensor], List[float], List[float]
    ]:
        """
        ä»ç¯å¢ƒä¸­é‡‡æ ·ä¸€æ‰¹å®Œæ•´è½¨è¿¹ï¼Œå¹¶è®¡ç®—å›æŠ¥ä¸ä¼˜åŠ¿å€¼ï¼ˆGAE Î»=1ï¼‰ã€‚

        è¿”å›
        ----------
        states : torch.Tensor
            å½¢çŠ¶ ``(T, seq_len)`` çš„ token åºåˆ—å¼ é‡ã€‚
        actions : torch.Tensor
            é•¿åº¦ ``T`` çš„åŠ¨ä½œ IDã€‚
        logps : torch.Tensor
            å¯¹åº”åŠ¨ä½œçš„å¯¹æ•°æ¦‚ç‡ã€‚
        returns : torch.Tensor
            æŠ˜ç°å›æŠ¥ã€‚
        advantages : torch.Tensor
            Advantage å€¼ï¼ˆæ­¤å¤„ä¸º `return - value`ï¼‰ã€‚
        """
        states, actions, logps, rewards, dones, values = [], [], [], [], [], []

        obs = torch.tensor([self.env.reset()], device=self.device)
        h_p, h_v = self.policy_net.init_hidden(1, self.device), self.value_net.init_hidden(1, self.device)

        while len(states) < self.batch_size:
            logits, h_p = self.policy_net(obs, h_p)

            # -------- Invalid-action-mask --------
            valid = self.env.valid_actions()
            if len(valid) == 0:
                raise RuntimeError("æ²¡æœ‰åˆæ³•åŠ¨ä½œ")
            else:
                mask = torch.full((self.vocab_size,), float('-inf'), device=self.device)
                mask[valid] = 0.0                                   # åˆæ³•åŠ¨ä½œè®¾ç½®æˆ 0ï¼Œå…¶å®ƒä»ä¸º âˆ’inf
                logits = logits + mask                              # éæ³•åŠ¨ä½œ logits å˜ä¸º âˆ’inf
                dist = Categorical(logits=logits)
                action = dist.sample()
                logp = dist.log_prob(action)

                value, h_v = self.value_net(obs, h_v)
                value = value.squeeze(0).detach()
            
                next_obs, reward, done, _ = self.env.step(action.item())
            
            pad_id = self.env.tokenizer.pad_token_id
            raw = obs.squeeze(0)  # é•¿åº¦ä¸å®š
            pad = torch.full((self.max_seq_len,), pad_id, dtype=torch.long, device=self.device)
            if raw.size(0) >= self.max_seq_len:
                pad[:] = raw[-self.max_seq_len:]
            else:
                pad[-raw.size(0):] = raw
            
            states.append(pad)
            actions.append(action)
            logps.append(logp)
            rewards.append(torch.tensor(reward, device=self.device, dtype=torch.float32))
            dones.append(done)
            values.append(value)

            if done:
                obs = torch.tensor([self.env.reset()], device=self.device)
                h_p, h_v = self.policy_net.init_hidden(1, self.device), self.value_net.init_hidden(1, self.device)
            else:
                obs = torch.tensor([next_obs], device=self.device)
        
        # ===== è®¡ç®— GAE(Î»=1) â†’ advantage = return - value =====
        returns, advantages, R = [], [], torch.tensor(0.0, device=self.device)
        for r, v, d in zip(reversed(rewards), reversed(values), reversed(dones)):
            R = r + self.gamma * R * (1.0 - float(d))
            returns.insert(0, R)
            advantages.insert(0, R - v)
        
        return (
            torch.stack(states),
            torch.stack(actions).squeeze(-1),
            torch.stack(logps),
            torch.stack(returns),
            torch.stack(advantages),
        )
    
    

================================================================================
File: ./paradigm.py
--------------------------------------------------------------------------------
import numpy as np

# alpha_mining_framework/
# â”œâ”€â”€ __init__.py
# â”œâ”€â”€ data.py            # Data loading & preprocessing
# â”œâ”€â”€ utils.py           # Metrics: IC, RankIC, normalization, caching
# â”œâ”€â”€ combination.py     # AlphaCombinationModel: linear combine + weight optimization
# â”œâ”€â”€ env.py             # AlphaGenerationEnv: custom RL environment without gym
# â”œâ”€â”€ generator.py       # RLAlphaGenerator: PPO policy & value networks
# â”œâ”€â”€ train.py           # Main training loop implementing Algorithm 2
# â””â”€â”€ run_backtest.py    # Backtesting & investment simulation (Figure 5)






================================================================================
File: ./train.py
--------------------------------------------------------------------------------
# train.py
import os
import yaml
import pandas as pd

from utility import set_random_seed
from data import load_market_data
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from alpha_generation_env import AlphaGenerationEnv
from generator import RLAlphaGenerator


def main(config_path: str = "config.yaml"):
    with open(config_path, "r") as f:
        cfg = yaml.safe_load(f)

    set_random_seed(cfg.get("random_seed", 42))

    data_cfg = cfg["data"]
    df = load_market_data(
        path=data_cfg["path"], multiplier=data_cfg["multiplier"], n=data_cfg["n"]
    )

    combo = AlphaCombinationModel(max_pool_size=cfg["model"]["max_pool_size"])
    combo.inject_data(df, target_col=data_cfg["target_col"])

    tokenizer = AlphaTokenizer()
    env = AlphaGenerationEnv(
        combo_model=combo, tokenizer=tokenizer, max_len=cfg["env"]["max_len"]
    )

    gen_cfg = cfg["generator"]
    gen_cfg["vocab_size"] = tokenizer.vocab_size
    gen_cfg["max_seq_len"] = cfg["env"]["max_len"]
    agent = RLAlphaGenerator(env=env, config=gen_cfg)

    print(f"Starting training for {gen_cfg['num_iterations']} iterations...")
    agent.train(num_iterations=gen_cfg["num_iterations"])

    out_cfg = cfg["output"]
    os.makedirs(os.path.dirname(out_cfg["alphas_weights_path"]), exist_ok=True)
    results = pd.DataFrame(
        {"expr": combo.expr_list, "ic": combo.ic_list, "weight": combo.weights}
    )
    results.to_csv(out_cfg["alphas_weights_path"], index=False)
    print(f"Saved discovered alphas and weights to {out_cfg['alphas_weights_path']}")


if __name__ == "__main__":
    main()


================================================================================
File: ./operators.py
--------------------------------------------------------------------------------
# operators.py
import pandas as pd
import numpy as np
import inspect
from typing import List, Union

# -----------------------------
# Basic Operators
# -----------------------------

ARITH_OPS = {'add', 'sub', 'mul', 'div',}

ScalarOrSeries = Union[pd.Series, float, int]

def add(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x + y

def sub(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x - y

def mul(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x * y

def div(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    if isinstance(y, pd.Series):
        y = y.replace(0, np.nan)
    elif y == 0:
        y = np.nan
    return x / y

# -----------------------------
# Unary Operators
# -----------------------------

def abs_(x: pd.Series) -> pd.Series:
    return x.abs()

def sign(x: pd.Series) -> pd.Series:
    return np.sign(x)

def signed_log(x: pd.Series) -> pd.Series:
    a = x.abs().replace(0, np.nan)
    lg = np.log(a)
    return np.sign(x) * lg

def signed_sqrt(x: pd.Series) -> pd.Series:
    return np.sign(x) * np.sqrt(x.abs())

def neg(x: pd.Series) -> pd.Series:
    return -x


# -----------------------------
# Time-Series Operators (TS)
# -----------------------------

def ref(series: pd.Series, window: int) -> pd.Series:
    """Ref(x, t)ï¼šæ»åæœŸ t çš„å€¼"""
    return series.shift(window)

def ts_mean(series: pd.Series, window: int) -> pd.Series:
    """Mean(x, t)ï¼šæ»šåŠ¨å‡å€¼"""
    return series.rolling(window).mean()

def ts_med(series: pd.Series, window: int) -> pd.Series:
    """Med(x, t)ï¼šæ»šåŠ¨ä¸­ä½æ•°"""
    return series.rolling(window).median()

def ts_sum(series: pd.Series, window: int) -> pd.Series:
    """Sum(x, t)ï¼šæ»šåŠ¨æ±‚å’Œ"""
    return series.rolling(window).sum()

def ts_std(series: pd.Series, window: int) -> pd.Series:
    """Std(x, t)ï¼šæ»šåŠ¨æ ‡å‡†å·®"""
    return series.rolling(window).std()

def ts_var(series: pd.Series, window: int) -> pd.Series:
    """Var(x, t)ï¼šæ»šåŠ¨æ–¹å·®"""
    return series.rolling(window).var()

def ts_skew(series: pd.Series, window: int) -> pd.Series:
    """æ»šåŠ¨ååº¦"""
    return series.rolling(window).skew()

def ts_kurt(series: pd.Series, window: int) -> pd.Series:
    """æ»šåŠ¨å³°åº¦"""
    return series.rolling(window).kurt()

def ts_max(series: pd.Series, window: int) -> pd.Series:
    """Max(x, t)ï¼šæ»šåŠ¨æœ€å¤§å€¼"""
    return series.rolling(window).max()

def ts_min(series: pd.Series, window: int) -> pd.Series:
    """Min(x, t)ï¼šæ»šåŠ¨æœ€å°å€¼"""
    return series.rolling(window).min()

def ts_mad(series: pd.Series, window: int) -> pd.Series:
    """Mad(x, t)ï¼šæ»šåŠ¨å¹³å‡ç»å¯¹åå·®"""
    return series.rolling(window).apply(
        lambda x: np.mean(np.abs(x - np.mean(x))), raw=True
    )

def ts_delta(series: pd.Series, window: int = 1) -> pd.Series:
    """Delta(x, t)ï¼šä¸ t æœŸå‰çš„å·®å€¼"""
    return series.diff(window)

def ts_rank(series: pd.Series, window: int) -> pd.Series:
    """æ»šåŠ¨æ’åºç™¾åˆ†ä½"""
    def _rank(x):
        return pd.Series(x).rank(pct=True).iloc[-1]
    return series.rolling(window).apply(_rank, raw=True)

def ts_corr(x: pd.Series, y: pd.Series, window: int) -> pd.Series:
    """Corr(x, y, t)ï¼šæ»šåŠ¨çš®å°”æ£®ç›¸å…³ç³»æ•°"""
    return x.rolling(window).corr(y)

def ts_cov(x: pd.Series, y: pd.Series, window: int) -> pd.Series:
    """Cov(x, y, t)ï¼šæ»šåŠ¨åæ–¹å·®"""
    return x.rolling(window).cov(y)

def ts_wma(series: pd.Series, window: int) -> pd.Series:
    """WMA(x, t)ï¼šæ»šåŠ¨çº¿æ€§åŠ æƒå¹³å‡"""
    weights = np.arange(1, window + 1)
    return series.rolling(window).apply(
        lambda x: np.dot(x, weights) / weights.sum(), raw=True
    )

def ts_ema(series: pd.Series, window: int) -> pd.Series:
    """EMA(x, t)ï¼šæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆspan å¯ç†è§£ä¸º tï¼‰"""
    return series.ewm(span=window, adjust=False).mean()


# -----------------------------
# Utility Operators
# -----------------------------

def decay_linear(series: pd.Series, window: int) -> pd.Series:
    """çº¿æ€§è¡°å‡åŠ æƒå¹³å‡ï¼ˆåŒ WMAï¼‰"""
    weights = np.arange(1, window + 1)[::-1]
    return series.rolling(window).apply(
        lambda x: np.dot(x, weights) / weights.sum(), raw=True
    )

def ts_zscore(series: pd.Series, window: int) -> pd.Series:
    """æ—¶åºæ ‡å‡†åˆ†"""
    return (series - ts_mean(series, window)) / ts_std(series, window)

def ts_return(series: pd.Series, window: int = 1) -> pd.Series:
    """å‘¨æœŸæ”¶ç›Šç‡"""
    return series.pct_change(window, fill_method=None)


FUNC_MAP: dict[str, tuple[callable, int, List[str]]] = {}

for name, fn in inspect.getmembers(__import__(__name__), inspect.isfunction):
    if name.startswith("_"):
        continue

    if name in ARITH_OPS:
        FUNC_MAP[name] = (fn, 2, ['Any', 'Any'])  # 'Any' è¡¨ç¤º Scalar æˆ– Series éƒ½æ¥å—
        continue

    sig = inspect.signature(fn)
    param_types = []
    for param in sig.parameters.values():
        pname = param.name
        if pname in ('x', 'y', 'series'):
            param_types.append('Series')
        elif pname in ('window', 'n'):
            param_types.append('Scalar_INT')
        else:
            raise RuntimeError("Unrecognizable param type.")
    FUNC_MAP[name] = (fn, len(param_types), param_types)



================================================================================
File: ./data.py
--------------------------------------------------------------------------------
# data.py
# TODO: é€»è¾‘éœ€è¦æ›´åŠ ç»†åŒ–ï¼Œ
# 1. è¿‡æ»¤ä¸åˆæ ¼çš„äº¤æ˜“æ—¶é—´--é’ˆå¯¹ä¸åŒçš„äº¤æ˜“å“ç§ 
# 2. æ€ä¹ˆæ ·å¼¹æ€§åœ°æ»¡è¶³ä¸åŒè·¨åº¦å› å­çš„éœ€æ±‚ï¼Œæ•´ç†æˆ numpy.array é«˜æ•ˆåœ°è®¡ç®— icï¼Œç°åœ¨å¤„ç†æ–¹å¼ä¸º ç›´æ¥concatï¼Œå¾ˆä¸åˆç†
#   a. ä¸åŒçš„æ—¶é—´çª—å£; 
#   b. ä¸åŒçš„ symbol;


from typing import List, Dict
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np
from joblib import Parallel, delayed

def load_and_process(file: Path, multiplier: int, n: int) -> pd.DataFrame:
    df = pd.read_parquet(file)
    return process_tick_data(df, multiplier=multiplier, n=n)

def load_symbol_dfs(
    directory: str,
    symbols: Dict[str, int],
    start_date: str,
    end_date: str,
    n_jobs: int = 4,
    n: int = 10
) -> Dict[str, List[pd.DataFrame]]:
    dir_path = Path(directory)
    dt_start = datetime.strptime(start_date, "%Y%m%d").date()
    dt_end   = datetime.strptime(end_date,   "%Y%m%d").date()

    symbol_dfs: Dict[str, List[pd.DataFrame]] = {}

    for sym, mul in symbols.items():
        files = []
        for file in dir_path.glob(f"{sym}_*.parquet"):
            date_str = file.stem.split("_", 1)[1]
            try:
                file_date = datetime.strptime(date_str, "%Y%m%d").date()
            except ValueError:
                continue
            if dt_start <= file_date <= dt_end:
                files.append(file)
        files = sorted(files)

        processed_list = Parallel(n_jobs=n_jobs, backend="loky")(
            delayed(load_and_process)(file, mul, n)
            for file in files
        )
        symbol_dfs[sym] = processed_list

    return symbol_dfs

def process_tick_data(df: pd.DataFrame, multiplier: int = 10, n: int = 5):

    df = df.copy()
    df = df.set_index("timestamp").sort_index()

    df["d_vol"] = df["volume"].diff()
    df["d_amt"] = df["amount"].diff()
    df["d_oi"] = df["openInterest"].diff()

    df.loc[df["d_vol"] <= 0, ["d_vol", "d_amt"]] = np.nan

    df["trade_price"] = df["d_amt"] / df["d_vol"] / multiplier

    df['ts_ceil'] = df.index.to_series().dt.ceil('s')

    group = df.groupby('ts_ceil', sort=True)
    ohlc = pd.DataFrame({
        'open':         group['last'].first(),
        'high':         group['trade_price'].max(),
        'low':          group['trade_price'].min(),
        'close':        group['last'].last(),
        'volume':       group['d_vol'].sum(),
        'amount':       group['d_amt'].sum(),
        'openInterest': group['d_oi'].sum(),
    })

    ohlc.index.name = 'timestamp'

    mask = ohlc['high'].isna()
    if mask.any():
        last_max = group['last'].max()
        last_min = group['last'].min()
        ohlc.loc[mask, 'high'] = last_max[mask]
        ohlc.loc[mask, 'low']  = last_min[mask]

    ohlc["target"] = ohlc["close"].pct_change(periods=-n, fill_method=None)
    return ohlc




