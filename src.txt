================================================================================
File: .\alpha_generation_env.py
--------------------------------------------------------------------------------
# alpha_generation_env.py
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from typing import List
from operators import FUNC_MAP


class AlphaGenerationEnv:
    """
    自定义强化学习环境：生成逆波兰表达式（RPN）的序列决策过程。

    - **状态**：当前已生成的 token ID 列表
    - **动作**：下一个 token 的 ID
    - **奖励**：组合模型评估的单因子 IC
    - **终止条件**：生成 `[SEP]` 或达到 `max_len`
    """

    def __init__(
        self, combo_model: AlphaCombinationModel, tokenizer: AlphaTokenizer, max_len=20
    ):
        """
        初始化环境。

        参数
        ----------
        combo_model : AlphaCombinationModel
            负责因子池管理与 IC 计算的组合模型。
        tokenizer : AlphaTokenizer
            RPN ↔ token 序列转换器。
        max_len : int, 可选
            生成序列的最⼤长度（含 `[BOS]` 与 `[SEP]`），默认 20。
        """
        self.combo_model = combo_model
        self.tokenizer = tokenizer
        self.max_len = max_len
        self.reset()

    def reset(self):
        """
        重新开始一条新序列。

        返回
        ----------
        List[int]
            仅包含 `[BOS]` 的初始序列。
        """
        self.sequence: List[int] = [self.tokenizer.bos_token_id]
        self.done: bool = False
        self._stack_types: List[str] = []
        return self._get_obs()

    def step(self, action: int):
        """
        执行一步生成并返回环境转移结果。

        参数
        ----------
        action : int
            选定的 token ID。

        返回
        ----------
        obs : List[int]
            新的 token 序列。
        reward : float
            若已结束则为该表达式的单因子 IC，否则为 0。
        done : bool
            是否到达终止状态。
        info : dict
            预留调试信息，当前为空字典。
        """

        # —— 记录前一时刻的 info ——
        info = {
            "prev_stack_types": self._stack_types.copy(),
            "prev_depth": len(self._stack_types),
            "prev_valid_actions": self.valid_actions(),
            "action_id": action,
            "action_token": self.tokenizer.id_to_token[action],
        }

        # —— 执行动作：更新 sequence & stack_types ——
        self.sequence.append(action)
        tok = info["action_token"]
        if tok in self.tokenizer.operand_type_map:
            self._stack_types.append(self.tokenizer.operand_type_map[tok])
        elif tok in FUNC_MAP:
            _, arity, _ = FUNC_MAP[tok]
            for _ in range(arity):
                self._stack_types.pop()
            self._stack_types.append("Series")
        else:
            pass

        # —— 再补充依赖于“后”状态的 info ——
        info.update(
            {
                "new_stack_types": self._stack_types.copy(),
                "new_depth": len(self._stack_types),
                "remaining": self.max_len - len(self.sequence),
            }
        )

        # —— 计算 reward & done ——
        reward = 0.0
        if action == self.tokenizer.sep_token_id or len(self.sequence) >= self.max_len:
            expr = self.tokenizer.decode(self.sequence, remove_special_tokens=True)
            try:
                reward = self.combo_model.add_alpha_expr(expr)
            except ValueError as e:
                reward = -1.0
                info["error"] = str(e)
            self.done = True

        obs = self._get_obs()
        return obs, reward, self.done, info

    def _get_obs(self):
        """
        获取当前观测值（token 序列）。

        返回
        ----------
        List[int]
            当前生成序列（含 `[BOS]`，可能含 `[SEP]`）。
        """
        return self.sequence

    def valid_actions(self) -> List[int]:
        """
        获取当前状态下所有合法动作的 token ID。

        根据当前表达式的栈状态与剩余步数，筛选出能够构成
        合法逆波兰表达式的下一个 token。

        包含如下合法性检查：
        - 栈深是否满足操作符的参数需求；
        - 栈顶参数类型是否与操作符定义匹配；
        - 剩余步数是否足够完成表达式闭合；
        - 对于操作数，保证不会超出最大长度限制。

        返回
        ----------
        List[int]
            所有合法 token 的 ID 列表。
        """
        depth = len(self._stack_types)
        remaining = self.max_len - len(self.sequence)

        if remaining == 1:
            return [self.tokenizer.sep_token_id] if depth == 1 else []

        valid = []
        
        if depth == 1:
            valid.append(self.tokenizer.sep_token_id)

        for tok_id, tok in self.tokenizer.id_to_token.items():
            if tok in ("[PAD]", "[BOS]", "[SEP]"):
                continue

            # 时间序列算子前，只有整型常量才合法
            if tok in FUNC_MAP and tok.startswith("ts_"):
                last_tok = self.tokenizer.id_to_token[self.sequence[-1]]
                last_type = self.tokenizer.operand_type_map.get(last_tok)
                if last_type != "Scalar_INT":
                    continue
                if last_tok == "CONST_1":
                    continue
                if tok == "ts_kurt" and last_tok == "CONST_3":
                    continue

            if tok in FUNC_MAP:
                fn, arity, param_types = FUNC_MAP[tok]
                if depth < arity:
                    continue
                if not all(
                    _type_compatible(g, r)
                    for g, r in zip(self._stack_types[-arity:], param_types)
                ):
                    continue
                if depth - arity + 1 >= remaining:
                    continue
                valid.append(tok_id)
            else:
                # 常量不能连着常量
                if depth > 0 \
                and self.tokenizer.operand_type_map[tok].startswith("Scalar") \
                and self._stack_types[-1].startswith("Scalar"):
                    continue
                if depth + 1 < remaining:
                    valid.append(tok_id)
        return valid


def _type_compatible(given: str, required: str) -> bool:
    if given == required:
        return True
    if required == "Any":
        return True
    if given == "Scalar_INT" and required == "Scalar_FLOAT":
        return True
    return False


================================================================================
File: .\backtest_for_factor_0715_sz.py
--------------------------------------------------------------------------------
# backtest_for_factor_0715_sz.py
import pandas as pd
import numpy as np
import pymysql
import os
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import pandas as pd
import logging
from tqdm import tqdm
from typing import List
import pathlib
import os
from joblib import Parallel, delayed

logging.basicConfig(level=logging.INFO)
plt.rcParams["font.sans-serif"] = ["Microsoft YaHei"]  # Windows系统

# 配置
symbol = "ma"  # 品种代码
start_date = "2025-04-01"  # 开始日期
# end_date = "2025-07-10"  # 结束日期
end_date = "2025-07-24"  # 结束日期

window = 40


def get_symbol_info(symbol: str, field: str):
    """
    从数据库的 SymbolInfo 表中获取指定合约的某个字段值。

    Parameters
    ----------
    symbol : str
        品种代码，例如 'jm'。
    field : str
        要查询的字段名，如 'ExchangeCode', 'TickSize', 'Multiplier'。

    Returns
    -------
    Any
        指定字段对应的值。

    Raises
    ------
    ValueError
        如果查询不到对应的记录。
    pymysql.MySQLError
        数据库操作出错时抛出。
    """
    try:
        conn = pymysql.connect(
            host="192.168.1.118",
            user="replay1",
            password="replayMvt*",
            db="mvtdb",
            connect_timeout=5,
        )

        with conn.cursor() as cursor:
            sql = f"SELECT {field} FROM SymbolInfo WHERE Symbol = %s"
            cursor.execute(sql, (symbol,))
            result = cursor.fetchone()

            if result is None:
                raise ValueError(f"No result found for symbol: {symbol}")

            return result[0]

    except pymysql.MySQLError as e:
        print("数据库错误：", e)
    finally:
        try:
            conn.close()
        except:
            pass


def get_tick_files(
    symbol: str, start_date: str, end_date: str, tradetype: str = "Primary"
):
    """
    根据指定品种和日期范围，从本地文件系统和数据库查询匹配的 tick 数据文件路径。

    Parameters
    ----------
    symbol : str
        品种代码，如 'jm'。
    start_date : str
        开始日期，格式 'YYYY-MM-DD'.
    end_date : str
        结束日期，格式 'YYYY-MM-DD'.
    tradetype : str, optional
        交易类型，默认为 'Primary'.

    Returns
    -------
    tuple[list[pathlib.Path], list, list[str]]
        target_files : 匹配到的 CSV 文件路径列表。
        period_data : 查询到的交易时段记录。
        trading_days : 按升序排序的交易日列表（YYYYMMDD 格式）。
    """
    db_config = {
        "user": "replay1",
        "password": "replayMvt*",
        "host": "192.168.1.118",
        "port": 3306,
        "database": "mvtdb",
        "charset": "utf8mb4",
    }

    # SQL 查询
    sql_instruments = f"""
        SELECT TradingDay, InstrumentID 
        FROM TradeableInstrument 
        WHERE Symbol = '{symbol}' 
          AND TradingDay BETWEEN '{start_date}' AND '{end_date}' 
          AND TradeableType = '{tradetype}'
    """

    sql_trading_period = f"""
        SELECT * FROM SymbolTradingPeriod WHERE symbol = '{symbol}'
    """

    target_files = []

    foldername_dict = {
        "SHFE": "microvast-zx_920",
        "DCE": "microvast-gtja_950",
        "CZCE": "microvast-zx_960",
        "INE": "microvast-zx_920",
        "GFEX": "microvast-zx_901",
    }

    ExchangeCode = get_symbol_info(symbol, field="ExchangeCode")

    folder_name = foldername_dict[ExchangeCode]

    trading_days = []

    try:
        connection = pymysql.connect(**db_config)
        with connection.cursor() as cursor:
            # 查询主力合约
            cursor.execute(sql_instruments)
            results = cursor.fetchall()

            # 查询交易时段
            cursor.execute(sql_trading_period)
            period_data = cursor.fetchall()

            # 遍历查询结果，查找 tick 文件
            for row in results:
                trading_day = row[0].strftime("%Y%m%d")  # 格式化为 YYYYMMDD
                trading_days.append(trading_day)
                instrument_id = row[1]  # 合约代码（如 '2509'）

                PATH = pathlib.Path(
                    *[
                        "T:",
                        folder_name,
                        "Future",
                        ExchangeCode,
                        symbol,
                        trading_day,
                        f"{instrument_id}_{trading_day}.csv",
                    ]
                )

                if os.path.exists(PATH):
                    target_files.append(PATH)

    except pymysql.MySQLError as e:
        print("数据库查询错误:", e)
    finally:
        if connection:
            connection.close()

    return target_files, period_data, sorted(trading_days)


def load_and_preprocess_parallel(
    tick_files: List[str], n_jobs: int = -1
) -> pd.DataFrame:
    """
    并行加载并合并多日 tick CSV 文件。

    Parameters
    ----------
    tick_files : list of str
        需要加载的文件路径列表。
    n_jobs : int, optional
        并行作业数，-1 表示使用所有 CPU 核心。

    Returns
    -------
    pd.DataFrame
        将所有文件内容合并后的 DataFrame，包含原始列和解析后的 timestamp。
    """

    def _load_single_tick_file(file: str) -> pd.DataFrame:
        df = pd.read_csv(file)
        if "timestamp" not in df.columns:
            columns = [
                "timestamp",
                "instrumentID",
                "exchangeID",
                "last",
                "iopv",
                "bid1",
                "bid2",
                "bid3",
                "bid4",
                "bid5",
                "ask1",
                "ask2",
                "ask3",
                "ask4",
                "ask5",
                "bidSize1",
                "bidSize2",
                "bidSize3",
                "bidSize4",
                "bidSize5",
                "askSize1",
                "askSize2",
                "askSize3",
                "askSize4",
                "askSize5",
                "volume",
                "amount",
                "openInterest",
                "updateTime",
                "tradingPhaseCode",
                "indicativeAuctionPrice",
                "indexPrice",
                "epochTime",
            ]
            df.columns = columns
        df["timestamp"] = pd.to_datetime(df.timestamp)
        return df

    dfs = Parallel(n_jobs=n_jobs)(
        delayed(_load_single_tick_file)(file)
        for file in tqdm(tick_files, desc="并行加载")
    )

    df = pd.concat(dfs, ignore_index=True)
    return df


def assign_segment(
    df: pd.DataFrame, time_period: pd.DataFrame, xcol: str = "timestamp"
) -> pd.Series:
    """
    根据时间戳映射到上午盘、下午盘或夜盘。

    Parameters
    ----------
    df : pd.DataFrame
        包含时间戳列的 DataFrame。
    time_period : pd.DataFrame
        来自 SymbolTradingPeriod 表的交易时段信息。
    xcol : str, optional
        时间戳列名称，默认 'timestamp'.

    Returns
    -------
    pd.Series
        与 df 对齐的 segment 标签序列，可为 'morning', 'afternoon', 'night' 或 None。
    """
    # 1. 把 timestamp 转成 hhmmss 整数
    t = df[xcol].dt.hour * 10000 + df[xcol].dt.minute * 100 + df[xcol].dt.second

    # 2️. 上午盘 & 下午盘 的掩码
    mask_am = ((t > 85900) & (t < 101500)) | ((t > 102900) & (t < 113000))
    mask_pm = (t > 132900) & (t < 150000)

    # 3. 根据 time_period["end_time"] 决定夜盘逻辑
    end_times = set(time_period["end_time"].tolist())
    if 23000 in end_times:
        mask_night = (t > 205900) | (t < 23000)
    elif 10000 in end_times:
        mask_night = (t > 205900) | (t < 10000)
    elif 240000 in end_times:
        mask_night = t > 205900
    elif 233000 in end_times:
        mask_night = (t > 205900) & (t < 233000)
    elif 230000 in end_times:
        mask_night = (t > 205900) & (t < 230000)
    else:
        mask_night = pd.Series(False, index=df.index)

    # 4. 用 np.select 一次性贴标签
    df["segment"] = np.select(
        [mask_am, mask_pm, mask_night], ["morning", "afternoon", "night"], default=None
    )
    return df["segment"]


def align_segment(df: pd.DataFrame, trading_days: List[str]) -> pd.Series:
    """
    将夜盘交易的跨日数据映射到对应的交易日。

    Parameters
    ----------
    df : pd.DataFrame
        必须包含 'timestamp' 和 'segment' 列的 DataFrame。
    trading_days : list[str]
        按日期升序排列的交易日列表（YYYYMMDD）。

    Returns
    -------
    pd.Series
        与 df 行数一致的交易日映射（YYYYMMDD 字符串）。
    """

    trading_days_arr = (
        pd.to_datetime(trading_days).normalize().values.astype("datetime64[D]")
    )

    ts = df["timestamp"]
    dates = ts.dt.normalize().values.astype("datetime64[D]")
    minutes = ts.dt.hour.to_numpy(dtype="int32") * 60 + ts.dt.minute.to_numpy(
        dtype="int32"
    )
    is_night = df["segment"].eq("night").to_numpy()

    idx_right = np.searchsorted(trading_days_arr, dates, side="right")
    next_td = trading_days_arr[np.minimum(idx_right, len(trading_days_arr) - 1)]

    # ---- 规则 1：夜盘 & >= 20:30 —— 总是映射到 next_td ----
    mask_late = is_night & (minutes >= 20 * 60 + 30)

    # ---- 规则 2：夜盘 & <= 02:30 ----
    mask_early = is_night & (minutes <= 2 * 60 + 30)
    idx_left = np.searchsorted(trading_days_arr, dates, side="left")
    match_curr = (idx_left < len(trading_days_arr)) & (
        trading_days_arr[idx_left] == dates
    )  # 日期存在于 trading_days
    mapped_early = np.where(
        match_curr, trading_days_arr[idx_left], next_td
    )  # 存在→当天，否则→next_td

    # ---- 结果合并 ----
    mapped = dates.copy()  # 默认就是当天（含日盘、非夜盘行）
    mapped[mask_late] = next_td[mask_late]  # 规则 1
    mapped[mask_early] = mapped_early[mask_early]  # 规则 2

    return pd.to_datetime(mapped).strftime("%Y%m%d")


def calculate_future_returns(df: pd.DataFrame, M: int) -> pd.DataFrame:
    """
    计算未来 M 跳的收益率。

    Parameters
    ----------
    df : pd.DataFrame
        必须包含 'trading_day_mapped', 'segment', 'timestamp', 'mid_price' 列。
    M : int
        lookahead 步数。

    Returns
    -------
    pd.DataFrame
        在原 DataFrame 基础上添加 'future_price' 和 'future_return'，并剔除无法计算的行。
    """
    df1 = df.copy()
    df1 = df1.sort_values(["trading_day_mapped", "segment", "timestamp"])
    df1["future_price"] = df1.groupby(["segment", "trading_day_mapped"])[
        "mid_price"
    ].shift(-M)
    df1["future_return"] = ((df1["future_price"] / df1["mid_price"]) - 1.0) * 10000
    df1 = df1.dropna(subset=["future_price"])
    return df1


def get_R_score(factor: pd.Series, label: pd.Series) -> float:
    if len(factor) == 0:
        return np.nan

    X = factor.values.reshape(-1, 1)
    y = label

    model = LinearRegression(fit_intercept=True)
    model.fit(X, y)
    return model.score(X, y)


def evaluate_factor_by_segment(factor: pd.Series, df: pd.DataFrame) -> dict:
    """
    按不同交易时段(segment)评估因子对未来收益的解释能力。

    Parameters
    ----------
    factor : pd.Series
        根据原始 df 生成的因子序列，索引与 df 对齐。
    df : pd.DataFrame
        包含 'future_return', 'segment', 'is_limit' 列的 DataFrame。

    Returns
    -------
    dict
        键为 'all' 或具体时段标签，值为对应的 R²。
    """
    # 1) 合并
    data = pd.concat(
        [factor.rename("factor"), df[["future_return", "segment", "is_limit"]]], axis=1
    )
    # 2) 丢掉 NaN 并排除涨跌停
    data = data.dropna().loc[~data["is_limit"]]

    results = {}
    # —— 全时段 R² ——
    if len(data) >= 2:
        X_all = data["factor"].values.reshape(-1, 1)
        y_all = data["future_return"].values
        results["all"] = LinearRegression().fit(X_all, y_all).score(X_all, y_all)
    else:
        # 样本太少，直接全返回空
        return {}

    # —— 分段 R² ——
    for seg, grp in data.groupby("segment"):
        if len(grp) < 2:
            results[seg] = np.nan
            continue

        X = grp["factor"].values.reshape(-1, 1)
        y = grp["future_return"].values
        results[seg] = LinearRegression().fit(X, y).score(X, y)

    return results


def example_price_oi_divergence(df: pd.DataFrame, periods: int) -> pd.Series:
    """
    示例因子：价格与持仓量背离信号。

    Parameters
    ----------
    df : pd.DataFrame
        包含 'mid_price' 和 'openInterest' 的原始市场数据。
    periods : int
        计算差分的步长。

    Returns
    -------
    pd.Series
        取值 -1, 0, 1，代表不同的背离信号。
    """
    g = df.groupby(["trading_day_mapped", "segment"])
    price_diff = g["mid_price"].diff(periods)
    price_denominator = g["mid_price"].shift(periods)  # 修复：分母也分组计算
    price_change = price_diff * 10000 / price_denominator

    oi_change = g["openInterest"].diff(periods)

    signal = np.zeros(len(df))
    signal[(price_change > 0) & (oi_change < 0)] = -1
    signal[(price_change < 0) & (oi_change < 0)] = 1

    return pd.Series(signal, index=df.index, name="signal")


def example_calculate_momentum(df: pd.DataFrame, window: int = 50) -> pd.Series:
    """
    示例因子：基于分组的动量信号。

    Parameters
    ----------
    df : pd.DataFrame
        包含 'mid_price' 列和分组键的原始数据。
    window : int, optional
        计算动量的时间差窗口，默认为 50。

    Returns
    -------
    pd.Series
        重命名为 'momentum' 的动量值序列。
    """
    g = df.groupby(["trading_day_mapped", "segment"])
    return g["mid_price"].diff(window).div(df["mid_price"]).rename("momentum")


def evaluate_factor(
    df: pd.DataFrame, factor_func: callable, verbose: bool = True, *args, **kwargs
) -> dict:
    """
    计算因子并打印各交易时段的 R²（决定系数）。

    Parameters
    ----------
    df : pd.DataFrame
        包含市场行情数据和标签列的数据框，需包含用于计算因子的所有原始字段。

    factor_func : callable
        用于计算因子的函数，应接受 df 和可选参数，返回一个 pd.Series。
        其签名应为：factor_func(df, *args, **kwargs) -> pd.Series

    verbose : bool, optional
        是否打印每个交易时段对应的 R²，默认为 True。

    *args, **kwargs :
        传递给 factor_func 的附加参数。

    Returns
    -------
    dict
        各交易时间段（如 '夜盘'、'上午盘' 等）对应的 R² 值。
        键为时段名，值为 float（或 np.nan）。

    Notes
    -----
    - 该函数首先调用 factor_func 生成因子 Series；
    - 然后使用 `.align(df)` 将因子与原始数据对齐（按索引交集）；
    - 接着对每个交易时段计算该因子与标签的回归拟合优度 R²；
    - 最终结果以 logging 输出（若 verbose=True），并返回字典形式结果。
    """
    # 计算因子值（Series），并与 df 对齐
    factor = factor_func(df, *args, **kwargs)
    aligned_factor, aligned_df = factor.align(df, join="inner")

    # 分时段计算 R²
    r_squared = evaluate_factor_by_segment(aligned_factor, aligned_df)

    # 打印结果（可选）
    if verbose:
        formatted = {seg: f"{val:.6f}" for seg, val in r_squared.items()}
        logging.info(f"{factor_func.__name__} 的 R²: {formatted}")

    return r_squared


def factor_analysis(
    symbol: str,
    start_date: str,
    end_date: str,
    factor_func,
    tradetype: str = "Primary",
    verbose: bool = False,
    *args,
    **kwargs,
) -> dict:
    """
    一站式因子分析接口：
    - 拉取 tick 文件、加载预处理、贴标签、计算收益
    - 生成因子、对齐数据、分段回归评估 R²

    Parameters
    ----------
    symbol : str
        品种代码
    start_date : str
        开始日期，'YYYY-MM-DD'
    end_date : str
        结束日期，'YYYY-MM-DD'
    factor_func : callable
        因子函数，签名为 func(df, *args, **kwargs) -> pd.Series
    tradetype : str
        交易类型，默认 'Primary'
    *args, **kwargs :
        传给因子函数的参数

    Returns
    -------
    dict
        evaluate_factor_by_segment 的输出，各时段 R²
    """
    files, periods, days = get_tick_files(symbol, start_date, end_date, tradetype)
    df = load_and_preprocess_parallel(files)
    period_df = pd.DataFrame(
        periods, columns=["id", "symbol", "segment", "start_time", "end_time"]
    )
    df["segment"] = assign_segment(df, period_df)
    df["trading_day_mapped"] = align_segment(df, days)
    df = df.dropna(subset=["segment"])

    df["mid_price"] = (df["bid1"] + df["ask1"]) / 2.0
    df["is_limit"] = (
        df["bid1"].isna() | df["ask1"].isna() | (df["bid1"] == 0) | (df["ask1"] == 0)
    )
    df["mid_price"] = np.where(
        df["is_limit"],
        df["bid1"].fillna(0) + df["ask1"].fillna(0),
        (df["bid1"] + df["ask1"]) / 2.0,
    )

    df = calculate_future_returns(df, window)
    factor = factor_func(df, *args, **kwargs)
    aligned_factor, aligned_df = factor.align(df, join="inner")
    return evaluate_factor_by_segment(aligned_factor, aligned_df, verbose=verbose)

def secret_factor(df: pd.DataFrame):
    from operators import signed_log
    df["factor"] = signed_log(df.askSize1 /  (df.bidSize1 + 20))
    return df["factor"]



if __name__ == "__main__":

    tick_files, period_data, trading_days = get_tick_files(symbol, start_date, end_date)

    df = load_and_preprocess_parallel(tick_files)

    period_data = pd.DataFrame(
        period_data, columns=["id", "symbol", "segment", "start_time", "end_time"]
    )

    df["segment"] = assign_segment(df, period_data)

    df["trading_day_mapped"] = align_segment(df, trading_days)

    df = df.loc[~df.segment.isna()]

    logging.info(
        "================================数据准备完毕============================================"
    )

    df["mid_price"] = (df["bid1"] + df["ask1"]) / 2.0

    # 涨跌停判断（即 bid1 或 ask1 有缺失或为0）
    df["is_limit"] = (
        df["bid1"].isna() | df["ask1"].isna() | (df["bid1"] == 0) | (df["ask1"] == 0)
    )

    # 计算 mid_price：如果一边无效，则使用另一边；两边都无效则返回 NaN；否则取平均
    df["mid_price"] = np.where(
        df["is_limit"],
        df["bid1"].fillna(0) + df["ask1"].fillna(0),
        (df["bid1"] + df["ask1"]) / 2.0,
    )

    logging.info(
        "==============================以下是因子计算参数设置======================================="
    )
    df = calculate_future_returns(df, window)

    print(df.columns)
    r_squared1 = evaluate_factor(df, example_price_oi_divergence, periods=15)
    r_squared2 = evaluate_factor(df, example_calculate_momentum, window=50)
    r_squared2 = evaluate_factor(df, secret_factor)


================================================================================
File: .\combination.py
--------------------------------------------------------------------------------
# combination.py
import numpy as np
from utility import zscore_normalize, winsorize, information_coefficient
from sklearn.linear_model import ElasticNet
from scipy.optimize import minimize
from typing import List, Dict, Union, Tuple, Callable
import operators
import pandas as pd


class AlphaCombinationModel:
    """
    因子线性组合管理器，实现论文中算法1的核心思想。

    功能:
      - 维护一个最多包含 `max_pool_size` 条归一化因子序列的因子池。
      - 每当有新因子生成时，执行截尾（Winsorize）和 Z-score 标准化，并计算该因子的单因子 IC（Information Coefficient）。
      - 将新因子加入因子池后，通过凸优化（SLSQP）求解最优线性权重，以最大化组合 IC。
      - 若因子池超过上限，则剔除对组合贡献度最小的因子。
      - 在多次计算中对标准化序列、IC 值、最优权重等中间结果进行缓存，以减少重复开销。

    Attributes:
        max_pool_size (int): 因子池最大容量。超过后将删除贡献最小的因子。
        alphas (List[np.ndarray]): 原始因子序列列表。
        norm_alphas (List[np.ndarray]): 归一化后的因子序列列表。
        ic_list (List[float]): 对应每条因子的单因子 IC 列表。
        weights (List[float]): 当前组合中各因子的线性权重。
        expr_list (List[str]): 保存每条因子对应的 RPN 表达式。
        _cache (Dict): 缓存用于存储中间计算结果。
        data (pd.DataFrame): 注入的行情数据。
        _target (np.ndarray): 注入的目标列（未来收益）数组。
    """

    def __init__(
        self,
        max_pool_size: int = 50,
        combiner: Union[str, Callable] = "lsqp",
        combiner_args: Tuple = (),
        combiner_kwargs: Dict = None,
    ):
        """
        初始化 AlphaCombinationModel。

        Args:
            max_pool_size (int): 因子池的最大容量，上限内优先保留贡献度高的因子。
        """
        self.max_pool_size = max_pool_size
        self.combiner = combiner
        self.combiner_args = combiner_args
        self.combiner_kwargs = combiner_kwargs or {}

        self.alphas = []  # 原始因子序列列表
        self.norm_alphas = []  # 归一化后的因子序列列表
        self.ic_list = []  # 对应的单因子 IC 值列表
        self.weights = []  # 当前组合的线性权重列表
        self._cache = {}  # 缓存字典，用于存储中间结果
        self.expr_list = []  # 新增：对应每条因子的 RPN 表达式字符串

    def inject_data(self, df: pd.DataFrame, target_col: str) -> None:
        """
        注入市场行情数据和目标序列，用于 IC 计算与权重优化。

        Args:
            df (pd.DataFrame): 行情特征表，包含基础字段和目标列。
            target_col (str): DataFrame 中代表未来收益的列名，用于 IC 计算。

        Raises:
            ValueError: 当 target_col 不在 df 列时抛出。
        """
        # TODO: 需要更细致的训练集 / 验证集 分割逻辑，添加新的数据集作为验证集 etc
        self.data: pd.DataFrame = df
        self._target = df[target_col].values.astype(np.float64)

    def add_alpha_expr(self, expr: str) -> float:
        """
        根据 RPN 表达式计算新因子，并将其加入因子池。

        Args:
            expr (str): RPN 格式的表达式，例如 "close 5 ts_mean"。

        Returns:
            float: 该因子的单 IC 值，可作为强化学习的 reward。

        Raises:
            ValueError: 当表达式格式错误或运算失败时。
        """
        raw, norm, ic = self._compute_alpha_and_ic(expr)
        self._update_pool(raw, norm, ic, expr)
        return ic

    def _reoptimize_weights(self):
        A = np.vstack(self.norm_alphas).T
        y = self._load_validation_target()

        if isinstance(self.combiner, str):
            if self.combiner == "lsqp":
                w = self._reoptimize_weights_lsqp(
                    A, y, *self.combiner_args, **self.combiner_kwargs
                )
            elif self.combiner == "elastic_net":
                w = self._reoptimize_weights_enet(
                    A, y, *self.combiner_args, **self.combiner_kwargs
                )
            else:
                raise ValueError(f"Unknown combiner: {self.combiner}")
        elif callable(self.combiner):
            w = self.combiner(A, y, *self.combiner_args, **self.combiner_kwargs)
        else:
            raise TypeError("combiner 必须是 str 或者 可调用")

        self.weights = np.asarray(w, dtype=float).ravel().tolist()
        self._cache["weights"] = w.copy()

    def _reoptimize_weights_lsqp(self, A, y, *args, **kwargs):
        """原始 SLSQP + L1 约束"""

        def objective(w):
            combo = A.dot(w)
            ic = np.corrcoef(combo, y)[0, 1]
            return -np.nan_to_num(ic)

        cons = {"type": "eq", "fun": lambda w: np.sum(np.abs(w)) - 1}
        x0 = np.ones(A.shape[1]) / A.shape[1]
        res = minimize(objective, x0, constraints=cons, method="SLSQP", **kwargs)
        return res.x

    def _reoptimize_weights_enet(self, A, y, *args, **kwargs):
        """ElasticNet 拟合后再归一化 ∑|w|=1"""
        model = ElasticNet(
            fit_intercept=False,
            random_state=42,
            **kwargs,
        )
        model.fit(A, y)
        w = model.coef_
        s = np.sum(np.abs(w))
        return (w / s) if s > 0 else w

    def evaluate_alpha(self, expr: str) -> float:
        """只评估 IC，不入池。"""
        _, _, ic = self._compute_alpha_and_ic(expr)
        return ic

    def _compute_alpha_and_ic(
        self, expr: str, in_pool: bool = True
    ) -> Tuple[np.ndarray, np.ndarray, float]:
        """
        统一计算入口：expr -> raw alpha, norm alpha, ic（全程带缓存）
        """
        # 1) raw
        key_raw = ("raw_alpha", expr)
        if key_raw in self._cache:
            raw = self._cache[key_raw]
        else:
            raw = self._compute_alpha_from_expr(expr)
            raw = np.nan_to_num(raw, nan=0.0)
            if in_pool:
                self._cache[key_raw] = raw

        # 2) norm
        key_norm = ("norm_alpha", expr)
        if key_norm in self._cache:
            norm = self._cache[key_norm]
        else:
            norm = self._maybe_normalize(raw)
            if in_pool:
                self._cache[key_norm] = norm

        # 3) ic
        key_ic = ("expr_ic", expr)
        if key_ic in self._cache:
            ic = self._cache[key_ic]
        else:
            if np.all(np.isnan(raw)):
                ic = -1.0
            else:
                target = self._load_validation_target()
                ic = information_coefficient(norm, target)
            if in_pool:
                self._cache[key_ic] = ic

        return raw, norm, ic

    def _update_pool(
        self, raw: np.ndarray, norm: np.ndarray, ic: float, expr: str
    ) -> None:
        """
        给定已经算好的 raw/norm/ic，把它们塞进因子池并重优化权重。
        """
        # 1. 加入池
        self.alphas.append(raw)
        self.norm_alphas.append(norm)
        self.ic_list.append(ic)
        self.expr_list.append(expr)

        # 2. 权重更新
        if len(self.norm_alphas) == 1:
            self.weights = [1.0]
        else:
            self._reoptimize_weights()


        # 3. 超出容量时剔除贡献最小的因子
        if len(self.alphas) > self.max_pool_size:
            contrib = [abs(w * ic_) for w, ic_ in zip(self.weights, self.ic_list)]
            idx = int(np.argmin(contrib))
            for lst in (
                self.alphas,
                self.norm_alphas,
                self.ic_list,
                self.weights,
                self.expr_list,
            ):
                lst.pop(idx)

    def score(self) -> float:
        """
        计算当前因子组合在验证集上的加权 IC。

        Returns:
            float: 组合因子的 Pearson IC 值。
        """
        A = np.vstack(self.norm_alphas).T
        print(A.shape)
        print(self.weights)
        combo = A.dot(np.array(self.weights))
        target = self._load_validation_target()
        return information_coefficient(combo, target)

    def _load_validation_target(self) -> np.ndarray:
        """
        获取注入的目标序列数组（未来收益或方向）。

        Returns:
            np.ndarray: 目标序列数值数组。

        Raises:
            AttributeError: 若未调用 `inject_data` 注入数据时。
        """
        if not hasattr(self, "_target"):
            raise AttributeError("请先调用 inject_data() 注入行情和目标序列")
        return self._target

    def _compute_alpha_from_expr(self, expr: str) -> np.ndarray:
        """
        解析逆波兰表达式（RPN），执行算子运算，生成原始因子序列。

        Args:
            expr (str): 形如 "close 5 ts_mean" 的 RPN 表达式字符串。

        Returns:
            np.ndarray: 计算得到的因子值数组，dtype=float64。

        Raises:
            AttributeError: 若未注入 `data` 时调用。
            ValueError: 表达式格式错误（未知 token、参数不足或最终栈深 != 1）。
        """
        if not hasattr(self, "data"):
            raise AttributeError(
                "AlphaCombinationModel 需先注入行情 DataFrame 到 self.data"
            )

        tokens: List[str] = expr.strip().split()
        stack: List[Union[pd.Series, float]] = []

        func_map: Dict[str, Tuple[Callable, int]] = operators.FUNC_MAP

        for tk in tokens:
            if tk in self.data.columns:
                stack.append(self.data[tk])
            elif _is_float(tk):
                val = float(tk)
                if val.is_integer():
                    stack.append(int(val))
                else:
                    stack.append(float(tk))
            elif tk in func_map:
                fn, arity, _ = func_map[tk]
                if len(stack) < arity:
                    raise ValueError(f"RPN 表达式参数不足：{tk}")
                args = [stack.pop() for _ in range(arity)][
                    ::-1
                ]  # 注意：弹栈顺序需反转以保持原来顺序
                res = fn(*args)
                stack.append(res)
            else:
                raise ValueError(f"未知 token：{tk}")

        if len(stack) != 1:
            raise ValueError(f"RPN 表达式最终栈深度应为 1, 计算时为: {len(stack)}")
        output = stack[0]
        if np.isscalar(output):
            series = pd.Series(output, index=self.data.index)
        elif isinstance(output, pd.Series):
            series = output.reindex(self.data.index)
        else:
            series = pd.Series(output, index=self.data.index)

        return series.values.astype(np.float64)

    def _maybe_normalize(self, alpha: np.ndarray) -> np.ndarray:
        """
        对原始因子序列执行截尾（winsorize）和 Z-score 标准化。

        Args:
            alpha (np.ndarray): 原始因子值数组。

        Returns:
            np.ndarray: 归一化后的因子序列。
        """
        return winsorize(zscore_normalize(alpha))

        # === 1. RPN 解析与执行 ====================================================


def _is_float(str) -> bool:
    """
    判断字符串是否可转换为浮点数。

    Args:
        s (str): 待检测字符串。

    Returns:
        bool: 若能安全转换为 float，则返回 True，否则 False。
    """
    try:
        float(str)
        return True
    except ValueError:
        return False


================================================================================
File: .\data.py
--------------------------------------------------------------------------------
# data.py
# TODO: 逻辑需要更加细化，
# 1. 过滤不合格的交易时间--针对不同的交易品种 
# 2. 怎么样弹性地满足不同跨度因子的需求，整理成 numpy.array 高效地计算 ic，现在处理方式为 直接concat，很不合理
#   a. 不同的时间窗口; 
#   b. 不同的 symbol;


from typing import List, Dict
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np
from joblib import Parallel, delayed

def load_and_process(file: Path, multiplier: int, n: int, base_fields: List[str], ticks_per_second: int) -> pd.DataFrame:
    df = process_tick_data(pd.read_parquet(file), multiplier=multiplier, n=n, ticks_per_second=ticks_per_second)
    if base_fields is not None:
        df = df[base_fields + ["target"]]
    return df 

def load_symbol_dfs(
    directory: str,
    symbols: Dict[str, int],
    start_date: str,
    end_date: str,
    n_jobs: int = 4,
    n: int = 10,
    base_fields: List[str] = None,
    ticks_per_second: int = 4
) -> Dict[str, List[pd.DataFrame]]:
    dir_path = Path(directory)
    dt_start = datetime.strptime(start_date, "%Y%m%d").date()
    dt_end   = datetime.strptime(end_date,   "%Y%m%d").date()

    symbol_dfs: Dict[str, List[pd.DataFrame]] = {}

    for sym, mul in symbols.items():
        files = []
        for file in dir_path.glob(f"{sym}_*.parquet"):
            date_str = file.stem.split("_", 1)[1]
            try:
                file_date = datetime.strptime(date_str, "%Y%m%d").date()
            except ValueError:
                continue
            if dt_start <= file_date <= dt_end:
                files.append(file)
        files = sorted(files)

        processed_list = Parallel(n_jobs=n_jobs, backend="loky")(
            delayed(load_and_process)(file, mul, n, base_fields, ticks_per_second)
            for file in files
        )
        symbol_dfs[sym] = processed_list

    return symbol_dfs

def process_tick_data(df: pd.DataFrame, multiplier: int = 10, n: int = 5, ticks_per_second: int = 4):

    df = df.copy()
    df = df.set_index("timestamp").sort_index()

    df["d_vol"] = df["volume"].diff()
    df["d_amt"] = df["amount"].diff()
    df["d_oi"] = df["openInterest"].diff()
    df["mid"] = (df["ask1"] + df["bid1"]) / 2
    df["target"] = df["mid"].pct_change(periods=-n*ticks_per_second, fill_method=None)

    df.loc[df["d_vol"] <= 0, ["d_vol", "d_amt"]] = np.nan

    df["trade_price"] = df["d_amt"] / df["d_vol"] / multiplier

    df['ts_ceil'] = df.index.to_series().dt.ceil('s')

    return df




================================================================================
File: .\generator.py
--------------------------------------------------------------------------------
# generator.py
from typing import List, Tuple, Dict, Any
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from torch.distributions import Categorical
from tqdm import tqdm
from alpha_generation_env import AlphaGenerationEnv


class PolicyNetwork(nn.Module):
    def __init__(self, vocab_size: int, hidden_dim: int, num_layers: int = 1) -> None:
        """
        策略网络，用于生成下一个 token 的概率分布。

        Args:
            vocab_size: token vocabulary 大小，即动作空间大小。
            hidden_dim: LSTM 隐藏层维度。
            num_layers: LSTM 层数。
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.fc_logits = nn.Linear(hidden_dim, vocab_size)

    def forward(
        self, x: torch.Tensor, hidden: Tuple[torch.Tensor, torch.Tensor]
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
        """
        Args:
            x: 输入 token 序列，形状为 (batch_size, seq_len)。
            hidden: LSTM 的隐藏状态 (h, c)，形状为 (num_layers, batch_size, hidden_dim)。

        Returns:
            logits: 下一个 token 的 logits，形状为 (batch_size, vocab_size)。
            hidden: 更新后的隐藏状态。
        """
        emb = self.embedding(x)
        out, hidden = self.lstm(emb, hidden)
        logits = self.fc_logits(out[:, -1, :])
        return logits, hidden

    def init_hidden(
        self, batch_size: int, device: torch.device
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        初始化隐藏状态为全零。

        Args:
            batch_size: 批量大小。
            device: 所在设备（cpu 或 cuda）。

        Returns:
            初始化的 (h, c) 状态。
        """
        num_layers = self.lstm.num_layers
        hidden_dim = self.lstm.hidden_size
        h0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        c0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        return (h0, c0)


class ValueNetwork(nn.Module):
    def __init__(self, vocab_size: int, hidden_dim: int, num_layers: int = 1) -> None:
        """
        价值网络，用于估计当前 token 序列的状态价值 V(s)

        Args:
            vocab_size: token vocabulary 大小。
            hidden_dim: LSTM 隐藏层维度。
            num_layers: LSTM 层数。
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, hidden_dim)
        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers, batch_first=True)
        self.fc_value = nn.Linear(hidden_dim, 1)

    def forward(
        self, x: torch.Tensor, hidden: Tuple[torch.Tensor, torch.Tensor]
    ) -> Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]:
        """
        参数:
            x: 输入 token 序列，形状为 (batch_size, seq_len)。
            hidden: LSTM 隐藏状态。

        返回值:
            value: 每个序列的状态价值，形状为 (batch_size,)。
            hidden: 更新后的隐藏状态。
        """
        emb = self.embedding(x)
        out, hidden = self.lstm(emb, hidden)
        value = self.fc_value(out[:, -1, :]).squeeze(-1)
        return value, hidden

    def init_hidden(
        self, batch_size: int, device: torch.device
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        同 PolicyNetwork，初始化 LSTM 隐藏状态。
        """
        num_layers = self.lstm.num_layers
        hidden_dim = self.lstm.hidden_size
        h0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        c0 = torch.zeros(num_layers, batch_size, hidden_dim, device=device)
        return (h0, c0)


class RLAlphaGenerator:
    # TODO: 多进程高效训练
    """
    使用 PPO 在 `AlphaGenerationEnv` 中训练策略网络，自动生成高 IC 的 Alpha 表达式。
    """

    def __init__(self, env: AlphaGenerationEnv, config: Dict[str, Any]) -> None:
        """
        参数:
            env: 强化学习环境，需支持 reset(), step(action), valid_actions() 接口。
            config: 包含网络和 PPO 超参数的配置字典。
        """
        self.env: AlphaGenerationEnv = env
        self.vocab_size = config["vocab_size"]
        self.hidden_dim = config.get("hidden_dim", 128)
        self.device = config.get("device", "cpu")

        self.policy_net = PolicyNetwork(self.vocab_size, self.hidden_dim).to(
            self.device
        )
        self.value_net = ValueNetwork(self.vocab_size, self.hidden_dim).to(self.device)

        self.policy_optimizer = torch.optim.AdamW(
            self.policy_net.parameters(), lr=config.get("lr_policy", 3e-4)
        )
        self.value_optimizer = torch.optim.AdamW(
            self.value_net.parameters(), lr=config.get("lr_value", 1e-3)
        )

        self.gamma = config.get("gamma", 1.0)
        self.clip_eps = config.get("clip_eps", 0.2)
        self.entropy_coef = config.get("entropy_coef", 0.01)
        self.value_coef = config.get("value_coef", 0.5)
        self.update_epochs = config.get("update_epochs", 4)
        self.max_seq_len = config.get("max_seq_len", 20)
        self.rollout_size    = config.get("rollout_size", 4096)
        self.mini_batch_size = config.get("mini_batch_size", 256)
    
    def train(self, num_iterations: int) -> None:
        """
        用 PPO 训练策略 & 价值网络。
        每轮：
          ① 与环境交互，采样 batch_size 步（或更多）完整 episode
          ② 计算优势 (A = R - V) 并标准化
          ③ 对策略 / 价值网络做多次 epoch 更新
        """
        for it in range(1, num_iterations + 1):
            # ------ 采样轨迹 -------------------------------------------------
            states, actions, old_logps, returns, advantages = self._collect_trajectories()
            
            # Advantage 标准化以稳定训练
            advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)

            # 打包成 DataLoader，方便多轮 epoch shuffle
            ds = TensorDataset(states, actions, old_logps, returns, advantages)
            loader = DataLoader(ds, batch_size=self.mini_batch_size, shuffle=True)

            for _ in range(self.update_epochs):
                for s, a, logp_old, ret, adv in loader:
                    s = s.to(self.device)
                    a = a.to(self.device)
                    logp_old = logp_old.to(self.device).detach()
                    ret = ret.to(self.device)
                    adv = adv.to(self.device)

                    # ----- 1. 重新计算策略 & log π(a|s) ---------------------
                    h0_p = self.policy_net.init_hidden(s.size(0), self.device)
                    logits, _ = self.policy_net(s, h0_p)
                    dist = Categorical(logits=logits)
                    logp = dist.log_prob(a)
                    entropy = dist.entropy().mean()

                    # ----- 2. 计算 PPO clip 损失 ---------------------------
                    ratio = (logp - logp_old).exp()
                    pg_loss = -torch.min(
                        ratio * adv,
                        torch.clamp(ratio, 1 - self.clip_eps, 1 + self.clip_eps) * adv,
                    ).mean()

                    # ----- 3. 计算价值函数损失 -----------------------------
                    h0_v = self.value_net.init_hidden(s.size(0), self.device)
                    value_pred, _ = self.value_net(s, h0_v)
                    value_loss = F.mse_loss(value_pred.squeeze(-1), ret)

                    # ----- 4. 总损失 & 反向传播 ----------------------------
                    loss = pg_loss + self.value_coef * value_loss - self.entropy_coef * entropy

                    self.policy_optimizer.zero_grad()
                    self.value_optimizer.zero_grad()
                    loss.backward()
                    torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)
                    torch.nn.utils.clip_grad_norm_(self.value_net.parameters(), 1.0)
                    self.policy_optimizer.step()
                    self.value_optimizer.step()

            # ------ 打印监控信息 --------------------------------------------
            if it % 1 == 0:
                with torch.no_grad():
                    avg_ret = returns.mean().item()
                    combo_ic = self.env.combo_model.score()
                print(f"[Iter {it:04d}]  AvgReturn={avg_ret:+.4f}   ComboIC={combo_ic:+.4f}")

    def _collect_trajectories(
        self,
    ) -> Tuple[
        List[torch.Tensor], List[int], List[torch.Tensor], List[float], List[float]
    ]:
        """
        从环境中采样一批完整轨迹，并计算回报与优势值（GAE λ=1）。

        返回
        ----------
        states : torch.Tensor
            形状 ``(T, seq_len)`` 的 token 序列张量。
        actions : torch.Tensor
            长度 ``T`` 的动作 ID。
        logps : torch.Tensor
            对应动作的对数概率。
        returns : torch.Tensor
            折现回报。
        advantages : torch.Tensor
            Advantage 值（此处为 `return - value`）。
        """
        states, actions, logps, rewards, dones, values = [], [], [], [], [], []

        obs = torch.tensor([self.env.reset()], device=self.device)
        h_p, h_v = self.policy_net.init_hidden(1, self.device), self.value_net.init_hidden(1, self.device)

        for _ in tqdm(range(self.rollout_size)):
            logits, h_p = self.policy_net(obs, h_p)

            # -------- Invalid-action-mask --------
            valid = self.env.valid_actions()
            if len(valid) == 0:
                raise RuntimeError("没有合法动作")
            else:
                mask = torch.full((self.vocab_size,), float('-inf'), device=self.device)
                mask[valid] = 0.0                                   # 合法动作设置成 0，其它仍为 −inf
                logits = logits + mask                              # 非法动作 logits 变为 −inf
                dist = Categorical(logits=logits)
                action = dist.sample()
                logp = dist.log_prob(action)

                value, h_v = self.value_net(obs, h_v)
                value = value.squeeze(0).detach()
            
                next_obs, reward, done, _ = self.env.step(action.item())
            
            pad_id = self.env.tokenizer.pad_token_id
            raw = obs.squeeze(0)  # 长度不定
            pad = torch.full((self.max_seq_len,), pad_id, dtype=torch.long, device=self.device)
            if raw.size(0) >= self.max_seq_len:
                pad[:] = raw[-self.max_seq_len:]
            else:
                pad[-raw.size(0):] = raw
            
            states.append(pad)
            actions.append(action)
            logps.append(logp)
            rewards.append(torch.tensor(reward, device=self.device, dtype=torch.float32))
            dones.append(done)
            values.append(value)

            if done:
                obs = torch.tensor([self.env.reset()], device=self.device)
                h_p, h_v = self.policy_net.init_hidden(1, self.device), self.value_net.init_hidden(1, self.device)
            else:
                obs = torch.tensor([next_obs], device=self.device)
        
        # ===== 计算 GAE(λ=1) → advantage = return - value =====
        returns, advantages, R = [], [], torch.tensor(0.0, device=self.device)
        for r, v, d in zip(reversed(rewards), reversed(values), reversed(dones)):
            R = r + self.gamma * R * (1.0 - float(d))
            returns.insert(0, R)
            advantages.insert(0, R - v)
        
        return (
            torch.stack(states),
            torch.stack(actions).squeeze(-1),
            torch.stack(logps),
            torch.stack(returns),
            torch.stack(advantages),
        )
    
    

================================================================================
File: .\operators.py
--------------------------------------------------------------------------------
# operators.py
import pandas as pd
import numpy as np
import inspect
from typing import List, Union

# -----------------------------
# Basic Operators
# -----------------------------

ARITH_OPS = {'add', 'sub', 'mul', 'div',}

ScalarOrSeries = Union[pd.Series, float, int]

def add(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x + y

def sub(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x - y

def mul(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    return x * y

def div(x: ScalarOrSeries, y: ScalarOrSeries) -> ScalarOrSeries:
    if isinstance(y, pd.Series):
        y = y.replace(0, np.nan)
    elif y == 0:
        y = np.nan
    return x / y

# -----------------------------
# Unary Operators
# -----------------------------

def abs_(x: pd.Series) -> pd.Series:
    return x.abs()

def sign(x: pd.Series) -> pd.Series:
    return np.sign(x)

def signed_log(x: pd.Series) -> pd.Series:
    a = x.abs().replace(0, np.nan)
    lg = np.log(a)
    return np.sign(x) * lg

def signed_sqrt(x: pd.Series) -> pd.Series:
    return np.sign(x) * np.sqrt(x.abs())

def neg(x: pd.Series) -> pd.Series:
    return -x


# -----------------------------
# Time-Series Operators (TS)
# -----------------------------

def ref(series: pd.Series, window: int) -> pd.Series:
    """Ref(x, t)：滞后期 t 的值"""
    return series.shift(window)

def ts_mean(series: pd.Series, window: int) -> pd.Series:
    """Mean(x, t)：滚动均值"""
    return series.rolling(window).mean()

def ts_med(series: pd.Series, window: int) -> pd.Series:
    """Med(x, t)：滚动中位数"""
    return series.rolling(window).median()

def ts_sum(series: pd.Series, window: int) -> pd.Series:
    """Sum(x, t)：滚动求和"""
    return series.rolling(window).sum()

def ts_std(series: pd.Series, window: int) -> pd.Series:
    """Std(x, t)：滚动标准差"""
    return series.rolling(window).std()

def ts_var(series: pd.Series, window: int) -> pd.Series:
    """Var(x, t)：滚动方差"""
    return series.rolling(window).var()

def ts_skew(series: pd.Series, window: int) -> pd.Series:
    """滚动偏度"""
    return series.rolling(window).skew()

def ts_kurt(series: pd.Series, window: int) -> pd.Series:
    """滚动峰度"""
    return series.rolling(window).kurt()

def ts_max(series: pd.Series, window: int) -> pd.Series:
    """Max(x, t)：滚动最大值"""
    return series.rolling(window).max()

def ts_min(series: pd.Series, window: int) -> pd.Series:
    """Min(x, t)：滚动最小值"""
    return series.rolling(window).min()

def ts_mad(series: pd.Series, window: int) -> pd.Series:
    """Mad(x, t)：滚动平均绝对偏差"""
    return series.rolling(window).apply(
        lambda x: np.mean(np.abs(x - np.mean(x))), raw=True
    )

def ts_delta(series: pd.Series, window: int = 1) -> pd.Series:
    """Delta(x, t)：与 t 期前的差值"""
    return series.diff(window)

def ts_rank(series: pd.Series, window: int) -> pd.Series:
    """滚动排序百分位"""
    def _rank(x):
        return pd.Series(x).rank(pct=True).iloc[-1]
    return series.rolling(window).apply(_rank, raw=True)

def ts_corr(x: pd.Series, y: pd.Series, window: int) -> pd.Series:
    """Corr(x, y, t)：滚动皮尔森相关系数"""
    return x.rolling(window).corr(y)

def ts_cov(x: pd.Series, y: pd.Series, window: int) -> pd.Series:
    """Cov(x, y, t)：滚动协方差"""
    return x.rolling(window).cov(y)

def ts_wma(series: pd.Series, window: int) -> pd.Series:
    """WMA(x, t)：滚动线性加权平均"""
    weights = np.arange(1, window + 1)
    return series.rolling(window).apply(
        lambda x: np.dot(x, weights) / weights.sum(), raw=True
    )

def ts_ema(series: pd.Series, window: int) -> pd.Series:
    """EMA(x, t)：指数移动平均（span 可理解为 t）"""
    return series.ewm(span=window, adjust=False).mean()


# -----------------------------
# Utility Operators
# -----------------------------

def decay_linear(series: pd.Series, window: int) -> pd.Series:
    """线性衰减加权平均（同 WMA）"""
    weights = np.arange(1, window + 1)[::-1]
    return series.rolling(window).apply(
        lambda x: np.dot(x, weights) / weights.sum(), raw=True
    )

def ts_zscore(series: pd.Series, window: int) -> pd.Series:
    """时序标准分"""
    return (series - ts_mean(series, window)) / ts_std(series, window)

def ts_return(series: pd.Series, window: int = 1) -> pd.Series:
    """周期收益率"""
    return series.pct_change(window, fill_method=None)


FUNC_MAP: dict[str, tuple[callable, int, List[str]]] = {}

for name, fn in inspect.getmembers(__import__(__name__), inspect.isfunction):
    if name.startswith("_"):
        continue

    if name in ARITH_OPS:
        FUNC_MAP[name] = (fn, 2, ['Any', 'Any'])  # 'Any' 表示 Scalar 或 Series 都接受
        continue

    sig = inspect.signature(fn)
    param_types = []
    for param in sig.parameters.values():
        pname = param.name
        if pname in ('x', 'y', 'series'):
            param_types.append('Series')
        elif pname in ('window', 'n'):
            param_types.append('Scalar_INT')
        else:
            raise RuntimeError("Unrecognizable param type.")
    FUNC_MAP[name] = (fn, len(param_types), param_types)



================================================================================
File: .\paradigm.py
--------------------------------------------------------------------------------
import numpy as np

# alpha_mining_framework/
# ├── __init__.py
# ├── data.py            # Data loading & preprocessing
# ├── utils.py           # Metrics: IC, RankIC, normalization, caching
# ├── combination.py     # AlphaCombinationModel: linear combine + weight optimization
# ├── env.py             # AlphaGenerationEnv: custom RL environment without gym
# ├── generator.py       # RLAlphaGenerator: PPO policy & value networks
# ├── train.py           # Main training loop implementing Algorithm 2
# └── run_backtest.py    # Backtesting & investment simulation (Figure 5)






================================================================================
File: .\tokenizer.py
--------------------------------------------------------------------------------
# tokenizer.py
import operators
from typing import List, Dict

class AlphaTokenizer:
    """
    将逆波兰表达式 (RPN) 与 token 序列相互映射的分词器。

    - **词表**：基础行情字段、常量桶、所有算子以及四则运算符  
    - **特殊标记**：`[PAD]` 填充、`[BOS]` 序列起始、`[SEP]` 序列终止
    """
    def __init__(self, base_fields: List[str] = None, const_buckets: List[float] = None):
        """
        构造分词器并自动扫描 `operators.py` 生成完整词表。

        参数
        ----------
        base_fields : list[str], 可选
            基础行情字段名称列表，默认为  
            ``['open', 'high', 'low', 'close', 'volume']``。
        const_buckets : list[float], 可选
            预定义浮点常量桶，默认为  
            ``[1, 3, 5, 10, 20, 0.1, 0.5]``。
        """
        if base_fields is None:
            base_fields = ['open', 'high', 'low', 'close', 'volume']
        if const_buckets is None:
            const_buckets = [1, 3, 5, 10, 20, 0.1, 0.5]

        self.base_fields = base_fields
        self.const_buckets = const_buckets

        self.special_tokens = ['[PAD]', '[BOS]', '[SEP]']
        field_tokens = base_fields
        const_tokens = [f'CONST_{c}' for c in const_buckets]
        op_tokens: List = list(operators.FUNC_MAP.keys())
        
        self.vocab: List[str] = self.special_tokens + field_tokens + const_tokens + op_tokens

        self.token_to_id: Dict[str, int] = {tok: idx for idx, tok in enumerate(self.vocab)}
        self.id_to_token: Dict[int, str] = {idx: tok for tok, idx in self.token_to_id.items()}
        self.operand_type_map: dict[str, str] = {}

        for f in self.base_fields:
            self.operand_type_map[f] = "Series"
        for c in self.const_buckets:
            tok = f"CONST_{c}"
            # 先把 c 转成 float，再看是不是整数
            if float(c).is_integer():
                self.operand_type_map[tok] = "Scalar_INT"
            else:
                self.operand_type_map[tok] = "Scalar_FLOAT"

        self.pad_token_id = self.token_to_id['[PAD]']
        self.bos_token_id = self.token_to_id['[BOS]']
        self.sep_token_id = self.token_to_id['[SEP]']

    @property
    def vocab_size(self) -> int:
        """
        返回当前词表大小。

        返回
        ----------
        int
            ``len(self.vocab)``。
        """
        return len(self.vocab)

    def encode(self, expr: str, add_special_tokens: bool = True) -> List[int]:
        """
        将 RPN 字符串编码为 token ID 序列。

        参数
        ----------
        expr : str
            形如 ``"close 5 ts_mean"`` 的逆波兰表达式。
        add_special_tokens : bool, 可选
            是否在首尾分别加入 `[BOS]` 与 `[SEP]`，默认为 ``True``。

        返回
        ----------
        list[int]
            token ID 序列。
        """
        tokens = expr.strip().split()
        ids = []
        for tk in tokens:
            # 基础字段
            if tk in self.token_to_id:
                ids.append(self.token_to_id[tk])
            # 常量：动态加入最近的 bucket
            elif self._is_float(tk):
                val = float(tk)
                const_tok = self._map_to_const(val)
                ids.append(self.token_to_id[const_tok])
            else:
                raise ValueError(f"未知 token：{tk}")

        if add_special_tokens:
            ids = [self.bos_token_id] + ids + [self.sep_token_id]
        return ids

    def decode(self, ids: List[int], remove_special_tokens: bool = True) -> str:
        """
        将 token ID 序列还原为 RPN 字符串。

        参数
        ----------
        ids : list[int]
            编码后的 token ID 列表。
        remove_special_tokens : bool, 可选
            是否去除 `[BOS]` / `[SEP]` / `[PAD]`，默认为 ``True``。

        返回
        ----------
        str
            逆波兰表达式，常量会被还原为原始数字字符串。
        """
        toks = []
        for idx in ids:
            if remove_special_tokens and idx in [self.bos_token_id, self.sep_token_id, self.pad_token_id]:
                continue
            toks.append(self.id_to_token.get(idx, 'UNK'))
        toks = [self._const_to_str(tk) for tk in toks]
        return " ".join(toks)

    def _map_to_const(self, val: float) -> str:
        """
        将任意浮点数映射到最近的常量桶，并返回其 token 名。

        参数
        ----------
        val : float
            原始浮点数。

        返回
        ----------
        str
            形如 ``"CONST_5"`` 的 token 名称。
        """
        closest = min(self.const_buckets, key=lambda x: abs(x - val))
        return f'CONST_{closest}'

    def _const_to_str(self, token: str) -> str:
        """
        将常量 token 名恢复为数字字符串。

        参数
        ----------
        token : str
            形如 ``"CONST_3"`` 的 token。

        返回
        ----------
        str
            ``"3"``；如果传入非常量 token，则原样返回。
        """
        if token.startswith('CONST_'):
            return token.split('_', 1)[1]
        return token

    def rpn_to_infix(self, rpn: str) -> str:
        """
        将逆波兰表达式 (RPN) 转换为可读的中缀表达式。

        参数
        ----------
        rpn : str
            形如 `"close 5 ts_mean high low sub mul"` 的 RPN 式字符串。

        返回
        ----------
        str
            对应的中缀表达式字符串，例如 `"(ts_mean(close, 5) * (high - low))"`。
        """
        from operators import FUNC_MAP

        stack: List[str] = []
        tokens = rpn.strip().split()
        for tk in tokens:
            # 操作符
            if tk in FUNC_MAP:
                fn, arity, _ = FUNC_MAP[tk]
                if arity == 1:
                    a = stack.pop()
                    stack.append(f"{tk}({a})")
                elif arity == 2:
                    b = stack.pop()
                    a = stack.pop()
                    if tk == "add":
                        stack.append(f"({a} + {b})")
                    elif tk == "sub":
                        stack.append(f"({a} - {b})")
                    elif tk == "mul":
                        stack.append(f"({a} * {b})")
                    elif tk == "div":
                        stack.append(f"({a} / {b})")
                    else:
                        stack.append(f"{tk}({a}, {b})")
                else:
                    args = ", ".join(stack[-arity:])
                    stack = stack[:-arity]
                    stack.append(f"{tk}({args})")
            else:
                val = self._const_to_str(tk)
                stack.append(val)
        return stack[0] if stack else ""

    @staticmethod
    def _is_float(s: str) -> bool:
        """
        判断字符串能否安全转换为 `float`。

        参数
        ----------
        s : str
            待检测字符串。

        返回
        ----------
        bool
            可转换返回 ``True``，否则 ``False``。
        """
        try:
            float(s)
            return True
        except ValueError:
            return False



================================================================================
File: .\train.py
--------------------------------------------------------------------------------
# train.py
import os
import yaml
import pandas as pd

from utility import set_random_seed
from data import load_market_data
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from alpha_generation_env import AlphaGenerationEnv
from generator import RLAlphaGenerator


def main(config_path: str = "config.yaml"):
    with open(config_path, "r") as f:
        cfg = yaml.safe_load(f)

    set_random_seed(cfg.get("random_seed", 42))

    data_cfg = cfg["data"]
    df = load_market_data(
        path=data_cfg["path"], multiplier=data_cfg["multiplier"], n=data_cfg["n"]
    )

    combo = AlphaCombinationModel(max_pool_size=cfg["model"]["max_pool_size"])
    combo.inject_data(df, target_col=data_cfg["target_col"])

    tokenizer = AlphaTokenizer()
    env = AlphaGenerationEnv(
        combo_model=combo, tokenizer=tokenizer, max_len=cfg["env"]["max_len"]
    )

    gen_cfg = cfg["generator"]
    gen_cfg["vocab_size"] = tokenizer.vocab_size
    gen_cfg["max_seq_len"] = cfg["env"]["max_len"]
    agent = RLAlphaGenerator(env=env, config=gen_cfg)

    print(f"Starting training for {gen_cfg['num_iterations']} iterations...")
    agent.train(num_iterations=gen_cfg["num_iterations"])

    out_cfg = cfg["output"]
    os.makedirs(os.path.dirname(out_cfg["alphas_weights_path"]), exist_ok=True)
    results = pd.DataFrame(
        {"expr": combo.expr_list, "ic": combo.ic_list, "weight": combo.weights}
    )
    results.to_csv(out_cfg["alphas_weights_path"], index=False)
    print(f"Saved discovered alphas and weights to {out_cfg['alphas_weights_path']}")


if __name__ == "__main__":
    main()


================================================================================
File: .\unit_test.py
--------------------------------------------------------------------------------
# %% [markdown]
# ### 这个 notebook 用来读取文件，并测试一些方法

# %%
import os
import numpy as np


def get_all_py_files(root_dir: str) -> list:
    """
    获取指定目录及其子目录下的所有 .py 文件路径。

    Args:
        root_dir (str): 起始目录路径。

    Returns:
        list: 包含所有 .py 文件完整路径的列表。
    """
    py_files = []
    for dirpath, _, filenames in os.walk(root_dir):
        for file in filenames:
            if file.endswith(".py"):
                py_files.append(os.path.join(dirpath, file))
    return py_files


def write_all_py_contents_to_output(
    py_files: list, output_path: str = "src.txt"
) -> None:
    """
    将所有 .py 文件的内容写入一个文本文件中，并打印文件名作为分隔。

    Args:
        py_files (list): .py 文件路径列表。
        output_path (str): 输出文件路径。
    """
    with open(output_path, "w", encoding="utf-8") as out_file:
        for path in py_files:
            out_file.write(f"{'=' * 80}\n")
            out_file.write(f"File: {path}\n")
            out_file.write(f"{'-' * 80}\n")
            try:
                with open(path, "r", encoding="utf-8") as f:
                    out_file.write(f.read())
            except Exception as e:
                out_file.write(f"⚠️ Error reading {path}: {e}\n")
            out_file.write("\n\n")


if True:
    root_directory = "."  # 当前目录
    all_py_files = get_all_py_files(root_directory)
    write_all_py_contents_to_output(all_py_files)
    print(f"📄 所有 Python 文件内容已写入 src.txt（共 {len(all_py_files)} 个文件）")


# %%
import importlib
from utility import set_random_seed


def reload_components():
    """
    重新加载以下模块，以便在开发过程中即时生效：
      - data.load_market_data
      - tokenizer.AlphaTokenizer
      - combination.AlphaCombinationModel
      - envs.AlphaGenerationEnv
      - generator.RLAlphaGenerator
    """
    import data, tokenizer, combination, alpha_generation_env, generator

    importlib.reload(data)
    importlib.reload(tokenizer)
    importlib.reload(combination)
    importlib.reload(alpha_generation_env)
    importlib.reload(generator)

    # 重新绑定到本地名称（可选）
    from data import load_market_data
    from tokenizer import AlphaTokenizer
    from combination import AlphaCombinationModel
    from alpha_generation_env import AlphaGenerationEnv
    from generator import RLAlphaGenerator

    return {
        "load_market_data": load_market_data,
        "AlphaTokenizer": AlphaTokenizer,
        "AlphaCombinationModel": AlphaCombinationModel,
        "AlphaGenerationEnv": AlphaGenerationEnv,
        "RLAlphaGenerator": RLAlphaGenerator,
    }


components = reload_components()


# %% [markdown]
# ### 1.测试 AlphaCombinationModel._compute_alpha_from_expr

# %%
from combination import AlphaCombinationModel
from data import load_market_data

df = load_market_data()
model = AlphaCombinationModel()
model.inject_data(df, target_col="target")

# 表达式：close 的 100 秒均值
expr = "close 100 ts_mean"
alpha = model._compute_alpha_from_expr(expr)

print("alpha shape:", alpha.shape)
print("alpha sample:", alpha[~np.isnan(alpha)][:5])


# %% [markdown]
# ###  2. 测试 AlphaCombinationModel.add_alpha_expr

# %%
ic = model.add_alpha_expr("high low sub 100 ts_max")
print("该因子的 IC 为：", ic)
print("当前池中因子数：", len(model.alphas))


# %% [markdown]
# ### 3. 测试 AlphaTokenizer.encode / decode

# %%
from tokenizer import AlphaTokenizer

tokenizer = AlphaTokenizer()

expr = "close 5 ts_mean"
ids = tokenizer.encode(expr)
decoded = tokenizer.decode(ids)

print("Token IDs:", ids)
print("Decoded expr:", decoded)


# %% [markdown]
# ### 4. 测试 AlphaGenerationEnv.reset / step

# %%
from alpha_generation_env import AlphaGenerationEnv
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from data import load_market_data

df = load_market_data()
combo = AlphaCombinationModel()
combo.inject_data(df, target_col="target")
tokenizer = AlphaTokenizer()
env = AlphaGenerationEnv(combo, tokenizer)

obs = env.reset()
print("初始状态 token IDs:", obs)

valid = env.valid_actions()
action = valid[1]
obs2, reward, done, info = env.step(action)
print("新状态:", obs2)
print("Reward:", reward, "Done:", done)


# %% [markdown]
# ### 5. 测试 PolicyNetwork / ValueNetwork 输出维度

# %%
import torch
from generator import PolicyNetwork, ValueNetwork

vocab_size = 50
seq_len = 6
hidden_dim = 64
device = "cpu"

x = torch.randint(0, vocab_size, (1, seq_len))  # batch_size=1
policy = PolicyNetwork(vocab_size, hidden_dim).to(device)
value = ValueNetwork(vocab_size, hidden_dim).to(device)

h0_p = policy.init_hidden(1, device)
logits, _ = policy(x, h0_p)
print("Policy logits shape:", logits.shape)  # 应为 (1, vocab_size)

h0_v = value.init_hidden(1, device)
v, _ = value(x, h0_v)
print("Value estimate shape:", v.shape)  # 应为 (1,)


# %% [markdown]
# ### 6. 测试 RLAlphaGenerator._collect_trajectories

# %%
from generator import RLAlphaGenerator
from alpha_generation_env import AlphaGenerationEnv
from combination import AlphaCombinationModel
from tokenizer import AlphaTokenizer
from data import load_market_data
from utility import set_random_seed

# reload_components()

set_random_seed(10)

df = load_market_data()
combo = AlphaCombinationModel()
combo.inject_data(df, "target")
tokenizer = AlphaTokenizer()
env = AlphaGenerationEnv(combo, tokenizer, max_len=20)

cfg = dict(
    vocab_size=tokenizer.vocab_size,
    hidden_dim=64,
    batch_size=1280,
    device="cpu",
)

agent = RLAlphaGenerator(env, cfg)

s, a, logp, ret, adv = agent._collect_trajectories()
print("Sample states shape:", s.shape)
print("Sample actions shape:", a.shape)
print("Sample rewards (returns):", ret.shape, ret)


# %%


================================================================================
File: .\utility.py
--------------------------------------------------------------------------------
# utility.py
import numpy as np
import pandas as pd
import os
import random
import torch


def zscore_normalize(alpha: np.ndarray) -> pd.Series:
    """
    对因子序列进行Z-score标准化。

    该函数对输入数组进行去均值除以标准差处理，
    并将结果限制为有限值，所有NaN或无穷值替换为0。

    Args:
        alpha (np.ndarray): 原始因子值数组，dtype可包含NaN。

    Returns:
        pd.Series: 标准化后的序列，长度与输入相同，无NaN。
    """
    a = np.asarray(alpha, dtype=np.float64)
    mean = np.nanmean(a)
    std = np.nanstd(a)
    if std == 0 or np.isnan(std):
        return pd.Series(np.zeros_like(a))
    with np.errstate(invalid="ignore", divide="ignore"):
        z = (a - mean) / std
    z = np.nan_to_num(z, nan=0.0, posinf=0.0, neginf=0.0)
    return pd.Series(z)


def winsorize(
    alpha: np.ndarray, lower_quantile: float = 0.01, upper_quantile: float = 0.99
) -> pd.Series:
    """
    对因子序列进行截尾处理，限制极端值。

    使用指定上下分位数计算阈值，并将超出范围的值裁剪到边界，
    所有NaN或无穷值替换为对应边界值。

    Args:
        alpha (np.ndarray): 原始因子值数组。
        lower_quantile (float): 下分位点，默认0.01。
        upper_quantile (float): 上分位点，默认0.99。

    Returns:
        pd.Series: 截尾后的序列，长度与输入相同，无NaN。
    """
    a = np.asarray(alpha, dtype=float)
    with np.errstate(invalid="ignore", over="ignore"):
        lower = np.nanpercentile(a, lower_quantile * 100)
        upper = np.nanpercentile(a, upper_quantile * 100)
        clipped = np.clip(a, lower, upper)
    clipped = np.nan_to_num(clipped, nan=lower, posinf=upper, neginf=lower)
    return pd.Series(clipped)


def information_coefficient(factor: np.ndarray, target: np.ndarray) -> float:
    """
    计算因子与目标的Pearson相关系数（信息系数）。

    若输入长度不匹配或有效样本少于2，返回0；
    若任意方差为0，返回0。

    Args:
        factor (np.ndarray): 因子值数组。
        target (np.ndarray): 目标值数组（未来收益）。

    Returns:
        float: Pearson相关系数，范围[-1,1]，或0表示无效。
    """
    if len(factor) != len(target):
        raise ValueError("Factor and target length mismatch")
    mask = np.isfinite(factor) & np.isfinite(target)
    if mask.sum() < 2:
        return 0.0
    f, t = factor[mask], target[mask]
    if np.std(f) == 0 or np.std(t) == 0:
        return 0.0
    return float(np.corrcoef(f, t)[0, 1])


def set_random_seed(seed: int = 42):
    """
    固定全局随机数种子，确保实验可复现。

    Args:
        seed (int): 随机数种子，默认42。
    """
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


================================================================================
File: .\__init__.py
--------------------------------------------------------------------------------


================================================================================
File: .\alpha101_code\101Alpha_code_1.py
--------------------------------------------------------------------------------
import numpy as np
import pandas as pd
from numpy import abs
from numpy import log
from numpy import sign
from scipy.stats import rankdata

# region Auxiliary functions
def ts_sum(df, window=10):
    """
    Wrapper function to estimate rolling sum.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    
    return df.rolling(window).sum()

def sma(df, window=10):
    """
    Wrapper function to estimate SMA.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    return df.rolling(window).mean()

def stddev(df, window=10):
    """
    Wrapper function to estimate rolling standard deviation.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    return df.rolling(window).std()

def correlation(x, y, window=10):
    """
    Wrapper function to estimate rolling corelations.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    return x.rolling(window).corr(y)

def covariance(x, y, window=10):
    """
    Wrapper function to estimate rolling covariance.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    return x.rolling(window).cov(y)

def rolling_rank(na):
    """
    Auxiliary function to be used in pd.rolling_apply
    :param na: numpy array.
    :return: The rank of the last value in the array.
    """
    return rankdata(na)[-1]

def ts_rank(df, window=10):
    """
    Wrapper function to estimate rolling rank.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series rank over the past window days.
    """
    return df.rolling(window).apply(rolling_rank)

def rolling_prod(na):
    """
    Auxiliary function to be used in pd.rolling_apply
    :param na: numpy array.
    :return: The product of the values in the array.
    """
    return np.prod(na)

def product(df, window=10):
    """
    Wrapper function to estimate rolling product.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series product over the past 'window' days.
    """
    return df.rolling(window).apply(rolling_prod)

def ts_min(df, window=10):
    """
    Wrapper function to estimate rolling min.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series min over the past 'window' days.
    """
    return df.rolling(window).min()

def ts_max(df, window=10):
    """
    Wrapper function to estimate rolling min.
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: a pandas DataFrame with the time-series max over the past 'window' days.
    """
    return df.rolling(window).max()

def delta(df, period=1):
    """
    Wrapper function to estimate difference.
    :param df: a pandas DataFrame.
    :param period: the difference grade.
    :return: a pandas DataFrame with today’s value minus the value 'period' days ago.
    """
    return df.diff(period)

def delay(df, period=1):
    """
    Wrapper function to estimate lag.
    :param df: a pandas DataFrame.
    :param period: the lag grade.
    :return: a pandas DataFrame with lagged time series
    """
    return df.shift(period)

def rank(df):
    """
    Cross sectional rank
    :param df: a pandas DataFrame.
    :return: a pandas DataFrame with rank along columns.
    """
    #return df.rank(axis=1, pct=True)
    return df.rank(pct=True)

def scale(df, k=1):
    """
    Scaling time serie.
    :param df: a pandas DataFrame.
    :param k: scaling factor.
    :return: a pandas DataFrame rescaled df such that sum(abs(df)) = k
    """
    return df.mul(k).div(np.abs(df).sum())

def ts_argmax(df, window=10):
    """
    Wrapper function to estimate which day ts_max(df, window) occurred on
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: well.. that :)
    """
    return df.rolling(window).apply(np.argmax) + 1 

def ts_argmin(df, window=10):
    """
    Wrapper function to estimate which day ts_min(df, window) occurred on
    :param df: a pandas DataFrame.
    :param window: the rolling window.
    :return: well.. that :)
    """
    return df.rolling(window).apply(np.argmin) + 1

def decay_linear(df, period=10):
    """
    Linear weighted moving average implementation.
    :param df: a pandas DataFrame.
    :param period: the LWMA period
    :return: a pandas DataFrame with the LWMA.
    """
    # Clean data
    if df.isnull().values.any():
        df.fillna(method='ffill', inplace=True)
        df.fillna(method='bfill', inplace=True)
        df.fillna(value=0, inplace=True)
    na_lwma = np.zeros_like(df)
    na_lwma[:period, :] = df.iloc[:period, :] 
    na_series = df.as_matrix()

    divisor = period * (period + 1) / 2
    y = (np.arange(period) + 1) * 1.0 / divisor
    # Estimate the actual lwma with the actual close.
    # The backtest engine should assure to be snooping bias free.
    for row in range(period - 1, df.shape[0]):
        x = na_series[row - period + 1: row + 1, :]
        na_lwma[row, :] = (np.dot(x.T, y))
    return pd.DataFrame(na_lwma, index=df.index, columns=['CLOSE'])  
# endregion

def get_alpha(df):
        stock=Alphas(df)
        df['alpha001']=stock.alpha001() 
        df['alpha002']=stock.alpha002()
        df['alpha003']=stock.alpha003()
        df['alpha004']=stock.alpha004()
        df['alpha005']=stock.alpha005()
        df['alpha006']=stock.alpha006()
        df['alpha007']=stock.alpha007()
        df['alpha008']=stock.alpha008()
        df['alpha009']=stock.alpha009()
        df['alpha010']=stock.alpha010()
        df['alpha011']=stock.alpha011()
        df['alpha012']=stock.alpha012()
        df['alpha013']=stock.alpha013()
        df['alpha014']=stock.alpha014()
        df['alpha015']=stock.alpha015()
        df['alpha016']=stock.alpha016()
        df['alpha017']=stock.alpha017()
        df['alpha018']=stock.alpha018()
        df['alpha019']=stock.alpha019()
        df['alpha020']=stock.alpha020()
        df['alpha021']=stock.alpha021()
        df['alpha022']=stock.alpha022()
        df['alpha023']=stock.alpha023()
        df['alpha024']=stock.alpha024()
        df['alpha025']=stock.alpha025()
        df['alpha026']=stock.alpha026()
        df['alpha027']=stock.alpha027()
        df['alpha028']=stock.alpha028()
        df['alpha029']=stock.alpha029()
        df['alpha030']=stock.alpha030()
        df['alpha031']=stock.alpha031()
        df['alpha032']=stock.alpha032()
        df['alpha033']=stock.alpha033()
        df['alpha034']=stock.alpha034()
        df['alpha035']=stock.alpha035()
        df['alpha036']=stock.alpha036()
        df['alpha037']=stock.alpha037()
        df['alpha038']=stock.alpha038()
        df['alpha039']=stock.alpha039()
        df['alpha040']=stock.alpha040()
        df['alpha041']=stock.alpha041()
        df['alpha042']=stock.alpha042()
        df['alpha043']=stock.alpha043()
        df['alpha044']=stock.alpha044()
        df['alpha045']=stock.alpha045()
        df['alpha046']=stock.alpha046()
        df['alpha047']=stock.alpha047()
        df['alpha049']=stock.alpha049()
        df['alpha050']=stock.alpha050()
        df['alpha051']=stock.alpha051()
        df['alpha052']=stock.alpha052()
        df['alpha053']=stock.alpha053()
        df['alpha054']=stock.alpha054()
        df['alpha055']=stock.alpha055()
        df['alpha057']=stock.alpha057()
        df['alpha060']=stock.alpha060()
        df['alpha061']=stock.alpha061()
        df['alpha062']=stock.alpha062()
        df['alpha064']=stock.alpha064()
        df['alpha065']=stock.alpha065()
        df['alpha066']=stock.alpha066()
        df['alpha068']=stock.alpha068()
        df['alpha071']=stock.alpha071()
        df['alpha072']=stock.alpha072()
        df['alpha073']=stock.alpha073()
        df['alpha074']=stock.alpha074()
        df['alpha075']=stock.alpha075()
        df['alpha077']=stock.alpha077()
        df['alpha078']=stock.alpha078()
        df['alpha081']=stock.alpha081()
        df['alpha083']=stock.alpha083()
        df['alpha084']=stock.alpha084()
        df['alpha085']=stock.alpha085()
        df['alpha086']=stock.alpha086()
        df['alpha088']=stock.alpha088()
        df['alpha092']=stock.alpha092()
        df['alpha094']=stock.alpha094()
        df['alpha095']=stock.alpha095()
        df['alpha096']=stock.alpha096()
        df['alpha098']=stock.alpha098()
        df['alpha099']=stock.alpha099()
        df['alpha101']=stock.alpha101()  
        return df

class Alphas(object):
    def __init__(self, df_data):

        self.open = df_data['S_DQ_OPEN'] 
        self.high = df_data['S_DQ_HIGH'] 
        self.low = df_data['S_DQ_LOW']   
        self.close = df_data['S_DQ_CLOSE'] 
        self.volume = df_data['S_DQ_VOLUME']*100 
        self.returns = df_data['S_DQ_PCTCHANGE'] 
        self.vwap = (df_data['S_DQ_AMOUNT']*1000)/(df_data['S_DQ_VOLUME']*100+1) 
        
    # Alpha#1	 (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) -0.5)
    def alpha001(self):
        inner = self.close
        inner[self.returns < 0] = stddev(self.returns, 20)
        return rank(ts_argmax(inner ** 2, 5))
    
    # Alpha#2	 (-1 * correlation(rank(delta(log(volume), 2)), rank(((close - open) / open)), 6))
    def alpha002(self):
        df = -1 * correlation(rank(delta(log(self.volume), 2)), rank((self.close - self.open) / self.open), 6)
        return df.replace([-np.inf, np.inf], 0).fillna(value=0)
    
    # Alpha#3	 (-1 * correlation(rank(open), rank(volume), 10))
    def alpha003(self):
        df = -1 * correlation(rank(self.open), rank(self.volume), 10)
        return df.replace([-np.inf, np.inf], 0).fillna(value=0)
    
    # Alpha#4	 (-1 * Ts_Rank(rank(low), 9))
    def alpha004(self):
        return -1 * ts_rank(rank(self.low), 9)
    
    # Alpha#5	 (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap)))))
    def alpha005(self):
        return  (rank((self.open - (sum(self.vwap, 10) / 10))) * (-1 * abs(rank((self.close - self.vwap)))))
    
    # Alpha#6	 (-1 * correlation(open, volume, 10))
    def alpha006(self):
        df = -1 * correlation(self.open, self.volume, 10)
        return df.replace([-np.inf, np.inf], 0).fillna(value=0)
    
    # Alpha#7	 ((adv20 < volume) ? ((-1 * ts_rank(abs(delta(close, 7)), 60)) * sign(delta(close, 7))) : (-1* 1))
    def alpha007(self):
        adv20 = sma(self.volume, 20)
        alpha = -1 * ts_rank(abs(delta(self.close, 7)), 60) * sign(delta(self.close, 7))
        alpha[adv20 >= self.volume] = -1
        return alpha
    
    # Alpha#8	 (-1 * rank(((sum(open, 5) * sum(returns, 5)) - delay((sum(open, 5) * sum(returns, 5)),10))))
    def alpha008(self):
        return -1 * (rank(((ts_sum(self.open, 5) * ts_sum(self.returns, 5)) -
                           delay((ts_sum(self.open, 5) * ts_sum(self.returns, 5)), 10))))
    
    # Alpha#9	 ((0 < ts_min(delta(close, 1), 5)) ? delta(close, 1) : ((ts_max(delta(close, 1), 5) < 0) ?delta(close, 1) : (-1 * delta(close, 1))))
    def alpha009(self):
        delta_close = delta(self.close, 1)
        cond_1 = ts_min(delta_close, 5) > 0
        cond_2 = ts_max(delta_close, 5) < 0
        alpha = -1 * delta_close
        alpha[cond_1 | cond_2] = delta_close
        return alpha
    
    # Alpha#10	 rank(((0 < ts_min(delta(close, 1), 4)) ? delta(close, 1) : ((ts_max(delta(close, 1), 4) < 0)? delta(close, 1) : (-1 * delta(close, 1)))))
    def alpha010(self):
        delta_close = delta(self.close, 1)
        cond_1 = ts_min(delta_close, 4) > 0
        cond_2 = ts_max(delta_close, 4) < 0
        alpha = -1 * delta_close
        alpha[cond_1 | cond_2] = delta_close
        return alpha
    
    # Alpha#11	 ((rank(ts_max((vwap - close), 3)) + rank(ts_min((vwap - close), 3))) *rank(delta(volume, 3)))
    def alpha011(self):
        return ((rank(ts_max((self.vwap - self.close), 3)) + rank(ts_min((self.vwap - self.close), 3))) *rank(delta(self.volume, 3)))
    
    # Alpha#12	 (sign(delta(volume, 1)) * (-1 * delta(close, 1)))
    def alpha012(self):
        return sign(delta(self.volume, 1)) * (-1 * delta(self.close, 1))

    # Alpha#13	 (-1 * rank(covariance(rank(close), rank(volume), 5)))
    def alpha013(self):
        return -1 * rank(covariance(rank(self.close), rank(self.volume), 5))
    
    # Alpha#14	 ((-1 * rank(delta(returns, 3))) * correlation(open, volume, 10))
    def alpha014(self):
        df = correlation(self.open, self.volume, 10)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * rank(delta(self.returns, 3)) * df
    
    # Alpha#15	 (-1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3))
    def alpha015(self):
        df = correlation(rank(self.high), rank(self.volume), 3)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * ts_sum(rank(df), 3)
    
    # Alpha#16	 (-1 * rank(covariance(rank(high), rank(volume), 5)))
    def alpha016(self):
        return -1 * rank(covariance(rank(self.high), rank(self.volume), 5))
    
    # Alpha#17	 (((-1 * rank(ts_rank(close, 10))) * rank(delta(delta(close, 1), 1))) *rank(ts_rank((volume / adv20), 5)))
    def alpha017(self):
        adv20 = sma(self.volume, 20)
        return -1 * (rank(ts_rank(self.close, 10)) *
                     rank(delta(delta(self.close, 1), 1)) *
                     rank(ts_rank((self.volume / adv20), 5)))
        
    # Alpha#18	 (-1 * rank(((stddev(abs((close - open)), 5) + (close - open)) + correlation(close, open,10))))
    def alpha018(self):
        df = correlation(self.close, self.open, 10)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * (rank((stddev(abs((self.close - self.open)), 5) + (self.close - self.open)) +
                          df))
    
    # Alpha#19	 ((-1 * sign(((close - delay(close, 7)) + delta(close, 7)))) * (1 + rank((1 + sum(returns,250)))))
    def alpha019(self):
        return ((-1 * sign((self.close - delay(self.close, 7)) + delta(self.close, 7))) *
                (1 + rank(1 + ts_sum(self.returns, 250))))
    
    # Alpha#20	 (((-1 * rank((open - delay(high, 1)))) * rank((open - delay(close, 1)))) * rank((open -delay(low, 1))))
    def alpha020(self):
        return -1 * (rank(self.open - delay(self.high, 1)) *
                     rank(self.open - delay(self.close, 1)) *
                     rank(self.open - delay(self.low, 1)))

    # Alpha#21	 ((((sum(close, 8) / 8) + stddev(close, 8)) < (sum(close, 2) / 2)) ? (-1 * 1) : (((sum(close,2) / 2) < ((sum(close, 8) / 8) - stddev(close, 8))) ? 1 : (((1 < (volume / adv20)) || ((volume /adv20) == 1)) ? 1 : (-1 * 1))))
    def alpha021(self):
        cond_1 = sma(self.close, 8) + stddev(self.close, 8) < sma(self.close, 2)
        cond_2 = sma(self.volume, 20) / self.volume < 1
        alpha = pd.DataFrame(np.ones_like(self.close), index=self.close.index
                             )
#        alpha = pd.DataFrame(np.ones_like(self.close), index=self.close.index,
#                             columns=self.close.columns)
        alpha[cond_1 | cond_2] = -1
        return alpha
    
    # Alpha#22	 (-1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20))))
    def alpha022(self):
        df = correlation(self.high, self.volume, 5)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * delta(df, 5) * rank(stddev(self.close, 20))

    # Alpha#23	 (((sum(high, 20) / 20) < high) ? (-1 * delta(high, 2)) : 0)
    def alpha023(self):
        cond = sma(self.high, 20) < self.high
        alpha = pd.DataFrame(np.zeros_like(self.close),index=self.close.index,columns=['close'])
        alpha.at[cond,'close'] = -1 * delta(self.high, 2).fillna(value=0)
        return alpha
    
    # Alpha#24	 ((((delta((sum(close, 100) / 100), 100) / delay(close, 100)) < 0.05) ||((delta((sum(close, 100) / 100), 100) / delay(close, 100)) == 0.05)) ? (-1 * (close - ts_min(close,100))) : (-1 * delta(close, 3)))
    def alpha024(self):
        cond = delta(sma(self.close, 100), 100) / delay(self.close, 100) <= 0.05
        alpha = -1 * delta(self.close, 3)
        alpha[cond] = -1 * (self.close - ts_min(self.close, 100))
        return alpha
    
    # Alpha#25	 rank(((((-1 * returns) * adv20) * vwap) * (high - close)))
    def alpha025(self):
        adv20 = sma(self.volume, 20)
        return rank(((((-1 * self.returns) * adv20) * self.vwap) * (self.high - self.close)))
    
    # Alpha#26	 (-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3))
    def alpha026(self):
        df = correlation(ts_rank(self.volume, 5), ts_rank(self.high, 5), 5)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * ts_max(df, 3)
    
    # Alpha#27	 ((0.5 < rank((sum(correlation(rank(volume), rank(vwap), 6), 2) / 2.0))) ? (-1 * 1) : 1)
    ###
    ## Some Error, still fixing!!
    def alpha027(self):
        alpha = rank((sma(correlation(rank(self.volume), rank(self.vwap), 6), 2) / 2.0))
        alpha[alpha > 0.5] = -1
        alpha[alpha <= 0.5]=1
        return alpha  
    
    # Alpha#28	 scale(((correlation(adv20, low, 5) + ((high + low) / 2)) - close))
    def alpha028(self):
        adv20 = sma(self.volume, 20)
        df = correlation(adv20, self.low, 5)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return scale(((df + ((self.high + self.low) / 2)) - self.close))

    # Alpha#29	 (min(product(rank(rank(scale(log(sum(ts_min(rank(rank((-1 * rank(delta((close - 1),5))))), 2), 1))))), 1), 5) + ts_rank(delay((-1 * returns), 6), 5))
    def alpha029(self):
        return (ts_min(rank(rank(scale(log(ts_sum(rank(rank(-1 * rank(delta((self.close - 1), 5)))), 2))))), 5) +
                ts_rank(delay((-1 * self.returns), 6), 5))

    # Alpha#30	 (((1.0 - rank(((sign((close - delay(close, 1))) + sign((delay(close, 1) - delay(close, 2)))) +sign((delay(close, 2) - delay(close, 3)))))) * sum(volume, 5)) / sum(volume, 20))
    def alpha030(self):
        delta_close = delta(self.close, 1)
        inner = sign(delta_close) + sign(delay(delta_close, 1)) + sign(delay(delta_close, 2))
        return ((1.0 - rank(inner)) * ts_sum(self.volume, 5)) / ts_sum(self.volume, 20)

    # Alpha#31	 ((rank(rank(rank(decay_linear((-1 * rank(rank(delta(close, 10)))), 10)))) + rank((-1 *delta(close, 3)))) + sign(scale(correlation(adv20, low, 12))))
    def alpha031(self):
        adv20 = sma(self.volume, 20)
        df = correlation(adv20, self.low, 12).replace([-np.inf, np.inf], 0).fillna(value=0)         
        p1=rank(rank(rank(decay_linear((-1 * rank(rank(delta(self.close, 10)))).to_frame(), 10)))) 
        p2=rank((-1 * delta(self.close, 3)))
        p3=sign(scale(df))
        
        return p1.CLOSE+p2+p3

    # Alpha#32	 (scale(((sum(close, 7) / 7) - close)) + (20 * scale(correlation(vwap, delay(close, 5),230))))
    def alpha032(self):
        return scale(((sma(self.close, 7) / 7) - self.close)) + (20 * scale(correlation(self.vwap, delay(self.close, 5),230)))
    
    # Alpha#33	 rank((-1 * ((1 - (open / close))^1)))
    def alpha033(self):
        return rank(-1 + (self.open / self.close))
    
    # Alpha#34	 rank(((1 - rank((stddev(returns, 2) / stddev(returns, 5)))) + (1 - rank(delta(close, 1)))))
    def alpha034(self):
        inner = stddev(self.returns, 2) / stddev(self.returns, 5)
        inner = inner.replace([-np.inf, np.inf], 1).fillna(value=1)
        return rank(2 - rank(inner) - rank(delta(self.close, 1)))

    # Alpha#35	 ((Ts_Rank(volume, 32) * (1 - Ts_Rank(((close + high) - low), 16))) * (1 -Ts_Rank(returns, 32)))
    def alpha035(self):
        return ((ts_rank(self.volume, 32) *
                 (1 - ts_rank(self.close + self.high - self.low, 16))) *
                (1 - ts_rank(self.returns, 32)))
            
    # Alpha#36	 (((((2.21 * rank(correlation((close - open), delay(volume, 1), 15))) + (0.7 * rank((open- close)))) + (0.73 * rank(Ts_Rank(delay((-1 * returns), 6), 5)))) + rank(abs(correlation(vwap,adv20, 6)))) + (0.6 * rank((((sum(close, 200) / 200) - open) * (close - open)))))
    def alpha036(self):
        adv20 = sma(self.volume, 20)
        return (((((2.21 * rank(correlation((self.close - self.open), delay(self.volume, 1), 15))) + (0.7 * rank((self.open- self.close)))) + (0.73 * rank(ts_rank(delay((-1 * self.returns), 6), 5)))) + rank(abs(correlation(self.vwap,adv20, 6)))) + (0.6 * rank((((sma(self.close, 200) / 200) - self.open) * (self.close - self.open)))))
    
    # Alpha#37	 (rank(correlation(delay((open - close), 1), close, 200)) + rank((open - close)))
    def alpha037(self):
        return rank(correlation(delay(self.open - self.close, 1), self.close, 200)) + rank(self.open - self.close)
    
    # Alpha#38	 ((-1 * rank(Ts_Rank(close, 10))) * rank((close / open)))
    def alpha038(self):
        inner = self.close / self.open
        inner = inner.replace([-np.inf, np.inf], 1).fillna(value=1)
        return -1 * rank(ts_rank(self.open, 10)) * rank(inner)
    
    # Alpha#39	 ((-1 * rank((delta(close, 7) * (1 - rank(decay_linear((volume / adv20), 9)))))) * (1 +rank(sum(returns, 250))))
    def alpha039(self):
        adv20 = sma(self.volume, 20)
        return ((-1 * rank(delta(self.close, 7) * (1 - rank(decay_linear((self.volume / adv20).to_frame(), 9).CLOSE)))) *
                (1 + rank(sma(self.returns, 250))))
    
    # Alpha#40	 ((-1 * rank(stddev(high, 10))) * correlation(high, volume, 10))
    def alpha040(self):
        return -1 * rank(stddev(self.high, 10)) * correlation(self.high, self.volume, 10)

    # Alpha#41	 (((high * low)^0.5) - vwap)
    def alpha041(self):
        return pow((self.high * self.low),0.5) - self.vwap
    
    # Alpha#42	 (rank((vwap - close)) / rank((vwap + close)))
    def alpha042(self):
        return rank((self.vwap - self.close)) / rank((self.vwap + self.close))
        
    # Alpha#43	 (ts_rank((volume / adv20), 20) * ts_rank((-1 * delta(close, 7)), 8))
    def alpha043(self):
        adv20 = sma(self.volume, 20)
        return ts_rank(self.volume / adv20, 20) * ts_rank((-1 * delta(self.close, 7)), 8)

    # Alpha#44	 (-1 * correlation(high, rank(volume), 5))
    def alpha044(self):
        df = correlation(self.high, rank(self.volume), 5)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * df

    # Alpha#45	 (-1 * ((rank((sum(delay(close, 5), 20) / 20)) * correlation(close, volume, 2)) *rank(correlation(sum(close, 5), sum(close, 20), 2))))
    def alpha045(self):
        df = correlation(self.close, self.volume, 2)
        df = df.replace([-np.inf, np.inf], 0).fillna(value=0)
        return -1 * (rank(sma(delay(self.close, 5), 20)) * df *
                     rank(correlation(ts_sum(self.close, 5), ts_sum(self.close, 20), 2)))
    
    # Alpha#46	 ((0.25 < (((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10))) ?(-1 * 1) : (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < 0) ? 1 :((-1 * 1) * (close - delay(close, 1)))))
    def alpha046(self):
        inner = ((delay(self.close, 20) - delay(self.close, 10)) / 10) - ((delay(self.close, 10) - self.close) / 10)
        alpha = (-1 * delta(self.close))
        alpha[inner < 0] = 1
        alpha[inner > 0.25] = -1
        return alpha

    # Alpha#47	 ((((rank((1 / close)) * volume) / adv20) * ((high * rank((high - close))) / (sum(high, 5) /5))) - rank((vwap - delay(vwap, 5))))
    def alpha047(self):
        adv20 = sma(self.volume, 20)
        return ((((rank((1 / self.close)) * self.volume) / adv20) * ((self.high * rank((self.high - self.close))) / (sma(self.high, 5) /5))) - rank((self.vwap - delay(self.vwap, 5))))
    
    # Alpha#48	 (indneutralize(((correlation(delta(close, 1), delta(delay(close, 1), 1), 250) *delta(close, 1)) / close), IndClass.subindustry) / sum(((delta(close, 1) / delay(close, 1))^2), 250))
     
    
    # Alpha#49	 (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < (-1 *0.1)) ? 1 : ((-1 * 1) * (close - delay(close, 1))))
    def alpha049(self):
        inner = (((delay(self.close, 20) - delay(self.close, 10)) / 10) - ((delay(self.close, 10) - self.close) / 10))
        alpha = (-1 * delta(self.close))
        alpha[inner < -0.1] = 1
        return alpha
    
    # Alpha#50	 (-1 * ts_max(rank(correlation(rank(volume), rank(vwap), 5)), 5))
    def alpha050(self):
        return (-1 * ts_max(rank(correlation(rank(self.volume), rank(self.vwap), 5)), 5))
    
    # Alpha#51	 (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < (-1 *0.05)) ? 1 : ((-1 * 1) * (close - delay(close, 1))))
    def alpha051(self):
        inner = (((delay(self.close, 20) - delay(self.close, 10)) / 10) - ((delay(self.close, 10) - self.close) / 10))
        alpha = (-1 * delta(self.close))
        alpha[inner < -0.05] = 1
        return alpha
    
    # Alpha#52	 ((((-1 * ts_min(low, 5)) + delay(ts_min(low, 5), 5)) * rank(((sum(returns, 240) -sum(returns, 20)) / 220))) * ts_rank(volume, 5))
    def alpha052(self):
        return (((-1 * delta(ts_min(self.low, 5), 5)) *
                 rank(((ts_sum(self.returns, 240) - ts_sum(self.returns, 20)) / 220))) * ts_rank(self.volume, 5))
        
    # Alpha#53	 (-1 * delta((((close - low) - (high - close)) / (close - low)), 9))
    def alpha053(self):
        inner = (self.close - self.low).replace(0, 0.0001)
        return -1 * delta((((self.close - self.low) - (self.high - self.close)) / inner), 9)

    # Alpha#54	 ((-1 * ((low - close) * (open^5))) / ((low - high) * (close^5)))
    def alpha054(self):
        inner = (self.low - self.high).replace(0, -0.0001)
        return -1 * (self.low - self.close) * (self.open ** 5) / (inner * (self.close ** 5))

    # Alpha#55	 (-1 * correlation(rank(((close - ts_min(low, 12)) / (ts_max(high, 12) - ts_min(low,12)))), rank(volume), 6))
    def alpha055(self):
        divisor = (ts_max(self.high, 12) - ts_min(self.low, 12)).replace(0, 0.0001)
        inner = (self.close - ts_min(self.low, 12)) / (divisor)
        df = correlation(rank(inner), rank(self.volume), 6)
        return -1 * df.replace([-np.inf, np.inf], 0).fillna(value=0)

    # Alpha#56	 (0 - (1 * (rank((sum(returns, 10) / sum(sum(returns, 2), 3))) * rank((returns * cap)))))
    # This Alpha uses the Cap, however I have not acquired the data yet
#    def alpha056(self):
#        return (0 - (1 * (rank((sma(self.returns, 10) / sma(sma(self.returns, 2), 3))) * rank((self.returns * self.cap)))))
    
    # Alpha#57	 (0 - (1 * ((close - vwap) / decay_linear(rank(ts_argmax(close, 30)), 2))))
    def alpha057(self):
        return (0 - (1 * ((self.close - self.vwap) / decay_linear(rank(ts_argmax(self.close, 30)).to_frame(), 2).CLOSE)))
    
    # Alpha#58	 (-1 * Ts_Rank(decay_linear(correlation(IndNeutralize(vwap, IndClass.sector), volume,3.92795), 7.89291), 5.50322))
     
    # Alpha#59	 (-1 * Ts_Rank(decay_linear(correlation(IndNeutralize(((vwap * 0.728317) + (vwap *(1 - 0.728317))), IndClass.industry), volume, 4.25197), 16.2289), 8.19648))
     
    
    # Alpha#60	 (0 - (1 * ((2 * scale(rank(((((close - low) - (high - close)) / (high - low)) * volume)))) -scale(rank(ts_argmax(close, 10))))))
    def alpha060(self):
        divisor = (self.high - self.low).replace(0, 0.0001)
        inner = ((self.close - self.low) - (self.high - self.close)) * self.volume / divisor
        return - ((2 * scale(rank(inner))) - scale(rank(ts_argmax(self.close, 10))))
    
	# Alpha#61	 (rank((vwap - ts_min(vwap, 16.1219))) < rank(correlation(vwap, adv180, 17.9282)))
    def alpha061(self):
        adv180 = sma(self.volume, 180)
        return (rank((self.vwap - ts_min(self.vwap, 16))) < rank(correlation(self.vwap, adv180, 18)))
    
	# Alpha#62	 ((rank(correlation(vwap, sum(adv20, 22.4101), 9.91009)) < rank(((rank(open) +rank(open)) < (rank(((high + low) / 2)) + rank(high))))) * -1)
    def alpha062(self):
        adv20 = sma(self.volume, 20)
        return ((rank(correlation(self.vwap, sma(adv20, 22), 10)) < rank(((rank(self.open) +rank(self.open)) < (rank(((self.high + self.low) / 2)) + rank(self.high))))) * -1)
    
    # Alpha#63	 ((rank(decay_linear(delta(IndNeutralize(close, IndClass.industry), 2.25164), 8.22237))- rank(decay_linear(correlation(((vwap * 0.318108) + (open * (1 - 0.318108))), sum(adv180,37.2467), 13.557), 12.2883))) * -1)
     
    
    # Alpha#64	 ((rank(correlation(sum(((open * 0.178404) + (low * (1 - 0.178404))), 12.7054),sum(adv120, 12.7054), 16.6208)) < rank(delta(((((high + low) / 2) * 0.178404) + (vwap * (1 -0.178404))), 3.69741))) * -1)
    def alpha064(self):
        adv120 = sma(self.volume, 120)
        return ((rank(correlation(sma(((self.open * 0.178404) + (self.low * (1 - 0.178404))), 13),sma(adv120, 13), 17)) < rank(delta(((((self.high + self.low) / 2) * 0.178404) + (self.vwap * (1 -0.178404))), 3.69741))) * -1)
    
    # Alpha#65	 ((rank(correlation(((open * 0.00817205) + (vwap * (1 - 0.00817205))), sum(adv60,8.6911), 6.40374)) < rank((open - ts_min(open, 13.635)))) * -1)
    def alpha065(self):
        adv60 = sma(self.volume, 60)
        return ((rank(correlation(((self.open * 0.00817205) + (self.vwap * (1 - 0.00817205))), sma(adv60,9), 6)) < rank((self.open - ts_min(self.open, 14)))) * -1)
      
    # Alpha#66	 ((rank(decay_linear(delta(vwap, 3.51013), 7.23052)) + Ts_Rank(decay_linear(((((low* 0.96633) + (low * (1 - 0.96633))) - vwap) / (open - ((high + low) / 2))), 11.4157), 6.72611)) * -1)
    def alpha066(self):
        return ((rank(decay_linear(delta(self.vwap, 4).to_frame(), 7).CLOSE) + ts_rank(decay_linear(((((self.low* 0.96633) + (self.low * (1 - 0.96633))) - self.vwap) / (self.open - ((self.high + self.low) / 2))).to_frame(), 11).CLOSE, 7)) * -1)
    
    # Alpha#67	 ((rank((high - ts_min(high, 2.14593)))^rank(correlation(IndNeutralize(vwap,IndClass.sector), IndNeutralize(adv20, IndClass.subindustry), 6.02936))) * -1)
     
    
    # Alpha#68	 ((Ts_Rank(correlation(rank(high), rank(adv15), 8.91644), 13.9333) <rank(delta(((close * 0.518371) + (low * (1 - 0.518371))), 1.06157))) * -1)
    def alpha068(self):
        adv15 = sma(self.volume, 15)
        return ((ts_rank(correlation(rank(self.high), rank(adv15), 9), 14) <rank(delta(((self.close * 0.518371) + (self.low * (1 - 0.518371))), 1.06157))) * -1)
    
    # Alpha#69	 ((rank(ts_max(delta(IndNeutralize(vwap, IndClass.industry), 2.72412),4.79344))^Ts_Rank(correlation(((close * 0.490655) + (vwap * (1 - 0.490655))), adv20, 4.92416),9.0615)) * -1)
         
    # Alpha#70	 ((rank(delta(vwap, 1.29456))^Ts_Rank(correlation(IndNeutralize(close,IndClass.industry), adv50, 17.8256), 17.9171)) * -1)
     
    
    # Alpha#71	 max(Ts_Rank(decay_linear(correlation(Ts_Rank(close, 3.43976), Ts_Rank(adv180,12.0647), 18.0175), 4.20501), 15.6948), Ts_Rank(decay_linear((rank(((low + open) - (vwap +vwap)))^2), 16.4662), 4.4388))
    def alpha071(self):
        adv180 = sma(self.volume, 180)
        p1=ts_rank(decay_linear(correlation(ts_rank(self.close, 3), ts_rank(adv180,12), 18).to_frame(), 4).CLOSE, 16)
        p2=ts_rank(decay_linear((rank(((self.low + self.open) - (self.vwap +self.vwap))).pow(2)).to_frame(), 16).CLOSE, 4)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'max']=df['p1']
        df.at[df['p2']>=df['p1'],'max']=df['p2']
        return df['max']
        #return max(ts_rank(decay_linear(correlation(ts_rank(self.close, 3), ts_rank(adv180,12), 18).to_frame(), 4).CLOSE, 16), ts_rank(decay_linear((rank(((self.low + self.open) - (self.vwap +self.vwap))).pow(2)).to_frame(), 16).CLOSE, 4))
    
    # Alpha#72	 (rank(decay_linear(correlation(((high + low) / 2), adv40, 8.93345), 10.1519)) /rank(decay_linear(correlation(Ts_Rank(vwap, 3.72469), Ts_Rank(volume, 18.5188), 6.86671),2.95011)))
    def alpha072(self):
        adv40 = sma(self.volume, 40)
        return (rank(decay_linear(correlation(((self.high + self.low) / 2), adv40, 9).to_frame(), 10).CLOSE) /rank(decay_linear(correlation(ts_rank(self.vwap, 4), ts_rank(self.volume, 19), 7).to_frame(),3).CLOSE))
    
    # Alpha#73	 (max(rank(decay_linear(delta(vwap, 4.72775), 2.91864)),Ts_Rank(decay_linear(((delta(((open * 0.147155) + (low * (1 - 0.147155))), 2.03608) / ((open *0.147155) + (low * (1 - 0.147155)))) * -1), 3.33829), 16.7411)) * -1)
    def alpha073(self):
        p1=rank(decay_linear(delta(self.vwap, 5).to_frame(), 3).CLOSE)
        p2=ts_rank(decay_linear(((delta(((self.open * 0.147155) + (self.low * (1 - 0.147155))), 2) / ((self.open *0.147155) + (self.low * (1 - 0.147155)))) * -1).to_frame(), 3).CLOSE, 17)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'max']=df['p1']
        df.at[df['p2']>=df['p1'],'max']=df['p2']
        return -1*df['max']
        #return (max(rank(decay_linear(delta(self.vwap, 5).to_frame(), 3).CLOSE),ts_rank(decay_linear(((delta(((self.open * 0.147155) + (self.low * (1 - 0.147155))), 2) / ((self.open *0.147155) + (self.low * (1 - 0.147155)))) * -1).to_frame(), 3).CLOSE, 17)) * -1)
    
    # Alpha#74	 ((rank(correlation(close, sum(adv30, 37.4843), 15.1365)) <rank(correlation(rank(((high * 0.0261661) + (vwap * (1 - 0.0261661)))), rank(volume), 11.4791)))* -1)
    def alpha074(self):
        adv30 = sma(self.volume, 30)
        return ((rank(correlation(self.close, sma(adv30, 37), 15)) <rank(correlation(rank(((self.high * 0.0261661) + (self.vwap * (1 - 0.0261661)))), rank(self.volume), 11)))* -1)
    
    # Alpha#75	 (rank(correlation(vwap, volume, 4.24304)) < rank(correlation(rank(low), rank(adv50),12.4413)))
    def alpha075(self):
        adv50 = sma(self.volume, 50)
        return (rank(correlation(self.vwap, self.volume, 4)) < rank(correlation(rank(self.low), rank(adv50),12)))
    
    # Alpha#76	 (max(rank(decay_linear(delta(vwap, 1.24383), 11.8259)),Ts_Rank(decay_linear(Ts_Rank(correlation(IndNeutralize(low, IndClass.sector), adv81,8.14941), 19.569), 17.1543), 19.383)) * -1)
     

    # Alpha#77	 min(rank(decay_linear(((((high + low) / 2) + high) - (vwap + high)), 20.0451)),rank(decay_linear(correlation(((high + low) / 2), adv40, 3.1614), 5.64125)))
    def alpha077(self):
        adv40 = sma(self.volume, 40)
        p1=rank(decay_linear(((((self.high + self.low) / 2) + self.high) - (self.vwap + self.high)).to_frame(), 20).CLOSE)
        p2=rank(decay_linear(correlation(((self.high + self.low) / 2), adv40, 3).to_frame(), 6).CLOSE)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'min']=df['p2']
        df.at[df['p2']>=df['p1'],'min']=df['p1']
        return df['min']
        #return min(rank(decay_linear(((((self.high + self.low) / 2) + self.high) - (self.vwap + self.high)).to_frame(), 20).CLOSE),rank(decay_linear(correlation(((self.high + self.low) / 2), adv40, 3).to_frame(), 6).CLOSE))
    
    # Alpha#78	 (rank(correlation(sum(((low * 0.352233) + (vwap * (1 - 0.352233))), 19.7428),sum(adv40, 19.7428), 6.83313))^rank(correlation(rank(vwap), rank(volume), 5.77492)))
    def alpha078(self):
        adv40 = sma(self.volume, 40)
        return (rank(correlation(ts_sum(((self.low * 0.352233) + (self.vwap * (1 - 0.352233))), 20),ts_sum(adv40,20), 7)).pow(rank(correlation(rank(self.vwap), rank(self.volume), 6))))
    
    # Alpha#79	 (rank(delta(IndNeutralize(((close * 0.60733) + (open * (1 - 0.60733))),IndClass.sector), 1.23438)) < rank(correlation(Ts_Rank(vwap, 3.60973), Ts_Rank(adv150,9.18637), 14.6644)))
     
    # Alpha#80	 ((rank(Sign(delta(IndNeutralize(((open * 0.868128) + (high * (1 - 0.868128))),IndClass.industry), 4.04545)))^Ts_Rank(correlation(high, adv10, 5.11456), 5.53756)) * -1)
     
   
    # Alpha#81	 ((rank(Log(product(rank((rank(correlation(vwap, sum(adv10, 49.6054),8.47743))^4)), 14.9655))) < rank(correlation(rank(vwap), rank(volume), 5.07914))) * -1)
    def alpha081(self):
        adv10 = sma(self.volume, 10)
        return ((rank(log(product(rank((rank(correlation(self.vwap, ts_sum(adv10, 50),8)).pow(4))), 15))) < rank(correlation(rank(self.vwap), rank(self.volume), 5))) * -1)
    
    # Alpha#82	 (min(rank(decay_linear(delta(open, 1.46063), 14.8717)),Ts_Rank(decay_linear(correlation(IndNeutralize(volume, IndClass.sector), ((open * 0.634196) +(open * (1 - 0.634196))), 17.4842), 6.92131), 13.4283)) * -1)
     
    
    # Alpha#83	 ((rank(delay(((high - low) / (sum(close, 5) / 5)), 2)) * rank(rank(volume))) / (((high -low) / (sum(close, 5) / 5)) / (vwap - close)))
    def alpha083(self):
        return ((rank(delay(((self.high - self.low) / (ts_sum(self.close, 5) / 5)), 2)) * rank(rank(self.volume))) / (((self.high -self.low) / (ts_sum(self.close, 5) / 5)) / (self.vwap - self.close)))
    
    # Alpha#84	 SignedPower(Ts_Rank((vwap - ts_max(vwap, 15.3217)), 20.7127), delta(close,4.96796))
    def alpha084(self):
        return pow(ts_rank((self.vwap - ts_max(self.vwap, 15)), 21), delta(self.close,5))
    
    # Alpha#85	 (rank(correlation(((high * 0.876703) + (close * (1 - 0.876703))), adv30,9.61331))^rank(correlation(Ts_Rank(((high + low) / 2), 3.70596), Ts_Rank(volume, 10.1595),7.11408)))
    def alpha085(self):
        adv30 = sma(self.volume, 30)
        return (rank(correlation(((self.high * 0.876703) + (self.close * (1 - 0.876703))), adv30,10)).pow(rank(correlation(ts_rank(((self.high + self.low) / 2), 4), ts_rank(self.volume, 10),7))))
    
    # Alpha#86	 ((Ts_Rank(correlation(close, sum(adv20, 14.7444), 6.00049), 20.4195) < rank(((open+ close) - (vwap + open)))) * -1)

    def alpha086(self):
        adv20 = sma(self.volume, 20)
        return ((ts_rank(correlation(self.close, sma(adv20, 15), 6), 20) < rank(((self.open+ self.close) - (self.vwap +self.open)))) * -1)
    
    # Alpha#87	 (max(rank(decay_linear(delta(((close * 0.369701) + (vwap * (1 - 0.369701))),1.91233), 2.65461)), Ts_Rank(decay_linear(abs(correlation(IndNeutralize(adv81,IndClass.industry), close, 13.4132)), 4.89768), 14.4535)) * -1)
     
    
    # Alpha#88	 min(rank(decay_linear(((rank(open) + rank(low)) - (rank(high) + rank(close))),8.06882)), Ts_Rank(decay_linear(correlation(Ts_Rank(close, 8.44728), Ts_Rank(adv60,20.6966), 8.01266), 6.65053), 2.61957))
    def alpha088(self):
        adv60 = sma(self.volume, 60)
        p1=rank(decay_linear(((rank(self.open) + rank(self.low)) - (rank(self.high) + rank(self.close))).to_frame(),8).CLOSE)
        p2=ts_rank(decay_linear(correlation(ts_rank(self.close, 8), ts_rank(adv60,21), 8).to_frame(), 7).CLOSE, 3)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'min']=df['p2']
        df.at[df['p2']>=df['p1'],'min']=df['p1']
        return df['min']
        #return min(rank(decay_linear(((rank(self.open) + rank(self.low)) - (rank(self.high) + rank(self.close))).to_frame(),8).CLOSE), ts_rank(decay_linear(correlation(ts_rank(self.close, 8), ts_rank(adv60,20.6966), 8).to_frame(), 7).CLOSE, 3))
    
    # Alpha#89	 (Ts_Rank(decay_linear(correlation(((low * 0.967285) + (low * (1 - 0.967285))), adv10,6.94279), 5.51607), 3.79744) - Ts_Rank(decay_linear(delta(IndNeutralize(vwap,IndClass.industry), 3.48158), 10.1466), 15.3012))
     
    # Alpha#90	 ((rank((close - ts_max(close, 4.66719)))^Ts_Rank(correlation(IndNeutralize(adv40,IndClass.subindustry), low, 5.38375), 3.21856)) * -1)
     
    # Alpha#91	 ((Ts_Rank(decay_linear(decay_linear(correlation(IndNeutralize(close,IndClass.industry), volume, 9.74928), 16.398), 3.83219), 4.8667) -rank(decay_linear(correlation(vwap, adv30, 4.01303), 2.6809))) * -1)
     

    # Alpha#92	 min(Ts_Rank(decay_linear(((((high + low) / 2) + close) < (low + open)), 14.7221),18.8683), Ts_Rank(decay_linear(correlation(rank(low), rank(adv30), 7.58555), 6.94024),6.80584))
    def alpha092(self):
        adv30 = sma(self.volume, 30)
        p1=ts_rank(decay_linear(((((self.high + self.low) / 2) + self.close) < (self.low + self.open)).to_frame(), 15).CLOSE,19)
        p2=ts_rank(decay_linear(correlation(rank(self.low), rank(adv30), 8).to_frame(), 7).CLOSE,7)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'min']=df['p2']
        df.at[df['p2']>=df['p1'],'min']=df['p1']
        return df['min']
        #return  min(ts_rank(decay_linear(((((self.high + self.low) / 2) + self.close) < (self.low + self.open)).to_frame(), 15).CLOSE,19), ts_rank(decay_linear(correlation(rank(self.low), rank(adv30), 8).to_frame(), 7).CLOSE,7))
    
    # Alpha#93	 (Ts_Rank(decay_linear(correlation(IndNeutralize(vwap, IndClass.industry), adv81,17.4193), 19.848), 7.54455) / rank(decay_linear(delta(((close * 0.524434) + (vwap * (1 -0.524434))), 2.77377), 16.2664)))
     
    
    # Alpha#94	 ((rank((vwap - ts_min(vwap, 11.5783)))^Ts_Rank(correlation(Ts_Rank(vwap,19.6462), Ts_Rank(adv60, 4.02992), 18.0926), 2.70756)) * -1)
    def alpha094(self):
        adv60 = sma(self.volume, 60)
        return ((rank((self.vwap - ts_min(self.vwap, 12))).pow(ts_rank(correlation(ts_rank(self.vwap,20), ts_rank(adv60, 4), 18), 3)) * -1))
    
    # Alpha#95	 (rank((open - ts_min(open, 12.4105))) < Ts_Rank((rank(correlation(sum(((high + low)/ 2), 19.1351), sum(adv40, 19.1351), 12.8742))^5), 11.7584))
    def alpha095(self):
        adv40 = sma(self.volume, 40)
        return (rank((self.open - ts_min(self.open, 12))) < ts_rank((rank(correlation(sma(((self.high + self.low)/ 2), 19), sma(adv40, 19), 13)).pow(5)), 12))
    
    # Alpha#96	 (max(Ts_Rank(decay_linear(correlation(rank(vwap), rank(volume), 3.83878),4.16783), 8.38151), Ts_Rank(decay_linear(Ts_ArgMax(correlation(Ts_Rank(close, 7.45404),Ts_Rank(adv60, 4.13242), 3.65459), 12.6556), 14.0365), 13.4143)) * -1)
    def alpha096(self):
        adv60 = sma(self.volume, 60)
        p1=ts_rank(decay_linear(correlation(rank(self.vwap), rank(self.volume).to_frame(), 4),4).CLOSE, 8)
        p2=ts_rank(decay_linear(ts_argmax(correlation(ts_rank(self.close, 7),ts_rank(adv60, 4), 4), 13).to_frame(), 14).CLOSE, 13)
        df=pd.DataFrame({'p1':p1,'p2':p2})
        df.at[df['p1']>=df['p2'],'max']=df['p1']
        df.at[df['p2']>=df['p1'],'max']=df['p2']
        return -1*df['max']
        #return (max(ts_rank(decay_linear(correlation(rank(self.vwap), rank(self.volume).to_frame(), 4),4).CLOSE, 8), ts_rank(decay_linear(ts_argmax(correlation(ts_rank(self.close, 7),ts_rank(adv60, 4), 4), 13).to_frame(), 14).CLOSE, 13)) * -1)
    
    # Alpha#97	 ((rank(decay_linear(delta(IndNeutralize(((low * 0.721001) + (vwap * (1 - 0.721001))),IndClass.industry), 3.3705), 20.4523)) - Ts_Rank(decay_linear(Ts_Rank(correlation(Ts_Rank(low,7.87871), Ts_Rank(adv60, 17.255), 4.97547), 18.5925), 15.7152), 6.71659)) * -1)
     
    
    # Alpha#98	 (rank(decay_linear(correlation(vwap, sum(adv5, 26.4719), 4.58418), 7.18088)) -rank(decay_linear(Ts_Rank(Ts_ArgMin(correlation(rank(open), rank(adv15), 20.8187), 8.62571),6.95668), 8.07206)))
    def alpha098(self):
        adv5 = sma(self.volume, 5)
        adv15 = sma(self.volume, 15)
        return (rank(decay_linear(correlation(self.vwap, sma(adv5, 26), 5).to_frame(), 7).CLOSE) -rank(decay_linear(ts_rank(ts_argmin(correlation(rank(self.open), rank(adv15), 21), 9),7).to_frame(), 8).CLOSE))
    
    # Alpha#99	 ((rank(correlation(sum(((high + low) / 2), 19.8975), sum(adv60, 19.8975), 8.8136)) <rank(correlation(low, volume, 6.28259))) * -1)
    def alpha099(self):
        adv60 = sma(self.volume, 60)
        return ((rank(correlation(ts_sum(((self.high + self.low) / 2), 20), ts_sum(adv60, 20), 9)) <rank(correlation(self.low, self.volume, 6))) * -1)
    
    # Alpha#100	 (0 - (1 * (((1.5 * scale(indneutralize(indneutralize(rank(((((close - low) - (high -close)) / (high - low)) * volume)), IndClass.subindustry), IndClass.subindustry))) -scale(indneutralize((correlation(close, rank(adv20), 5) - rank(ts_argmin(close, 30))),IndClass.subindustry))) * (volume / adv20))))
     

    # Alpha#101	 ((close - open) / ((high - low) + .001))
    def alpha101(self):
        return (self.close - self.open) /((self.high - self.low) + 0.001)
     
     

================================================================================
File: .\alpha101_code\101Alpha_code_2.py
--------------------------------------------------------------------------------
import pandas as pd
import numpy as np
from scipy import stats 


 def make_factors():
        
            #  (rank(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5)
    class Alpha1(CustomFactor):
        inputs = [USEquityPricing.close, Returns(window_length=2)]
        window_length = 20

        def compute(self, today, assets, out, close, returns):
            v000 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v000000 = returns[-i0]
                v000001 = np.full(out.shape[0], 0.0)
                v00000 = v000000 < v000001
                v000010 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v000010[-i1] = returns[-i1]
                v00001 = np.std(v000010, axis=0)
                v00002 = close[-i0]
                v0000lgcl = np.empty(out.shape[0])
                v0000lgcl[v00000] = v00001[v00000]
                v0000lgcl[~v00000] = v00002[~v00000]
                v0000 = v0000lgcl
                v0001 = np.full(out.shape[0], 2.0)
                v000[-i0] = np.power(v0000, v0001)
            v00 = np.argmax(v000, axis=0)
            v0 = stats.rankdata(v00)
            v1 = np.full(out.shape[0], 0.5)
            out[:] = v0 - v1

    #  (-1 * correlation(rank(delta(log(volume), 2)), rank(((close - open) / open)), 6))
    class Alpha2(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close, USEquityPricing.open]
        window_length = 6

        def compute(self, today, assets, out, volume, close, open):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v1000 = np.empty((3, out.shape[0]))
                for i1 in range(1, 4):
                    v10000 = volume[-i1]
                    v1000[-i1] = np.log(v10000)
                v100 = v1000[-1] - v1000[-3]
                v10[-i0] = stats.rankdata(v100)
            v11 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v11000 = close[-i0]
                v11001 = open[-i0]
                v1100 = v11000 - v11001
                v1101 = open[-i0]
                v110 = v1100 / v1101
                v11[-i0] = stats.rankdata(v110)
            v1 = pd.DataFrame(v10).rolling(window=6).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * correlation(rank(open), rank(volume), 10))
    class Alpha3(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.open]
        window_length = 10

        def compute(self, today, assets, out, volume, open):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v100 = open[-i0]
                v10[-i0] = stats.rankdata(v100)
            v11 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v110 = volume[-i0]
                v11[-i0] = stats.rankdata(v110)
            v1 = pd.DataFrame(v10).rolling(window=10).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * Ts_Rank(rank(low), 9))
    class Alpha4(CustomFactor):
        inputs = [USEquityPricing.low]
        window_length = 9

        def compute(self, today, assets, out, low):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((9, out.shape[0]))
            for i0 in range(1, 10):
                v100 = low[-i0]
                v10[-i0] = stats.rankdata(v100)
            v1 = pd.DataFrame(v10).rank().tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap)))))
    class Alpha5(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.close, USEquityPricing.open, vwap_in]
        window_length = 10

        def compute(self, today, assets, out, close, open, vwap):
            v000 = open[-1]
            v00100 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v00100[-i0] = vwap[-i0]
            v0010 = v00100.sum(axis=0)
            v0011 = np.full(out.shape[0], 10.0)
            v001 = v0010 / v0011
            v00 = v000 - v001
            v0 = stats.rankdata(v00)
            v10 = np.full(out.shape[0], -1.0)
            v11000 = close[-1]
            v11001 = vwap[-1]
            v1100 = v11000 - v11001
            v110 = stats.rankdata(v1100)
            v11 = np.abs(v110)
            v1 = v10 * v11
            out[:] = v0 * v1

    #  (-1 * correlation(open, volume, 10))
    class Alpha6(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.open]
        window_length = 10

        def compute(self, today, assets, out, volume, open):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v10[-i0] = open[-i0]
            v11 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v11[-i0] = volume[-i0]
            v1 = pd.DataFrame(v10).rolling(window=10).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  ((adv20 < volume) ? ((-1 * ts_rank(abs(delta(close, 7)), 60)) * sign(delta(close, 7))) : (-1 * 1))
    class Alpha7(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, adv20_in]
        window_length = 60

        def compute(self, today, assets, out, volume, close, adv20):
            v00 = adv20[-1]
            v01 = volume[-1]
            v0 = v00 < v01
            v100 = np.full(out.shape[0], -1.0)
            v1010 = np.empty((60, out.shape[0]))
            for i0 in range(1, 61):
                v101000 = np.empty((8, out.shape[0]))
                for i1 in range(1, 9):
                    v101000[-i1] = close[-i1]
                v10100 = v101000[-1] - v101000[-8]
                v1010[-i0] = np.abs(v10100)
            v101 = pd.DataFrame(v1010).rank().tail(1).as_matrix()[-1]
            v10 = v100 * v101
            v1100 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v1100[-i0] = close[-i0]
            v110 = v1100[-1] - v1100[-8]
            v11 = np.sign(v110)
            v1 = v10 * v11
            v20 = np.full(out.shape[0], -1.0)
            v21 = np.full(out.shape[0], 1.0)
            v2 = v20 * v21
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  (-1 * rank(((sum(open, 5) * sum(returns, 5)) - delay((sum(open, 5) * sum(returns, 5)), 10))))
    class Alpha8(CustomFactor):
        inputs = [Returns(window_length=2), USEquityPricing.open]
        window_length = 15

        def compute(self, today, assets, out, returns, open):
            v0 = np.full(out.shape[0], -1.0)
            v10000 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v10000[-i0] = open[-i0]
            v1000 = v10000.sum(axis=0)
            v10010 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v10010[-i0] = returns[-i0]
            v1001 = v10010.sum(axis=0)
            v100 = v1000 * v1001
            v101000 = np.empty((5, out.shape[0]))
            for i0 in range(11, 16):
                v101000[10-i0] = open[-i0]
            v10100 = v101000.sum(axis=0)
            v101010 = np.empty((5, out.shape[0]))
            for i0 in range(11, 16):
                v101010[10-i0] = returns[-i0]
            v10101 = v101010.sum(axis=0)
            v1010 = v10100 * v10101
            v101 = v1010 # delay
            v10 = v100 - v101
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  ((0 < ts_min(delta(close, 1), 5)) ? delta(close, 1) : ((ts_max(delta(close, 1), 5) < 0) ? delta(close, 1) : (-1 * delta(close, 1))))
    class Alpha9(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 5

        def compute(self, today, assets, out, close):
            v00 = np.full(out.shape[0], 0.0)
            v010 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v0100 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v0100[-i1] = close[-i1]
                v010[-i0] = v0100[-1] - v0100[-2]
            v01 = np.min(v010, axis=0)
            v0 = v00 < v01
            v10 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v10[-i0] = close[-i0]
            v1 = v10[-1] - v10[-2]
            v2000 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v20000 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v20000[-i1] = close[-i1]
                v2000[-i0] = v20000[-1] - v20000[-2]
            v200 = np.max(v2000, axis=0)
            v201 = np.full(out.shape[0], 0.0)
            v20 = v200 < v201
            v210 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v210[-i0] = close[-i0]
            v21 = v210[-1] - v210[-2]
            v220 = np.full(out.shape[0], -1.0)
            v2210 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v2210[-i0] = close[-i0]
            v221 = v2210[-1] - v2210[-2]
            v22 = v220 * v221
            v2lgcl = np.empty(out.shape[0])
            v2lgcl[v20] = v21[v20]
            v2lgcl[~v20] = v22[~v20]
            v2 = v2lgcl
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  rank(((0 < ts_min(delta(close, 1), 4)) ? delta(close, 1) : ((ts_max(delta(close, 1), 4) < 0) ? delta(close, 1) : (-1 * delta(close, 1)))))
    class Alpha10(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 4

        def compute(self, today, assets, out, close):
            v000 = np.full(out.shape[0], 0.0)
            v0010 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v00100 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v00100[-i1] = close[-i1]
                v0010[-i0] = v00100[-1] - v00100[-2]
            v001 = np.min(v0010, axis=0)
            v00 = v000 < v001
            v010 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v010[-i0] = close[-i0]
            v01 = v010[-1] - v010[-2]
            v02000 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v020000 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v020000[-i1] = close[-i1]
                v02000[-i0] = v020000[-1] - v020000[-2]
            v0200 = np.max(v02000, axis=0)
            v0201 = np.full(out.shape[0], 0.0)
            v020 = v0200 < v0201
            v0210 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v0210[-i0] = close[-i0]
            v021 = v0210[-1] - v0210[-2]
            v0220 = np.full(out.shape[0], -1.0)
            v02210 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v02210[-i0] = close[-i0]
            v0221 = v02210[-1] - v02210[-2]
            v022 = v0220 * v0221
            v02lgcl = np.empty(out.shape[0])
            v02lgcl[v020] = v021[v020]
            v02lgcl[~v020] = v022[~v020]
            v02 = v02lgcl
            v0lgcl = np.empty(out.shape[0])
            v0lgcl[v00] = v01[v00]
            v0lgcl[~v00] = v02[~v00]
            v0 = v0lgcl
            out[:] = stats.rankdata(v0)

    #  ((rank(ts_max((vwap - close), 3)) + rank(ts_min((vwap - close), 3))) * rank(delta(volume, 3)))
    class Alpha11(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, vwap_in]
        window_length = 4

        def compute(self, today, assets, out, volume, close, vwap):
            v0000 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v00000 = vwap[-i0]
                v00001 = close[-i0]
                v0000[-i0] = v00000 - v00001
            v000 = np.max(v0000, axis=0)
            v00 = stats.rankdata(v000)
            v0100 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v01000 = vwap[-i0]
                v01001 = close[-i0]
                v0100[-i0] = v01000 - v01001
            v010 = np.min(v0100, axis=0)
            v01 = stats.rankdata(v010)
            v0 = v00 + v01
            v100 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v100[-i0] = volume[-i0]
            v10 = v100[-1] - v100[-4]
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  (sign(delta(volume, 1)) * (-1 * delta(close, 1)))
    class Alpha12(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close]
        window_length = 2

        def compute(self, today, assets, out, volume, close):
            v000 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v000[-i0] = volume[-i0]
            v00 = v000[-1] - v000[-2]
            v0 = np.sign(v00)
            v10 = np.full(out.shape[0], -1.0)
            v110 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v110[-i0] = close[-i0]
            v11 = v110[-1] - v110[-2]
            v1 = v10 * v11
            out[:] = v0 * v1

    #  (-1 * rank(covariance(rank(close), rank(volume), 5)))
    class Alpha13(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close]
        window_length = 5

        def compute(self, today, assets, out, volume, close):
            v0 = np.full(out.shape[0], -1.0)
            v100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000 = close[-i0]
                v100[-i0] = stats.rankdata(v1000)
            v101 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1010 = volume[-i0]
                v101[-i0] = stats.rankdata(v1010)
            v10 = pd.DataFrame(v100).rolling(window=5).corr(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  ((-1 * rank(delta(returns, 3))) * correlation(open, volume, 10))
    class Alpha14(CustomFactor):
        inputs = [USEquityPricing.volume, Returns(window_length=2), USEquityPricing.open]
        window_length = 10

        def compute(self, today, assets, out, volume, returns, open):
            v00 = np.full(out.shape[0], -1.0)
            v0100 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v0100[-i0] = returns[-i0]
            v010 = v0100[-1] - v0100[-4]
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v10 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v10[-i0] = open[-i0]
            v11 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v11[-i0] = volume[-i0]
            v1 = pd.DataFrame(v10).rolling(window=10).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3))
    class Alpha15(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.volume]
        window_length = 3

        def compute(self, today, assets, out, high, volume):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v1000 = np.empty((3, out.shape[0]))
                for i1 in range(1, 4):
                    v10000 = high[-i1]
                    v1000[-i1] = stats.rankdata(v10000)
                v1001 = np.empty((3, out.shape[0]))
                for i1 in range(1, 4):
                    v10010 = volume[-i1]
                    v1001[-i1] = stats.rankdata(v10010)
                v100 = pd.DataFrame(v1000).rolling(window=3).cov(pd.DataFrame(v1001)).tail(1).as_matrix()[-1]
                v10[-i0] = stats.rankdata(v100)
            v1 = v10.sum(axis=0)
            out[:] = v0 * v1

    #  (-1 * rank(covariance(rank(high), rank(volume), 5)))
    class Alpha16(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.volume]
        window_length = 5

        def compute(self, today, assets, out, high, volume):
            v0 = np.full(out.shape[0], -1.0)
            v100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000 = high[-i0]
                v100[-i0] = stats.rankdata(v1000)
            v101 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1010 = volume[-i0]
                v101[-i0] = stats.rankdata(v1010)
            v10 = pd.DataFrame(v100).rolling(window=5).corr(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  (((-1 * rank(ts_rank(close, 10))) * rank(delta(delta(close, 1), 1))) * rank(ts_rank((volume / adv20), 5)))
    class Alpha17(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, adv20_in]
        window_length = 10

        def compute(self, today, assets, out, volume, close, adv20):
            v000 = np.full(out.shape[0], -1.0)
            v00100 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v00100[-i0] = close[-i0]
            v0010 = pd.DataFrame(v00100).rank().tail(1).as_matrix()[-1]
            v001 = stats.rankdata(v0010)
            v00 = v000 * v001
            v0100 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v01000 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v01000[-i1] = close[-i1]
                v0100[-i0] = v01000[-1] - v01000[-2]
            v010 = v0100[-1] - v0100[-2]
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000 = volume[-i0]
                v1001 = adv20[-i0]
                v100[-i0] = v1000 / v1001
            v10 = pd.DataFrame(v100).rank().tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  (-1 * rank(((stddev(abs((close - open)), 5) + (close - open)) + correlation(close, open, 10))))
    class Alpha18(CustomFactor):
        inputs = [USEquityPricing.close, USEquityPricing.open]
        window_length = 10

        def compute(self, today, assets, out, close, open):
            v0 = np.full(out.shape[0], -1.0)
            v10000 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000000 = close[-i0]
                v1000001 = open[-i0]
                v100000 = v1000000 - v1000001
                v10000[-i0] = np.abs(v100000)
            v1000 = np.std(v10000, axis=0)
            v10010 = close[-1]
            v10011 = open[-1]
            v1001 = v10010 - v10011
            v100 = v1000 + v1001
            v1010 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v1010[-i0] = close[-i0]
            v1011 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v1011[-i0] = open[-i0]
            v101 = pd.DataFrame(v1010).rolling(window=10).cov(pd.DataFrame(v1011)).tail(1).as_matrix()[-1]
            v10 = v100 + v101
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  ((-1 * sign(((close - delay(close, 7)) + delta(close, 7)))) * (1 + rank((1 + sum(returns, 250)))))
    class Alpha19(CustomFactor):
        inputs = [USEquityPricing.close, Returns(window_length=2)]
        window_length = 250

        def compute(self, today, assets, out, close, returns):
            v00 = np.full(out.shape[0], -1.0)
            v01000 = close[-1]
            v010010 = close[-1]
            v01001 = v010010 # delay
            v0100 = v01000 - v01001
            v01010 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v01010[-i0] = close[-i0]
            v0101 = v01010[-1] - v01010[-8]
            v010 = v0100 + v0101
            v01 = np.sign(v010)
            v0 = v00 * v01
            v10 = np.full(out.shape[0], 1.0)
            v1100 = np.full(out.shape[0], 1.0)
            v11010 = np.empty((250, out.shape[0]))
            for i0 in range(1, 251):
                v11010[-i0] = returns[-i0]
            v1101 = v11010.sum(axis=0)
            v110 = v1100 + v1101
            v11 = stats.rankdata(v110)
            v1 = v10 + v11
            out[:] = v0 * v1

    #  (((-1 * rank((open - delay(high, 1)))) * rank((open - delay(close, 1)))) * rank((open - delay(low, 1))))
    class Alpha20(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.open, USEquityPricing.low]
        window_length = 2

        def compute(self, today, assets, out, high, close, open, low):
            v000 = np.full(out.shape[0], -1.0)
            v00100 = open[-1]
            v001010 = high[-1]
            v00101 = v001010 # delay
            v0010 = v00100 - v00101
            v001 = stats.rankdata(v0010)
            v00 = v000 * v001
            v0100 = open[-1]
            v01010 = close[-1]
            v0101 = v01010 # delay
            v010 = v0100 - v0101
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v100 = open[-1]
            v1010 = low[-1]
            v101 = v1010 # delay
            v10 = v100 - v101
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  ((((sum(close, 8) / 8) + stddev(close, 8)) < (sum(close, 2) / 2)) ? (-1 * 1) : (((sum(close, 2) / 2) < ((sum(close, 8) / 8) - stddev(close, 8))) ? 1 : (((1 < (volume / adv20)) || ((volume / adv20) == 1)) ? 1 : (-1 * 1))))
    class Alpha21(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, adv20_in]
        window_length = 8

        def compute(self, today, assets, out, volume, close, adv20):
            v00000 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v00000[-i0] = close[-i0]
            v0000 = v00000.sum(axis=0)
            v0001 = np.full(out.shape[0], 8.0)
            v000 = v0000 / v0001
            v0010 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v0010[-i0] = close[-i0]
            v001 = np.std(v0010, axis=0)
            v00 = v000 + v001
            v0100 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v0100[-i0] = close[-i0]
            v010 = v0100.sum(axis=0)
            v011 = np.full(out.shape[0], 2.0)
            v01 = v010 / v011
            v0 = v00 < v01
            v10 = np.full(out.shape[0], -1.0)
            v11 = np.full(out.shape[0], 1.0)
            v1 = v10 * v11
            v20000 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v20000[-i0] = close[-i0]
            v2000 = v20000.sum(axis=0)
            v2001 = np.full(out.shape[0], 2.0)
            v200 = v2000 / v2001
            v201000 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v201000[-i0] = close[-i0]
            v20100 = v201000.sum(axis=0)
            v20101 = np.full(out.shape[0], 8.0)
            v2010 = v20100 / v20101
            v20110 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v20110[-i0] = close[-i0]
            v2011 = np.std(v20110, axis=0)
            v201 = v2010 - v2011
            v20 = v200 < v201
            v21 = np.full(out.shape[0], 1.0)
            v22000 = np.full(out.shape[0], 1.0)
            v220010 = volume[-1]
            v220011 = adv20[-1]
            v22001 = v220010 / v220011
            v2200 = v22000 < v22001
            v220100 = volume[-1]
            v220101 = adv20[-1]
            v22010 = v220100 / v220101
            v22011 = np.full(out.shape[0], 1.0)
            v2201 = v22010 == v22011
            v220 = v2200 | v2201
            v221 = np.full(out.shape[0], 1.0)
            v2220 = np.full(out.shape[0], -1.0)
            v2221 = np.full(out.shape[0], 1.0)
            v222 = v2220 * v2221
            v22lgcl = np.empty(out.shape[0])
            v22lgcl[v220] = 1
            v22lgcl[~v220] = v222[~v220]
            v22 = v22lgcl
            v2lgcl = np.empty(out.shape[0])
            v2lgcl[v20] = 1
            v2lgcl[~v20] = v22[~v20]
            v2 = v2lgcl
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  (-1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20))))
    class Alpha22(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.volume, USEquityPricing.close]
        window_length = 20

        def compute(self, today, assets, out, high, volume, close):
            v0 = np.full(out.shape[0], -1.0)
            v100 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v1000 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v1000[-i1] = high[-i1]
                v1001 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v1001[-i1] = volume[-i1]
                v100[-i0] = pd.DataFrame(v1000).rolling(window=5).cov(pd.DataFrame(v1001)).tail(1).as_matrix()[-1]
            v10 = v100[-1] - v100[-6]
            v1100 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v1100[-i0] = close[-i0]
            v110 = np.std(v1100, axis=0)
            v11 = stats.rankdata(v110)
            v1 = v10 * v11
            out[:] = v0 * v1

    #  (((sum(high, 20) / 20) < high) ? (-1 * delta(high, 2)) : 0)
    class Alpha23(CustomFactor):
        inputs = [USEquityPricing.high]
        window_length = 20

        def compute(self, today, assets, out, high):
            v0000 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v0000[-i0] = high[-i0]
            v000 = v0000.sum(axis=0)
            v001 = np.full(out.shape[0], 20.0)
            v00 = v000 / v001
            v01 = high[-1]
            v0 = v00 < v01
            v10 = np.full(out.shape[0], -1.0)
            v110 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v110[-i0] = high[-i0]
            v11 = v110[-1] - v110[-3]
            v1 = v10 * v11
            v2 = np.full(out.shape[0], 0.0)
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = 0
            out[:] = vlgcl

    #  ((((delta((sum(close, 100) / 100), 100) / delay(close, 100)) < 0.05) || ((delta((sum(close, 100) / 100), 100) / delay(close, 100)) == 0.05)) ? (-1 * (close - ts_min(close, 100))) : (-1 * delta(close, 3)))
    class Alpha24(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 101

        def compute(self, today, assets, out, close):
            v00000 = np.empty((101, out.shape[0]))
            for i0 in range(1, 102):
                v0000000 = np.empty((100, out.shape[0]))
                for i1 in range(1, 101):
                    v0000000[-i1] = close[-i1]
                v000000 = v0000000.sum(axis=0)
                v000001 = np.full(out.shape[0], 100.0)
                v00000[-i0] = v000000 / v000001
            v0000 = v00000[-1] - v00000[-101]
            v00010 = close[-1]
            v0001 = v00010 # delay
            v000 = v0000 / v0001
            v001 = np.full(out.shape[0], 0.05)
            v00 = v000 < v001
            v01000 = np.empty((101, out.shape[0]))
            for i0 in range(1, 102):
                v0100000 = np.empty((100, out.shape[0]))
                for i1 in range(1, 101):
                    v0100000[-i1] = close[-i1]
                v010000 = v0100000.sum(axis=0)
                v010001 = np.full(out.shape[0], 100.0)
                v01000[-i0] = v010000 / v010001
            v0100 = v01000[-1] - v01000[-101]
            v01010 = close[-1]
            v0101 = v01010 # delay
            v010 = v0100 / v0101
            v011 = np.full(out.shape[0], 0.05)
            v01 = v010 == v011
            v0 = v00 | v01
            v10 = np.full(out.shape[0], -1.0)
            v110 = close[-1]
            v1110 = np.empty((100, out.shape[0]))
            for i0 in range(1, 101):
                v1110[-i0] = close[-i0]
            v111 = np.min(v1110, axis=0)
            v11 = v110 - v111
            v1 = v10 * v11
            v20 = np.full(out.shape[0], -1.0)
            v210 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v210[-i0] = close[-i0]
            v21 = v210[-1] - v210[-4]
            v2 = v20 * v21
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  rank(((((-1 * returns) * adv20) * vwap) * (high - close)))
    class Alpha25(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.close, Returns(window_length=2), adv20_in, vwap_in]
        window_length = 2

        def compute(self, today, assets, out, high, close, returns, adv20, vwap):
            v00000 = np.full(out.shape[0], -1.0)
            v00001 = returns[-1]
            v0000 = v00000 * v00001
            v0001 = adv20[-1]
            v000 = v0000 * v0001
            v001 = vwap[-1]
            v00 = v000 * v001
            v010 = high[-1]
            v011 = close[-1]
            v01 = v010 - v011
            v0 = v00 * v01
            out[:] = stats.rankdata(v0)

    #  (-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3))
    class Alpha26(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.high]
        window_length = 5

        def compute(self, today, assets, out, volume, high):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v100 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v1000 = np.empty((5, out.shape[0]))
                    for i2 in range(1, 6):
                        v1000[-i2] = volume[-i2]
                    v100[-i1] = pd.DataFrame(v1000).rank().tail(1).as_matrix()[-1]
                v101 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v1010 = np.empty((5, out.shape[0]))
                    for i2 in range(1, 6):
                        v1010[-i2] = high[-i2]
                    v101[-i1] = pd.DataFrame(v1010).rank().tail(1).as_matrix()[-1]
                v10[-i0] = pd.DataFrame(v100).rolling(window=5).cov(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = np.max(v10, axis=0)
            out[:] = v0 * v1

    #  ((0.5 < rank((sum(correlation(rank(volume), rank(vwap), 6), 2) / 2.0))) ? (-1 * 1) : 1)
    class Alpha27(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.volume, vwap_in]
        window_length = 6

        def compute(self, today, assets, out, volume, vwap):
            v00 = np.full(out.shape[0], 0.5)
            v01000 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v010000 = np.empty((6, out.shape[0]))
                for i1 in range(1, 7):
                    v0100000 = volume[-i1]
                    v010000[-i1] = stats.rankdata(v0100000)
                v010001 = np.empty((6, out.shape[0]))
                for i1 in range(1, 7):
                    v0100010 = vwap[-i1]
                    v010001[-i1] = stats.rankdata(v0100010)
                v01000[-i0] = pd.DataFrame(v010000).rolling(window=6).cov(pd.DataFrame(v010001)).tail(1).as_matrix()[-1]
            v0100 = v01000.sum(axis=0)
            v0101 = np.full(out.shape[0], 2.0)
            v010 = v0100 / v0101
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v10 = np.full(out.shape[0], -1.0)
            v11 = np.full(out.shape[0], 1.0)
            v1 = v10 * v11
            v2 = np.full(out.shape[0], 1.0)
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = 1
            out[:] = vlgcl

    #  scale(((correlation(adv20, low, 5) + ((high + low) / 2)) - close))
    class Alpha28(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.close, adv20_in, USEquityPricing.low]
        window_length = 5

        def compute(self, today, assets, out, high, close, adv20, low):
            v0000 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v0000[-i0] = adv20[-i0]
            v0001 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v0001[-i0] = low[-i0]
            v000 = pd.DataFrame(v0000).rolling(window=5).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00100 = high[-1]
            v00101 = low[-1]
            v0010 = v00100 + v00101
            v0011 = np.full(out.shape[0], 2.0)
            v001 = v0010 / v0011
            v00 = v000 + v001
            v01 = close[-1]
            v0 = v00 - v01
            out[:] = v0/np.abs(v0).sum()

    #  (min(product(rank(rank(scale(log(sum(ts_min(rank(rank((-1 * rank(delta((close - 1), 5))))), 2), 1))))), 1), 5) + ts_rank(delay((-1 * returns), 6), 5))
    class Alpha29(CustomFactor):
        inputs = [USEquityPricing.close, Returns(window_length=2)]
        window_length = 7

        def compute(self, today, assets, out, close, returns):
            v00 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v000 = np.empty((1, out.shape[0]))
                for i1 in range(1, 2):
                    v00000000 = np.empty((1, out.shape[0]))
                    for i2 in range(1, 2):
                        v000000000 = np.empty((2, out.shape[0]))
                        for i3 in range(1, 3):
                            v000000000000 = np.full(out.shape[0], -1.0)
                            v00000000000100 = np.empty((6, out.shape[0]))
                            for i4 in range(1, 7):
                                v000000000001000 = close[-i4]
                                v000000000001001 = np.full(out.shape[0], 1.0)
                                v00000000000100[-i4] = v000000000001000 - v000000000001001
                            v0000000000010 = v00000000000100[-1] - v00000000000100[-6]
                            v000000000001 = stats.rankdata(v0000000000010)
                            v00000000000 = v000000000000 * v000000000001
                            v0000000000 = stats.rankdata(v00000000000)
                            v000000000[-i3] = stats.rankdata(v0000000000)
                        v00000000[-i2] = np.min(v000000000, axis=0)
                    v0000000 = v00000000.sum(axis=0)
                    v000000 = np.log(v0000000)
                    v00000 = v000000/np.abs(v000000).sum()
                    v0000 = stats.rankdata(v00000)
                    v000[-i1] = stats.rankdata(v0000)
                v00[-i0] = np.prod(v000, axis=0)
            v0 = np.min(v00, axis=0)
            v10 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000 = np.full(out.shape[0], -1.0)
                v1001 = returns[-1]
                v100 = v1000 * v1001
                v10[-i0] = v100 # delay
            v1 = pd.DataFrame(v10).rank().tail(1).as_matrix()[-1]
            out[:] = v0 + v1

    #  (((1.0 - rank(((sign((close - delay(close, 1))) + sign((delay(close, 1) - delay(close, 2)))) + sign((delay(close, 2) - delay(close, 3)))))) * sum(volume, 5)) / sum(volume, 20))
    class Alpha30(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close]
        window_length = 20

        def compute(self, today, assets, out, volume, close):
            v000 = np.full(out.shape[0], 1.0)
            v00100000 = close[-1]
            v001000010 = close[-1]
            v00100001 = v001000010 # delay
            v0010000 = v00100000 - v00100001
            v001000 = np.sign(v0010000)
            v001001000 = close[-1]
            v00100100 = v001001000 # delay
            v001001010 = close[-1]
            v00100101 = v001001010 # delay
            v0010010 = v00100100 - v00100101
            v001001 = np.sign(v0010010)
            v00100 = v001000 + v001001
            v00101000 = close[-1]
            v0010100 = v00101000 # delay
            v00101010 = close[-1]
            v0010101 = v00101010 # delay
            v001010 = v0010100 - v0010101
            v00101 = np.sign(v001010)
            v0010 = v00100 + v00101
            v001 = stats.rankdata(v0010)
            v00 = v000 - v001
            v010 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v010[-i0] = volume[-i0]
            v01 = v010.sum(axis=0)
            v0 = v00 * v01
            v10 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v10[-i0] = volume[-i0]
            v1 = v10.sum(axis=0)
            out[:] = v0 / v1

    #  ((rank(rank(rank(decay_linear((-1 * rank(rank(delta(close, 10)))), 10)))) + rank((-1 * delta(close, 3)))) + sign(scale(correlation(adv20, low, 12))))
    class Alpha31(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.close, adv20_in, USEquityPricing.low]
        window_length = 12

        def compute(self, today, assets, out, close, adv20, low):
            v000000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v0000000 = np.full(out.shape[0], -1.0)
                v0000001000 = np.empty((11, out.shape[0]))
                for i1 in range(1, 12):
                    v0000001000[-i1] = close[-i1]
                v000000100 = v0000001000[-1] - v0000001000[-11]
                v00000010 = stats.rankdata(v000000100)
                v0000001 = stats.rankdata(v00000010)
                v000000[-i0] = v0000000 * v0000001
            v00000 = (v000000 * (np.arange(1.0, 11, 1.0)/55)[:, np.newaxis]).sum(axis=0) # decay_linear
            v0000 = stats.rankdata(v00000)
            v000 = stats.rankdata(v0000)
            v00 = stats.rankdata(v000)
            v0100 = np.full(out.shape[0], -1.0)
            v01010 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v01010[-i0] = close[-i0]
            v0101 = v01010[-1] - v01010[-4]
            v010 = v0100 * v0101
            v01 = stats.rankdata(v010)
            v0 = v00 + v01
            v1000 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v1000[-i0] = adv20[-i0]
            v1001 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v1001[-i0] = low[-i0]
            v100 = pd.DataFrame(v1000).rolling(window=12).cov(pd.DataFrame(v1001)).tail(1).as_matrix()[-1]
            v10 = v100/np.abs(v100).sum()
            v1 = np.sign(v10)
            out[:] = v0 + v1

    #  (scale(((sum(close, 7) / 7) - close)) + (20 * scale(correlation(vwap, delay(close, 5), 230))))
    class Alpha32(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.close, vwap_in]
        window_length = 230

        def compute(self, today, assets, out, close, vwap):
            v00000 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v00000[-i0] = close[-i0]
            v0000 = v00000.sum(axis=0)
            v0001 = np.full(out.shape[0], 7.0)
            v000 = v0000 / v0001
            v001 = close[-1]
            v00 = v000 - v001
            v0 = v00/np.abs(v00).sum()
            v10 = np.full(out.shape[0], 20.0)
            v1100 = np.empty((230, out.shape[0]))
            for i0 in range(1, 231):
                v1100[-i0] = vwap[-i0]
            v1101 = np.empty((230, out.shape[0]))
            for i0 in range(1, 231):
                v11010 = close[-1]
                v1101[-i0] = v11010 # delay
            v110 = pd.DataFrame(v1100).rolling(window=230).cov(pd.DataFrame(v1101)).tail(1).as_matrix()[-1]
            v11 = v110/np.abs(v110).sum()
            v1 = v10 * v11
            out[:] = v0 + v1

    #  rank((-1 * ((1 - (open / close))^1)))
    class Alpha33(CustomFactor):
        inputs = [USEquityPricing.close, USEquityPricing.open]
        window_length = 2

        def compute(self, today, assets, out, close, open):
            v00 = np.full(out.shape[0], -1.0)
            v0100 = np.full(out.shape[0], 1.0)
            v01010 = open[-1]
            v01011 = close[-1]
            v0101 = v01010 / v01011
            v010 = v0100 - v0101
            v011 = np.full(out.shape[0], 1.0)
            v01 = np.power(v010, v011)
            v0 = v00 * v01
            out[:] = stats.rankdata(v0)

    #  rank(((1 - rank((stddev(returns, 2) / stddev(returns, 5)))) + (1 - rank(delta(close, 1)))))
    class Alpha34(CustomFactor):
        inputs = [USEquityPricing.close, Returns(window_length=2)]
        window_length = 5

        def compute(self, today, assets, out, close, returns):
            v000 = np.full(out.shape[0], 1.0)
            v001000 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v001000[-i0] = returns[-i0]
            v00100 = np.std(v001000, axis=0)
            v001010 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v001010[-i0] = returns[-i0]
            v00101 = np.std(v001010, axis=0)
            v0010 = v00100 / v00101
            v001 = stats.rankdata(v0010)
            v00 = v000 - v001
            v010 = np.full(out.shape[0], 1.0)
            v01100 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v01100[-i0] = close[-i0]
            v0110 = v01100[-1] - v01100[-2]
            v011 = stats.rankdata(v0110)
            v01 = v010 - v011
            v0 = v00 + v01
            out[:] = stats.rankdata(v0)

    #  ((Ts_Rank(volume, 32) * (1 - Ts_Rank(((close + high) - low), 16))) * (1 - Ts_Rank(returns, 32)))
    class Alpha35(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close, USEquityPricing.high, Returns(window_length=2), USEquityPricing.low]
        window_length = 32

        def compute(self, today, assets, out, volume, close, high, returns, low):
            v000 = np.empty((32, out.shape[0]))
            for i0 in range(1, 33):
                v000[-i0] = volume[-i0]
            v00 = pd.DataFrame(v000).rank().tail(1).as_matrix()[-1]
            v010 = np.full(out.shape[0], 1.0)
            v0110 = np.empty((16, out.shape[0]))
            for i0 in range(1, 17):
                v011000 = close[-i0]
                v011001 = high[-i0]
                v01100 = v011000 + v011001
                v01101 = low[-i0]
                v0110[-i0] = v01100 - v01101
            v011 = pd.DataFrame(v0110).rank().tail(1).as_matrix()[-1]
            v01 = v010 - v011
            v0 = v00 * v01
            v10 = np.full(out.shape[0], 1.0)
            v110 = np.empty((32, out.shape[0]))
            for i0 in range(1, 33):
                v110[-i0] = returns[-i0]
            v11 = pd.DataFrame(v110).rank().tail(1).as_matrix()[-1]
            v1 = v10 - v11
            out[:] = v0 * v1

    #  (((((2.21 * rank(correlation((close - open), delay(volume, 1), 15))) + (0.7 * rank((open - close)))) + (0.73 * rank(Ts_Rank(delay((-1 * returns), 6), 5)))) + rank(abs(correlation(vwap, adv20, 6)))) + (0.6 * rank((((sum(close, 200) / 200) - open) * (close - open)))))
    class Alpha36(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [adv20_in, vwap_in, USEquityPricing.volume, Returns(window_length=2), USEquityPricing.close, USEquityPricing.open]
        window_length = 200

        def compute(self, today, assets, out, adv20, vwap, volume, returns, close, open):
            v00000 = np.full(out.shape[0], 2.21)
            v0000100 = np.empty((15, out.shape[0]))
            for i0 in range(1, 16):
                v00001000 = close[-i0]
                v00001001 = open[-i0]
                v0000100[-i0] = v00001000 - v00001001
            v0000101 = np.empty((15, out.shape[0]))
            for i0 in range(1, 16):
                v00001010 = volume[-1]
                v0000101[-i0] = v00001010 # delay
            v000010 = pd.DataFrame(v0000100).rolling(window=15).cov(pd.DataFrame(v0000101)).tail(1).as_matrix()[-1]
            v00001 = stats.rankdata(v000010)
            v0000 = v00000 * v00001
            v00010 = np.full(out.shape[0], 0.7)
            v0001100 = open[-1]
            v0001101 = close[-1]
            v000110 = v0001100 - v0001101
            v00011 = stats.rankdata(v000110)
            v0001 = v00010 * v00011
            v000 = v0000 + v0001
            v0010 = np.full(out.shape[0], 0.73)
            v001100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v00110000 = np.full(out.shape[0], -1.0)
                v00110001 = returns[-1]
                v0011000 = v00110000 * v00110001
                v001100[-i0] = v0011000 # delay
            v00110 = pd.DataFrame(v001100).rank().tail(1).as_matrix()[-1]
            v0011 = stats.rankdata(v00110)
            v001 = v0010 * v0011
            v00 = v000 + v001
            v01000 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v01000[-i0] = vwap[-i0]
            v01001 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v01001[-i0] = adv20[-i0]
            v0100 = pd.DataFrame(v01000).rolling(window=6).cov(pd.DataFrame(v01001)).tail(1).as_matrix()[-1]
            v010 = np.abs(v0100)
            v01 = stats.rankdata(v010)
            v0 = v00 + v01
            v10 = np.full(out.shape[0], 0.6)
            v1100000 = np.empty((200, out.shape[0]))
            for i0 in range(1, 201):
                v1100000[-i0] = close[-i0]
            v110000 = v1100000.sum(axis=0)
            v110001 = np.full(out.shape[0], 200.0)
            v11000 = v110000 / v110001
            v11001 = open[-1]
            v1100 = v11000 - v11001
            v11010 = close[-1]
            v11011 = open[-1]
            v1101 = v11010 - v11011
            v110 = v1100 * v1101
            v11 = stats.rankdata(v110)
            v1 = v10 * v11
            out[:] = v0 + v1

    #  (rank(correlation(delay((open - close), 1), close, 200)) + rank((open - close)))
    class Alpha37(CustomFactor):
        inputs = [USEquityPricing.close, USEquityPricing.open]
        window_length = 200

        def compute(self, today, assets, out, close, open):
            v000 = np.empty((200, out.shape[0]))
            for i0 in range(1, 201):
                v00000 = open[-1]
                v00001 = close[-1]
                v0000 = v00000 - v00001
                v000[-i0] = v0000 # delay
            v001 = np.empty((200, out.shape[0]))
            for i0 in range(1, 201):
                v001[-i0] = close[-i0]
            v00 = pd.DataFrame(v000).rolling(window=200).cov(pd.DataFrame(v001)).tail(1).as_matrix()[-1]
            v0 = stats.rankdata(v00)
            v100 = open[-1]
            v101 = close[-1]
            v10 = v100 - v101
            v1 = stats.rankdata(v10)
            out[:] = v0 + v1

    #  ((-1 * rank(Ts_Rank(close, 10))) * rank((close / open)))
    class Alpha38(CustomFactor):
        inputs = [USEquityPricing.close, USEquityPricing.open]
        window_length = 10

        def compute(self, today, assets, out, close, open):
            v00 = np.full(out.shape[0], -1.0)
            v0100 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v0100[-i0] = close[-i0]
            v010 = pd.DataFrame(v0100).rank().tail(1).as_matrix()[-1]
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v100 = close[-1]
            v101 = open[-1]
            v10 = v100 / v101
            v1 = stats.rankdata(v10)
            out[:] = v0 * v1

    #  ((-1 * rank((delta(close, 7) * (1 - rank(decay_linear((volume / adv20), 9)))))) * (1 + rank(sum(returns, 250))))
    class Alpha39(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, Returns(window_length=2), adv20_in]
        window_length = 250

        def compute(self, today, assets, out, volume, close, returns, adv20):
            v00 = np.full(out.shape[0], -1.0)
            v01000 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v01000[-i0] = close[-i0]
            v0100 = v01000[-1] - v01000[-8]
            v01010 = np.full(out.shape[0], 1.0)
            v0101100 = np.empty((9, out.shape[0]))
            for i0 in range(1, 10):
                v01011000 = volume[-i0]
                v01011001 = adv20[-i0]
                v0101100[-i0] = v01011000 / v01011001
            v010110 = (v0101100 * (np.arange(1.0, 10, 1.0)/45)[:, np.newaxis]).sum(axis=0) # decay_linear
            v01011 = stats.rankdata(v010110)
            v0101 = v01010 - v01011
            v010 = v0100 * v0101
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v10 = np.full(out.shape[0], 1.0)
            v1100 = np.empty((250, out.shape[0]))
            for i0 in range(1, 251):
                v1100[-i0] = returns[-i0]
            v110 = v1100.sum(axis=0)
            v11 = stats.rankdata(v110)
            v1 = v10 + v11
            out[:] = v0 * v1

    #  ((-1 * rank(stddev(high, 10))) * correlation(high, volume, 10))
    class Alpha40(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.volume]
        window_length = 10

        def compute(self, today, assets, out, high, volume):
            v00 = np.full(out.shape[0], -1.0)
            v0100 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v0100[-i0] = high[-i0]
            v010 = np.std(v0100, axis=0)
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v10 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v10[-i0] = high[-i0]
            v11 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v11[-i0] = volume[-i0]
            v1 = pd.DataFrame(v10).rolling(window=10).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (((high * low)^0.5) - vwap)
    class Alpha41(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.low, vwap_in]
        window_length = 2

        def compute(self, today, assets, out, high, low, vwap):
            v000 = high[-1]
            v001 = low[-1]
            v00 = v000 * v001
            v01 = np.full(out.shape[0], 0.5)
            v0 = np.power(v00, v01)
            v1 = vwap[-1]
            out[:] = v0 - v1

    #  (rank((vwap - close)) / rank((vwap + close)))
    class Alpha42(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.close, vwap_in]
        window_length = 2

        def compute(self, today, assets, out, close, vwap):
            v000 = vwap[-1]
            v001 = close[-1]
            v00 = v000 - v001
            v0 = stats.rankdata(v00)
            v100 = vwap[-1]
            v101 = close[-1]
            v10 = v100 + v101
            v1 = stats.rankdata(v10)
            out[:] = v0 / v1

    #  (ts_rank((volume / adv20), 20) * ts_rank((-1 * delta(close, 7)), 8))
    class Alpha43(CustomFactor):
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, adv20_in]
        window_length = 20

        def compute(self, today, assets, out, volume, close, adv20):
            v00 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v000 = volume[-i0]
                v001 = adv20[-i0]
                v00[-i0] = v000 / v001
            v0 = pd.DataFrame(v00).rank().tail(1).as_matrix()[-1]
            v10 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v100 = np.full(out.shape[0], -1.0)
                v1010 = np.empty((8, out.shape[0]))
                for i1 in range(1, 9):
                    v1010[-i1] = close[-i1]
                v101 = v1010[-1] - v1010[-8]
                v10[-i0] = v100 * v101
            v1 = pd.DataFrame(v10).rank().tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * correlation(high, rank(volume), 5))
    class Alpha44(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.volume]
        window_length = 5

        def compute(self, today, assets, out, high, volume):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v10[-i0] = high[-i0]
            v11 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v110 = volume[-i0]
                v11[-i0] = stats.rankdata(v110)
            v1 = pd.DataFrame(v10).rolling(window=5).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * ((rank((sum(delay(close, 5), 20) / 20)) * correlation(close, volume, 2)) * rank(correlation(sum(close, 5), sum(close, 20), 2))))
    class Alpha45(CustomFactor):
        inputs = [USEquityPricing.volume, USEquityPricing.close]
        window_length = 20

        def compute(self, today, assets, out, volume, close):
            v0 = np.full(out.shape[0], -1.0)
            v100000 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v1000000 = close[-1]
                v100000[-i0] = v1000000 # delay
            v10000 = v100000.sum(axis=0)
            v10001 = np.full(out.shape[0], 20.0)
            v1000 = v10000 / v10001
            v100 = stats.rankdata(v1000)
            v1010 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v1010[-i0] = close[-i0]
            v1011 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v1011[-i0] = volume[-i0]
            v101 = pd.DataFrame(v1010).rolling(window=2).cov(pd.DataFrame(v1011)).tail(1).as_matrix()[-1]
            v10 = v100 * v101
            v1100 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v11000 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v11000[-i1] = close[-i1]
                v1100[-i0] = v11000.sum(axis=0)
            v1101 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v11010 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v11010[-i1] = close[-i1]
                v1101[-i0] = v11010.sum(axis=0)
            v110 = pd.DataFrame(v1100).rolling(window=2).cov(pd.DataFrame(v1101)).tail(1).as_matrix()[-1]
            v11 = stats.rankdata(v110)
            v1 = v10 * v11
            out[:] = v0 * v1

    #  ((0.25 < (((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10))) ? (-1 * 1) : (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < 0) ? 1 : ((-1 * 1) * (close - delay(close, 1)))))
    class Alpha46(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 21

        def compute(self, today, assets, out, close):
            v00 = np.full(out.shape[0], 0.25)
            v010000 = close[-1]
            v01000 = v010000 # delay
            v010010 = close[-1]
            v01001 = v010010 # delay
            v0100 = v01000 - v01001
            v0101 = np.full(out.shape[0], 10.0)
            v010 = v0100 / v0101
            v011000 = close[-1]
            v01100 = v011000 # delay
            v01101 = close[-1]
            v0110 = v01100 - v01101
            v0111 = np.full(out.shape[0], 10.0)
            v011 = v0110 / v0111
            v01 = v010 - v011
            v0 = v00 < v01
            v10 = np.full(out.shape[0], -1.0)
            v11 = np.full(out.shape[0], 1.0)
            v1 = v10 * v11
            v2000000 = close[-1]
            v200000 = v2000000 # delay
            v2000010 = close[-1]
            v200001 = v2000010 # delay
            v20000 = v200000 - v200001
            v20001 = np.full(out.shape[0], 10.0)
            v2000 = v20000 / v20001
            v2001000 = close[-1]
            v200100 = v2001000 # delay
            v200101 = close[-1]
            v20010 = v200100 - v200101
            v20011 = np.full(out.shape[0], 10.0)
            v2001 = v20010 / v20011
            v200 = v2000 - v2001
            v201 = np.full(out.shape[0], 0.0)
            v20 = v200 < v201
            v21 = np.full(out.shape[0], 1.0)
            v2200 = np.full(out.shape[0], -1.0)
            v2201 = np.full(out.shape[0], 1.0)
            v220 = v2200 * v2201
            v2210 = close[-1]
            v22110 = close[-1]
            v2211 = v22110 # delay
            v221 = v2210 - v2211
            v22 = v220 * v221
            v2lgcl = np.empty(out.shape[0])
            v2lgcl[v20] = 1
            v2lgcl[~v20] = v22[~v20]
            v2 = v2lgcl
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = v1[v0]
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  ((((rank((1 / close)) * volume) / adv20) * ((high * rank((high - close))) / (sum(high, 5) / 5))) - rank((vwap - delay(vwap, 5))))
    class Alpha47(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.volume, USEquityPricing.close, USEquityPricing.high, adv20_in, vwap_in]
        window_length = 6

        def compute(self, today, assets, out, volume, close, high, adv20, vwap):
            v000000 = np.full(out.shape[0], 1.0)
            v000001 = close[-1]
            v00000 = v000000 / v000001
            v0000 = stats.rankdata(v00000)
            v0001 = volume[-1]
            v000 = v0000 * v0001
            v001 = adv20[-1]
            v00 = v000 / v001
            v0100 = high[-1]
            v010100 = high[-1]
            v010101 = close[-1]
            v01010 = v010100 - v010101
            v0101 = stats.rankdata(v01010)
            v010 = v0100 * v0101
            v01100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v01100[-i0] = high[-i0]
            v0110 = v01100.sum(axis=0)
            v0111 = np.full(out.shape[0], 5.0)
            v011 = v0110 / v0111
            v01 = v010 / v011
            v0 = v00 * v01
            v100 = vwap[-1]
            v1010 = vwap[-1]
            v101 = v1010 # delay
            v10 = v100 - v101
            v1 = stats.rankdata(v10)
            out[:] = v0 - v1

    #  (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < (-1 * 0.1)) ? 1 : ((-1 * 1) * (close - delay(close, 1))))
    class Alpha49(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 21

        def compute(self, today, assets, out, close):
            v000000 = close[-1]
            v00000 = v000000 # delay
            v000010 = close[-1]
            v00001 = v000010 # delay
            v0000 = v00000 - v00001
            v0001 = np.full(out.shape[0], 10.0)
            v000 = v0000 / v0001
            v001000 = close[-1]
            v00100 = v001000 # delay
            v00101 = close[-1]
            v0010 = v00100 - v00101
            v0011 = np.full(out.shape[0], 10.0)
            v001 = v0010 / v0011
            v00 = v000 - v001
            v010 = np.full(out.shape[0], -1.0)
            v011 = np.full(out.shape[0], 0.1)
            v01 = v010 * v011
            v0 = v00 < v01
            v1 = np.full(out.shape[0], 1.0)
            v200 = np.full(out.shape[0], -1.0)
            v201 = np.full(out.shape[0], 1.0)
            v20 = v200 * v201
            v210 = close[-1]
            v2110 = close[-1]
            v211 = v2110 # delay
            v21 = v210 - v211
            v2 = v20 * v21
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = 1
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  (-1 * ts_max(rank(correlation(rank(volume), rank(vwap), 5)), 5))
    class Alpha50(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.volume, vwap_in]
        window_length = 5

        def compute(self, today, assets, out, volume, vwap):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v1000 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v10000 = volume[-i1]
                    v1000[-i1] = stats.rankdata(v10000)
                v1001 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v10010 = vwap[-i1]
                    v1001[-i1] = stats.rankdata(v10010)
                v100 = pd.DataFrame(v1000).rolling(window=5).cov(pd.DataFrame(v1001)).tail(1).as_matrix()[-1]
                v10[-i0] = stats.rankdata(v100)
            v1 = np.max(v10, axis=0)
            out[:] = v0 * v1

    #  (((((delay(close, 20) - delay(close, 10)) / 10) - ((delay(close, 10) - close) / 10)) < (-1 * 0.05)) ? 1 : ((-1 * 1) * (close - delay(close, 1))))
    class Alpha51(CustomFactor):
        inputs = [USEquityPricing.close]
        window_length = 21

        def compute(self, today, assets, out, close):
            v000000 = close[-1]
            v00000 = v000000 # delay
            v000010 = close[-1]
            v00001 = v000010 # delay
            v0000 = v00000 - v00001
            v0001 = np.full(out.shape[0], 10.0)
            v000 = v0000 / v0001
            v001000 = close[-1]
            v00100 = v001000 # delay
            v00101 = close[-1]
            v0010 = v00100 - v00101
            v0011 = np.full(out.shape[0], 10.0)
            v001 = v0010 / v0011
            v00 = v000 - v001
            v010 = np.full(out.shape[0], -1.0)
            v011 = np.full(out.shape[0], 0.05)
            v01 = v010 * v011
            v0 = v00 < v01
            v1 = np.full(out.shape[0], 1.0)
            v200 = np.full(out.shape[0], -1.0)
            v201 = np.full(out.shape[0], 1.0)
            v20 = v200 * v201
            v210 = close[-1]
            v2110 = close[-1]
            v211 = v2110 # delay
            v21 = v210 - v211
            v2 = v20 * v21
            vlgcl = np.empty(out.shape[0])
            vlgcl[v0] = 1
            vlgcl[~v0] = v2[~v0]
            out[:] = vlgcl

    #  ((((-1 * ts_min(low, 5)) + delay(ts_min(low, 5), 5)) * rank(((sum(returns, 240) - sum(returns, 20)) / 220))) * ts_rank(volume, 5))
    class Alpha52(CustomFactor):
        inputs = [USEquityPricing.volume, Returns(window_length=2), USEquityPricing.low]
        window_length = 240

        def compute(self, today, assets, out, volume, returns, low):
            v0000 = np.full(out.shape[0], -1.0)
            v00010 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v00010[-i0] = low[-i0]
            v0001 = np.min(v00010, axis=0)
            v000 = v0000 * v0001
            v00100 = np.empty((5, out.shape[0]))
            for i0 in range(6, 11):
                v00100[5-i0] = low[-i0]
            v0010 = np.min(v00100, axis=0)
            v001 = v0010 # delay
            v00 = v000 + v001
            v010000 = np.empty((240, out.shape[0]))
            for i0 in range(1, 241):
                v010000[-i0] = returns[-i0]
            v01000 = v010000.sum(axis=0)
            v010010 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v010010[-i0] = returns[-i0]
            v01001 = v010010.sum(axis=0)
            v0100 = v01000 - v01001
            v0101 = np.full(out.shape[0], 220.0)
            v010 = v0100 / v0101
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v10 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v10[-i0] = volume[-i0]
            v1 = pd.DataFrame(v10).rank().tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (-1 * delta((((close - low) - (high - close)) / (close - low)), 9))
    class Alpha53(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.low]
        window_length = 10

        def compute(self, today, assets, out, high, close, low):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v10000 = close[-i0]
                v10001 = low[-i0]
                v1000 = v10000 - v10001
                v10010 = high[-i0]
                v10011 = close[-i0]
                v1001 = v10010 - v10011
                v100 = v1000 - v1001
                v1010 = close[-i0]
                v1011 = low[-i0]
                v101 = v1010 - v1011
                v10[-i0] = v100 / v101
            v1 = v10[-1] - v10[-10]
            out[:] = v0 * v1

    #  ((-1 * ((low - close) * (open^5))) / ((low - high) * (close^5)))
    class Alpha54(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.open, USEquityPricing.low]
        window_length = 2

        def compute(self, today, assets, out, high, close, open, low):
            v00 = np.full(out.shape[0], -1.0)
            v0100 = low[-1]
            v0101 = close[-1]
            v010 = v0100 - v0101
            v0110 = open[-1]
            v0111 = np.full(out.shape[0], 5.0)
            v011 = np.power(v0110, v0111)
            v01 = v010 * v011
            v0 = v00 * v01
            v100 = low[-1]
            v101 = high[-1]
            v10 = v100 - v101
            v110 = close[-1]
            v111 = np.full(out.shape[0], 5.0)
            v11 = np.power(v110, v111)
            v1 = v10 * v11
            out[:] = v0 / v1

    #  (-1 * correlation(rank(((close - ts_min(low, 12)) / (ts_max(high, 12) - ts_min(low, 12)))), rank(volume), 6))
    class Alpha55(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.low, USEquityPricing.volume]
        window_length = 12

        def compute(self, today, assets, out, high, close, low, volume):
            v0 = np.full(out.shape[0], -1.0)
            v10 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v10000 = close[-i0]
                v100010 = np.empty((12, out.shape[0]))
                for i1 in range(1, 13):
                    v100010[-i1] = low[-i1]
                v10001 = np.min(v100010, axis=0)
                v1000 = v10000 - v10001
                v100100 = np.empty((12, out.shape[0]))
                for i1 in range(1, 13):
                    v100100[-i1] = high[-i1]
                v10010 = np.max(v100100, axis=0)
                v100110 = np.empty((12, out.shape[0]))
                for i1 in range(1, 13):
                    v100110[-i1] = low[-i1]
                v10011 = np.min(v100110, axis=0)
                v1001 = v10010 - v10011
                v100 = v1000 / v1001
                v10[-i0] = stats.rankdata(v100)
            v11 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v110 = volume[-i0]
                v11[-i0] = stats.rankdata(v110)
            v1 = pd.DataFrame(v10).rolling(window=6).cov(pd.DataFrame(v11)).tail(1).as_matrix()[-1]
            out[:] = v0 * v1

    #  (0 - (1 * (rank((sum(returns, 10) / sum(sum(returns, 2), 3))) * rank((returns * cap)))))
    class Alpha56(CustomFactor):
        inputs = [Returns(window_length=2)]
        window_length = 10

        def compute(self, today, assets, out, returns):
            v0 = np.full(out.shape[0], 0.0)
            v10 = np.full(out.shape[0], 1.0)
            v110000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v110000[-i0] = returns[-i0]
            v11000 = v110000.sum(axis=0)
            v110010 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v1100100 = np.empty((2, out.shape[0]))
                for i1 in range(1, 3):
                    v1100100[-i1] = returns[-i1]
                v110010[-i0] = v1100100.sum(axis=0)
            v11001 = v110010.sum(axis=0)
            v1100 = v11000 / v11001
            v110 = stats.rankdata(v1100)
            v11100 = returns[-1]
            v11101 = cap[-1]
            v1110 = v11100 * v11101
            v111 = stats.rankdata(v1110)
            v11 = v110 * v111
            v1 = v10 * v11
            out[:] = v0 - v1

    #  (0 - (1 * ((close - vwap) / decay_linear(rank(ts_argmax(close, 30)), 2))))
    class Alpha57(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.close, vwap_in]
        window_length = 30

        def compute(self, today, assets, out, close, vwap):
            v0 = np.full(out.shape[0], 0.0)
            v10 = np.full(out.shape[0], 1.0)
            v1100 = close[-1]
            v1101 = vwap[-1]
            v110 = v1100 - v1101
            v1110 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v111000 = np.empty((30, out.shape[0]))
                for i1 in range(1, 31):
                    v111000[-i1] = close[-i1]
                v11100 = np.argmax(v111000, axis=0)
                v1110[-i0] = stats.rankdata(v11100)
            v111 = (v1110 * (np.arange(1.0, 3, 1.0)/3)[:, np.newaxis]).sum(axis=0) # decay_linear
            v11 = v110 / v111
            v1 = v10 * v11
            out[:] = v0 - v1

    #  (0 - (1 * ((2 * scale(rank(((((close - low) - (high - close)) / (high - low)) * volume)))) - scale(rank(ts_argmax(close, 10))))))
    class Alpha60(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.low, USEquityPricing.volume]
        window_length = 10

        def compute(self, today, assets, out, high, close, low, volume):
            v0 = np.full(out.shape[0], 0.0)
            v10 = np.full(out.shape[0], 1.0)
            v1100 = np.full(out.shape[0], 2.0)
            v1101000000 = close[-1]
            v1101000001 = low[-1]
            v110100000 = v1101000000 - v1101000001
            v1101000010 = high[-1]
            v1101000011 = close[-1]
            v110100001 = v1101000010 - v1101000011
            v11010000 = v110100000 - v110100001
            v110100010 = high[-1]
            v110100011 = low[-1]
            v11010001 = v110100010 - v110100011
            v1101000 = v11010000 / v11010001
            v1101001 = volume[-1]
            v110100 = v1101000 * v1101001
            v11010 = stats.rankdata(v110100)
            v1101 = v11010/np.abs(v11010).sum()
            v110 = v1100 * v1101
            v111000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v111000[-i0] = close[-i0]
            v11100 = np.argmax(v111000, axis=0)
            v1110 = stats.rankdata(v11100)
            v111 = v1110/np.abs(v1110).sum()
            v11 = v110 - v111
            v1 = v10 * v11
            out[:] = v0 - v1

    #  (rank((vwap - ts_min(vwap, 16.1219))) < rank(correlation(vwap, adv180, 17.9282)))
    class Alpha61(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv180_in = AverageDollarVolume(window_length=180)
        adv180_in.window_safe = True
        inputs = [adv180_in, vwap_in]
        window_length = 17

        def compute(self, today, assets, out, adv180, vwap):
            v000 = vwap[-1]
            v0010 = np.empty((16, out.shape[0]))
            for i0 in range(1, 17):
                v0010[-i0] = vwap[-i0]
            v001 = np.min(v0010, axis=0)
            v00 = v000 - v001
            v0 = stats.rankdata(v00)
            v100 = np.empty((18, out.shape[0]))
            for i0 in range(1, 19):
                v100[-i0] = vwap[-i0]
            v101 = np.empty((18, out.shape[0]))
            for i0 in range(1, 19):
                v101[-i0] = adv180[-i0]
            v10 = pd.DataFrame(v100).rolling(window=18).cov(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = v0 < v1

    #  ((rank(correlation(vwap, sum(adv20, 22.4101), 9.91009)) < rank(((rank(open) + rank(open)) < (rank(((high + low) / 2)) + rank(high))))) * -1)
    class Alpha62(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.open, adv20_in, USEquityPricing.low, vwap_in]
        window_length = 22

        def compute(self, today, assets, out, high, open, adv20, low, vwap):
            v0000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v0000[-i0] = vwap[-i0]
            v0001 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v00010 = np.empty((22, out.shape[0]))
                for i1 in range(1, 23):
                    v00010[-i1] = adv20[-i1]
                v0001[-i0] = v00010.sum(axis=0)
            v000 = pd.DataFrame(v0000).rolling(window=10).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = stats.rankdata(v000)
            v010000 = open[-1]
            v01000 = stats.rankdata(v010000)
            v010010 = open[-1]
            v01001 = stats.rankdata(v010010)
            v0100 = v01000 + v01001
            v01010000 = high[-1]
            v01010001 = low[-1]
            v0101000 = v01010000 + v01010001
            v0101001 = np.full(out.shape[0], 2.0)
            v010100 = v0101000 / v0101001
            v01010 = stats.rankdata(v010100)
            v010110 = high[-1]
            v01011 = stats.rankdata(v010110)
            v0101 = v01010 + v01011
            v010 = v0100 < v0101
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((rank(correlation(sum(((open * 0.178404) + (low * (1 - 0.178404))), 12.7054), sum(adv120, 12.7054), 16.6208)) < rank(delta(((((high + low) / 2) * 0.178404) + (vwap * (1 - 0.178404))), 3.69741))) * -1)
    class Alpha64(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv120_in = AverageDollarVolume(window_length=120)
        adv120_in.window_safe = True
        inputs = [adv120_in, USEquityPricing.high, USEquityPricing.open, USEquityPricing.low, vwap_in]
        window_length = 16

        def compute(self, today, assets, out, adv120, high, open, low, vwap):
            v0000 = np.empty((17, out.shape[0]))
            for i0 in range(1, 18):
                v00000 = np.empty((13, out.shape[0]))
                for i1 in range(1, 14):
                    v0000000 = open[-i1]
                    v0000001 = np.full(out.shape[0], 0.178404)
                    v000000 = v0000000 * v0000001
                    v0000010 = low[-i1]
                    v00000110 = np.full(out.shape[0], 1.0)
                    v00000111 = np.full(out.shape[0], 0.178404)
                    v0000011 = v00000110 - v00000111
                    v000001 = v0000010 * v0000011
                    v00000[-i1] = v000000 + v000001
                v0000[-i0] = v00000.sum(axis=0)
            v0001 = np.empty((17, out.shape[0]))
            for i0 in range(1, 18):
                v00010 = np.empty((13, out.shape[0]))
                for i1 in range(1, 14):
                    v00010[-i1] = adv120[-i1]
                v0001[-i0] = v00010.sum(axis=0)
            v000 = pd.DataFrame(v0000).rolling(window=17).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = stats.rankdata(v000)
            v0100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v01000000 = high[-i0]
                v01000001 = low[-i0]
                v0100000 = v01000000 + v01000001
                v0100001 = np.full(out.shape[0], 2.0)
                v010000 = v0100000 / v0100001
                v010001 = np.full(out.shape[0], 0.178404)
                v01000 = v010000 * v010001
                v010010 = vwap[-i0]
                v0100110 = np.full(out.shape[0], 1.0)
                v0100111 = np.full(out.shape[0], 0.178404)
                v010011 = v0100110 - v0100111
                v01001 = v010010 * v010011
                v0100[-i0] = v01000 + v01001
            v010 = v0100[-1] - v0100[-5]
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((rank(correlation(((open * 0.00817205) + (vwap * (1 - 0.00817205))), sum(adv60, 8.6911), 6.40374)) < rank((open - ts_min(open, 13.635)))) * -1)
    class Alpha65(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv60_in = AverageDollarVolume(window_length=60)
        adv60_in.window_safe = True
        inputs = [adv60_in, USEquityPricing.open, vwap_in]
        window_length = 13

        def compute(self, today, assets, out, adv60, open, vwap):
            v0000 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v000000 = open[-i0]
                v000001 = np.full(out.shape[0], 0.00817205)
                v00000 = v000000 * v000001
                v000010 = vwap[-i0]
                v0000110 = np.full(out.shape[0], 1.0)
                v0000111 = np.full(out.shape[0], 0.00817205)
                v000011 = v0000110 - v0000111
                v00001 = v000010 * v000011
                v0000[-i0] = v00000 + v00001
            v0001 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v00010 = np.empty((9, out.shape[0]))
                for i1 in range(1, 10):
                    v00010[-i1] = adv60[-i1]
                v0001[-i0] = v00010.sum(axis=0)
            v000 = pd.DataFrame(v0000).rolling(window=6).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = stats.rankdata(v000)
            v0100 = open[-1]
            v01010 = np.empty((14, out.shape[0]))
            for i0 in range(1, 15):
                v01010[-i0] = open[-i0]
            v0101 = np.min(v01010, axis=0)
            v010 = v0100 - v0101
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((rank(decay_linear(delta(vwap, 3.51013), 7.23052)) + Ts_Rank(decay_linear(((((low * 0.96633) + (low * (1 - 0.96633))) - vwap) / (open - ((high + low) / 2))), 11.4157), 6.72611)) * -1)
    class Alpha66(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.open, USEquityPricing.low, vwap_in]
        window_length = 11

        def compute(self, today, assets, out, high, open, low, vwap):
            v0000 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v00000 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v00000[-i1] = vwap[-i1]
                v0000[-i0] = v00000[-1] - v00000[-5]
            v000 = (v0000 * (np.arange(1.0, 8, 1.0)/28)[:, np.newaxis]).sum(axis=0) # decay_linear
            v00 = stats.rankdata(v000)
            v010 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v0100 = np.empty((11, out.shape[0]))
                for i1 in range(1, 12):
                    v01000000 = low[-i1]
                    v01000001 = np.full(out.shape[0], 0.96633)
                    v0100000 = v01000000 * v01000001
                    v01000010 = low[-i1]
                    v010000110 = np.full(out.shape[0], 1.0)
                    v010000111 = np.full(out.shape[0], 0.96633)
                    v01000011 = v010000110 - v010000111
                    v0100001 = v01000010 * v01000011
                    v010000 = v0100000 + v0100001
                    v010001 = vwap[-i1]
                    v01000 = v010000 - v010001
                    v010010 = open[-i1]
                    v01001100 = high[-i1]
                    v01001101 = low[-i1]
                    v0100110 = v01001100 + v01001101
                    v0100111 = np.full(out.shape[0], 2.0)
                    v010011 = v0100110 / v0100111
                    v01001 = v010010 - v010011
                    v0100[-i1] = v01000 / v01001
                v010[-i0] = (v0100 * (np.arange(1.0, 12, 1.0)/66)[:, np.newaxis]).sum(axis=0) # decay_linear
            v01 = pd.DataFrame(v010).rank().tail(1).as_matrix()[-1]
            v0 = v00 + v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((Ts_Rank(correlation(rank(high), rank(adv15), 8.91644), 13.9333) < rank(delta(((close * 0.518371) + (low * (1 - 0.518371))), 1.06157))) * -1)
    class Alpha68(CustomFactor):
        adv15_in = AverageDollarVolume(window_length=15)
        adv15_in.window_safe = True
        inputs = [USEquityPricing.high, adv15_in, USEquityPricing.low, USEquityPricing.close]
        window_length = 13

        def compute(self, today, assets, out, high, adv15, low, close):
            v000 = np.empty((14, out.shape[0]))
            for i0 in range(1, 15):
                v0000 = np.empty((9, out.shape[0]))
                for i1 in range(1, 10):
                    v00000 = high[-i1]
                    v0000[-i1] = stats.rankdata(v00000)
                v0001 = np.empty((9, out.shape[0]))
                for i1 in range(1, 10):
                    v00010 = adv15[-i1]
                    v0001[-i1] = stats.rankdata(v00010)
                v000[-i0] = pd.DataFrame(v0000).rolling(window=9).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = pd.DataFrame(v000).rank().tail(1).as_matrix()[-1]
            v0100 = np.empty((2, out.shape[0]))
            for i0 in range(1, 3):
                v010000 = close[-i0]
                v010001 = np.full(out.shape[0], 0.518371)
                v01000 = v010000 * v010001
                v010010 = low[-i0]
                v0100110 = np.full(out.shape[0], 1.0)
                v0100111 = np.full(out.shape[0], 0.518371)
                v010011 = v0100110 - v0100111
                v01001 = v010010 * v010011
                v0100[-i0] = v01000 + v01001
            v010 = v0100[-1] - v0100[-2]
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  (rank(decay_linear(correlation(((high + low) / 2), adv40, 8.93345), 10.1519)) / rank(decay_linear(correlation(Ts_Rank(vwap, 3.72469), Ts_Rank(volume, 18.5188), 6.86671), 2.95011)))
    class Alpha72(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv40_in = AverageDollarVolume(window_length=40)
        adv40_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.volume, adv40_in, USEquityPricing.low, vwap_in]
        window_length = 18

        def compute(self, today, assets, out, high, volume, adv40, low, vwap):
            v000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v0000 = np.empty((9, out.shape[0]))
                for i1 in range(1, 10):
                    v000000 = high[-i1]
                    v000001 = low[-i1]
                    v00000 = v000000 + v000001
                    v00001 = np.full(out.shape[0], 2.0)
                    v0000[-i1] = v00000 / v00001
                v0001 = np.empty((9, out.shape[0]))
                for i1 in range(1, 10):
                    v0001[-i1] = adv40[-i1]
                v000[-i0] = pd.DataFrame(v0000).rolling(window=9).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = (v000 * (np.arange(1.0, 11, 1.0)/55)[:, np.newaxis]).sum(axis=0) # decay_linear
            v0 = stats.rankdata(v00)
            v100 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v1000 = np.empty((7, out.shape[0]))
                for i1 in range(1, 8):
                    v10000 = np.empty((4, out.shape[0]))
                    for i2 in range(1, 5):
                        v10000[-i2] = vwap[-i2]
                    v1000[-i1] = pd.DataFrame(v10000).rank().tail(1).as_matrix()[-1]
                v1001 = np.empty((7, out.shape[0]))
                for i1 in range(1, 8):
                    v10010 = np.empty((19, out.shape[0]))
                    for i2 in range(1, 20):
                        v10010[-i2] = volume[-i2]
                    v1001[-i1] = pd.DataFrame(v10010).rank().tail(1).as_matrix()[-1]
                v100[-i0] = pd.DataFrame(v1000).rolling(window=7).cov(pd.DataFrame(v1001)).tail(1).as_matrix()[-1]
            v10 = (v100 * (np.arange(1.0, 4, 1.0)/6)[:, np.newaxis]).sum(axis=0) # decay_linear
            v1 = stats.rankdata(v10)
            out[:] = v0 / v1

    #  ((rank(correlation(close, sum(adv30, 37.4843), 15.1365)) < rank(correlation(rank(((high * 0.0261661) + (vwap * (1 - 0.0261661)))), rank(volume), 11.4791))) * -1)
    class Alpha74(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv30_in = AverageDollarVolume(window_length=30)
        adv30_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.close, adv30_in, vwap_in, USEquityPricing.volume]
        window_length = 37

        def compute(self, today, assets, out, high, close, adv30, vwap, volume):
            v0000 = np.empty((15, out.shape[0]))
            for i0 in range(1, 16):
                v0000[-i0] = close[-i0]
            v0001 = np.empty((15, out.shape[0]))
            for i0 in range(1, 16):
                v00010 = np.empty((37, out.shape[0]))
                for i1 in range(1, 38):
                    v00010[-i1] = adv30[-i1]
                v0001[-i0] = v00010.sum(axis=0)
            v000 = pd.DataFrame(v0000).rolling(window=15).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = stats.rankdata(v000)
            v0100 = np.empty((11, out.shape[0]))
            for i0 in range(1, 12):
                v0100000 = high[-i0]
                v0100001 = np.full(out.shape[0], 0.0261661)
                v010000 = v0100000 * v0100001
                v0100010 = vwap[-i0]
                v01000110 = np.full(out.shape[0], 1.0)
                v01000111 = np.full(out.shape[0], 0.0261661)
                v0100011 = v01000110 - v01000111
                v010001 = v0100010 * v0100011
                v01000 = v010000 + v010001
                v0100[-i0] = stats.rankdata(v01000)
            v0101 = np.empty((11, out.shape[0]))
            for i0 in range(1, 12):
                v01010 = volume[-i0]
                v0101[-i0] = stats.rankdata(v01010)
            v010 = pd.DataFrame(v0100).rolling(window=11).cov(pd.DataFrame(v0101)).tail(1).as_matrix()[-1]
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  (rank(correlation(vwap, volume, 4.24304)) < rank(correlation(rank(low), rank(adv50), 12.4413)))
    class Alpha75(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv50_in = AverageDollarVolume(window_length=50)
        adv50_in.window_safe = True
        inputs = [USEquityPricing.volume, adv50_in, USEquityPricing.low, vwap_in]
        window_length = 12

        def compute(self, today, assets, out, volume, adv50, low, vwap):
            v000 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v000[-i0] = vwap[-i0]
            v001 = np.empty((4, out.shape[0]))
            for i0 in range(1, 5):
                v001[-i0] = volume[-i0]
            v00 = pd.DataFrame(v000).rolling(window=4).cov(pd.DataFrame(v001)).tail(1).as_matrix()[-1]
            v0 = stats.rankdata(v00)
            v100 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v1000 = low[-i0]
                v100[-i0] = stats.rankdata(v1000)
            v101 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v1010 = adv50[-i0]
                v101[-i0] = stats.rankdata(v1010)
            v10 = pd.DataFrame(v100).rolling(window=12).cov(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = v0 < v1

    #  (rank(correlation(sum(((low * 0.352233) + (vwap * (1 - 0.352233))), 19.7428), sum(adv40, 19.7428), 6.83313))^rank(correlation(rank(vwap), rank(volume), 5.77492)))
    class Alpha78(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv40_in = AverageDollarVolume(window_length=40)
        adv40_in.window_safe = True
        inputs = [USEquityPricing.volume, adv40_in, USEquityPricing.low, vwap_in]
        window_length = 19

        def compute(self, today, assets, out, volume, adv40, low, vwap):
            v000 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v0000 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v000000 = low[-i1]
                    v000001 = np.full(out.shape[0], 0.352233)
                    v00000 = v000000 * v000001
                    v000010 = vwap[-i1]
                    v0000110 = np.full(out.shape[0], 1.0)
                    v0000111 = np.full(out.shape[0], 0.352233)
                    v000011 = v0000110 - v0000111
                    v00001 = v000010 * v000011
                    v0000[-i1] = v00000 + v00001
                v000[-i0] = v0000.sum(axis=0)
            v001 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v0010 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v0010[-i1] = adv40[-i1]
                v001[-i0] = v0010.sum(axis=0)
            v00 = pd.DataFrame(v000).rolling(window=7).cov(pd.DataFrame(v001)).tail(1).as_matrix()[-1]
            v0 = stats.rankdata(v00)
            v100 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v1000 = vwap[-i0]
                v100[-i0] = stats.rankdata(v1000)
            v101 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v1010 = volume[-i0]
                v101[-i0] = stats.rankdata(v1010)
            v10 = pd.DataFrame(v100).rolling(window=6).cov(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = np.power(v0, v1)

    #  ((rank(Log(product(rank((rank(correlation(vwap, sum(adv10, 49.6054), 8.47743))^4)), 14.9655))) < rank(correlation(rank(vwap), rank(volume), 5.07914))) * -1)
    class Alpha81(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv10_in = AverageDollarVolume(window_length=10)
        adv10_in.window_safe = True
        inputs = [USEquityPricing.volume, adv10_in, vwap_in]
        window_length = 49

        def compute(self, today, assets, out, volume, adv10, vwap):
            v00000 = np.empty((15, out.shape[0]))
            for i0 in range(1, 16):
                v000000000 = np.empty((8, out.shape[0]))
                for i1 in range(1, 9):
                    v000000000[-i1] = vwap[-i1]
                v000000001 = np.empty((8, out.shape[0]))
                for i1 in range(1, 9):
                    v0000000010 = np.empty((50, out.shape[0]))
                    for i2 in range(1, 51):
                        v0000000010[-i2] = adv10[-i2]
                    v000000001[-i1] = v0000000010.sum(axis=0)
                v00000000 = pd.DataFrame(v000000000).rolling(window=8).cov(pd.DataFrame(v000000001)).tail(1).as_matrix()[-1]
                v0000000 = stats.rankdata(v00000000)
                v0000001 = np.full(out.shape[0], 4.0)
                v000000 = np.power(v0000000, v0000001)
                v00000[-i0] = stats.rankdata(v000000)
            v0000 = np.prod(v00000, axis=0)
            v000 = np.log(v0000)
            v00 = stats.rankdata(v000)
            v0100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v01000 = vwap[-i0]
                v0100[-i0] = stats.rankdata(v01000)
            v0101 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v01010 = volume[-i0]
                v0101[-i0] = stats.rankdata(v01010)
            v010 = pd.DataFrame(v0100).rolling(window=5).cov(pd.DataFrame(v0101)).tail(1).as_matrix()[-1]
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((rank(delay(((high - low) / (sum(close, 5) / 5)), 2)) * rank(rank(volume))) / (((high - low) / (sum(close, 5) / 5)) / (vwap - close)))
    class Alpha83(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.low, vwap_in, USEquityPricing.volume]
        window_length = 7

        def compute(self, today, assets, out, high, close, low, vwap, volume):
            v000000 = high[-1]
            v000001 = low[-1]
            v00000 = v000000 - v000001
            v0000100 = np.empty((5, out.shape[0]))
            for i0 in range(3, 8):
                v0000100[2-i0] = close[-i0]
            v000010 = v0000100.sum(axis=0)
            v000011 = np.full(out.shape[0], 5.0)
            v00001 = v000010 / v000011
            v0000 = v00000 / v00001
            v000 = v0000 # delay
            v00 = stats.rankdata(v000)
            v0100 = volume[-1]
            v010 = stats.rankdata(v0100)
            v01 = stats.rankdata(v010)
            v0 = v00 * v01
            v1000 = high[-1]
            v1001 = low[-1]
            v100 = v1000 - v1001
            v10100 = np.empty((5, out.shape[0]))
            for i0 in range(1, 6):
                v10100[-i0] = close[-i0]
            v1010 = v10100.sum(axis=0)
            v1011 = np.full(out.shape[0], 5.0)
            v101 = v1010 / v1011
            v10 = v100 / v101
            v110 = vwap[-1]
            v111 = close[-1]
            v11 = v110 - v111
            v1 = v10 / v11
            out[:] = v0 / v1

    #  SignedPower(Ts_Rank((vwap - ts_max(vwap, 15.3217)), 20.7127), delta(close, 4.96796))
    class Alpha84(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        inputs = [USEquityPricing.close, vwap_in]
        window_length = 20

        def compute(self, today, assets, out, close, vwap):
            v00 = np.empty((21, out.shape[0]))
            for i0 in range(1, 22):
                v000 = vwap[-i0]
                v0010 = np.empty((15, out.shape[0]))
                for i1 in range(1, 16):
                    v0010[-i1] = vwap[-i1]
                v001 = np.max(v0010, axis=0)
                v00[-i0] = v000 - v001
            v0 = pd.DataFrame(v00).rank().tail(1).as_matrix()[-1]
            v10 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v10[-i0] = close[-i0]
            v1 = v10[-1] - v10[-6]
            out[:] = np.power(v0, v1)

    #  (rank(correlation(((high * 0.876703) + (close * (1 - 0.876703))), adv30, 9.61331))^rank(correlation(Ts_Rank(((high + low) / 2), 3.70596), Ts_Rank(volume, 10.1595), 7.11408)))
    class Alpha85(CustomFactor):
        adv30_in = AverageDollarVolume(window_length=30)
        adv30_in.window_safe = True
        inputs = [USEquityPricing.high, USEquityPricing.close, adv30_in, USEquityPricing.low, USEquityPricing.volume]
        window_length = 10

        def compute(self, today, assets, out, high, close, adv30, low, volume):
            v000 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v00000 = high[-i0]
                v00001 = np.full(out.shape[0], 0.876703)
                v0000 = v00000 * v00001
                v00010 = close[-i0]
                v000110 = np.full(out.shape[0], 1.0)
                v000111 = np.full(out.shape[0], 0.876703)
                v00011 = v000110 - v000111
                v0001 = v00010 * v00011
                v000[-i0] = v0000 + v0001
            v001 = np.empty((10, out.shape[0]))
            for i0 in range(1, 11):
                v001[-i0] = adv30[-i0]
            v00 = pd.DataFrame(v000).rolling(window=10).cov(pd.DataFrame(v001)).tail(1).as_matrix()[-1]
            v0 = stats.rankdata(v00)
            v100 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v1000 = np.empty((4, out.shape[0]))
                for i1 in range(1, 5):
                    v100000 = high[-i1]
                    v100001 = low[-i1]
                    v10000 = v100000 + v100001
                    v10001 = np.full(out.shape[0], 2.0)
                    v1000[-i1] = v10000 / v10001
                v100[-i0] = pd.DataFrame(v1000).rank().tail(1).as_matrix()[-1]
            v101 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v1010 = np.empty((10, out.shape[0]))
                for i1 in range(1, 11):
                    v1010[-i1] = volume[-i1]
                v101[-i0] = pd.DataFrame(v1010).rank().tail(1).as_matrix()[-1]
            v10 = pd.DataFrame(v100).rolling(window=7).cov(pd.DataFrame(v101)).tail(1).as_matrix()[-1]
            v1 = stats.rankdata(v10)
            out[:] = np.power(v0, v1)

    #  ((Ts_Rank(correlation(close, sum(adv20, 14.7444), 6.00049), 20.4195) < rank(((open + close) - (vwap + open)))) * -1)
    class Alpha86(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv20_in = AverageDollarVolume(window_length=20)
        adv20_in.window_safe = True
        inputs = [USEquityPricing.close, adv20_in, vwap_in, USEquityPricing.open]
        window_length = 20

        def compute(self, today, assets, out, close, adv20, vwap, open):
            v000 = np.empty((20, out.shape[0]))
            for i0 in range(1, 21):
                v0000 = np.empty((6, out.shape[0]))
                for i1 in range(1, 7):
                    v0000[-i1] = close[-i1]
                v0001 = np.empty((6, out.shape[0]))
                for i1 in range(1, 7):
                    v00010 = np.empty((15, out.shape[0]))
                    for i2 in range(1, 16):
                        v00010[-i2] = adv20[-i2]
                    v0001[-i1] = v00010.sum(axis=0)
                v000[-i0] = pd.DataFrame(v0000).rolling(window=6).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = pd.DataFrame(v000).rank().tail(1).as_matrix()[-1]
            v01000 = open[-1]
            v01001 = close[-1]
            v0100 = v01000 + v01001
            v01010 = vwap[-1]
            v01011 = open[-1]
            v0101 = v01010 + v01011
            v010 = v0100 - v0101
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((rank((vwap - ts_min(vwap, 11.5783)))^Ts_Rank(correlation(Ts_Rank(vwap, 19.6462), Ts_Rank(adv60, 4.02992), 18.0926), 2.70756)) * -1)
    class Alpha94(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv60_in = AverageDollarVolume(window_length=60)
        adv60_in.window_safe = True
        inputs = [adv60_in, vwap_in]
        window_length = 19

        def compute(self, today, assets, out, adv60, vwap):
            v0000 = vwap[-1]
            v00010 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v00010[-i0] = vwap[-i0]
            v0001 = np.min(v00010, axis=0)
            v000 = v0000 - v0001
            v00 = stats.rankdata(v000)
            v010 = np.empty((3, out.shape[0]))
            for i0 in range(1, 4):
                v0100 = np.empty((18, out.shape[0]))
                for i1 in range(1, 19):
                    v01000 = np.empty((20, out.shape[0]))
                    for i2 in range(1, 21):
                        v01000[-i2] = vwap[-i2]
                    v0100[-i1] = pd.DataFrame(v01000).rank().tail(1).as_matrix()[-1]
                v0101 = np.empty((18, out.shape[0]))
                for i1 in range(1, 19):
                    v01010 = np.empty((4, out.shape[0]))
                    for i2 in range(1, 5):
                        v01010[-i2] = adv60[-i2]
                    v0101[-i1] = pd.DataFrame(v01010).rank().tail(1).as_matrix()[-1]
                v010[-i0] = pd.DataFrame(v0100).rolling(window=18).cov(pd.DataFrame(v0101)).tail(1).as_matrix()[-1]
            v01 = pd.DataFrame(v010).rank().tail(1).as_matrix()[-1]
            v0 = np.power(v00, v01)
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  (rank((open - ts_min(open, 12.4105))) < Ts_Rank((rank(correlation(sum(((high + low) / 2), 19.1351), sum(adv40, 19.1351), 12.8742))^5), 11.7584))
    class Alpha95(CustomFactor):
        adv40_in = AverageDollarVolume(window_length=40)
        adv40_in.window_safe = True
        inputs = [USEquityPricing.high, adv40_in, USEquityPricing.open, USEquityPricing.low]
        window_length = 19

        def compute(self, today, assets, out, high, adv40, open, low):
            v000 = open[-1]
            v0010 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v0010[-i0] = open[-i0]
            v001 = np.min(v0010, axis=0)
            v00 = v000 - v001
            v0 = stats.rankdata(v00)
            v10 = np.empty((12, out.shape[0]))
            for i0 in range(1, 13):
                v10000 = np.empty((13, out.shape[0]))
                for i1 in range(1, 14):
                    v100000 = np.empty((19, out.shape[0]))
                    for i2 in range(1, 20):
                        v10000000 = high[-i2]
                        v10000001 = low[-i2]
                        v1000000 = v10000000 + v10000001
                        v1000001 = np.full(out.shape[0], 2.0)
                        v100000[-i2] = v1000000 / v1000001
                    v10000[-i1] = v100000.sum(axis=0)
                v10001 = np.empty((13, out.shape[0]))
                for i1 in range(1, 14):
                    v100010 = np.empty((19, out.shape[0]))
                    for i2 in range(1, 20):
                        v100010[-i2] = adv40[-i2]
                    v10001[-i1] = v100010.sum(axis=0)
                v1000 = pd.DataFrame(v10000).rolling(window=13).cov(pd.DataFrame(v10001)).tail(1).as_matrix()[-1]
                v100 = stats.rankdata(v1000)
                v101 = np.full(out.shape[0], 5.0)
                v10[-i0] = np.power(v100, v101)
            v1 = pd.DataFrame(v10).rank().tail(1).as_matrix()[-1]
            out[:] = v0 < v1

    #  (rank(decay_linear(correlation(vwap, sum(adv5, 26.4719), 4.58418), 7.18088)) - rank(decay_linear(Ts_Rank(Ts_ArgMin(correlation(rank(open), rank(adv15), 20.8187), 8.62571), 6.95668), 8.07206)))
    class Alpha98(CustomFactor):
        vwap_in = VWAP(window_length=2)
        vwap_in.window_safe = True
        adv5_in = AverageDollarVolume(window_length=5)
        adv5_in.window_safe = True
        adv15_in = AverageDollarVolume(window_length=15)
        adv15_in.window_safe = True
        inputs = [adv5_in, adv15_in, USEquityPricing.open, vwap_in]
        window_length = 26

        def compute(self, today, assets, out, adv5, adv15, open, vwap):
            v000 = np.empty((7, out.shape[0]))
            for i0 in range(1, 8):
                v0000 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v0000[-i1] = vwap[-i1]
                v0001 = np.empty((5, out.shape[0]))
                for i1 in range(1, 6):
                    v00010 = np.empty((26, out.shape[0]))
                    for i2 in range(1, 27):
                        v00010[-i2] = adv5[-i2]
                    v0001[-i1] = v00010.sum(axis=0)
                v000[-i0] = pd.DataFrame(v0000).rolling(window=5).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = (v000 * (np.arange(1.0, 8, 1.0)/28)[:, np.newaxis]).sum(axis=0) # decay_linear
            v0 = stats.rankdata(v00)
            v100 = np.empty((8, out.shape[0]))
            for i0 in range(1, 9):
                v1000 = np.empty((7, out.shape[0]))
                for i1 in range(1, 8):
                    v10000 = np.empty((9, out.shape[0]))
                    for i2 in range(1, 10):
                        v100000 = np.empty((21, out.shape[0]))
                        for i3 in range(1, 22):
                            v1000000 = open[-i3]
                            v100000[-i3] = stats.rankdata(v1000000)
                        v100001 = np.empty((21, out.shape[0]))
                        for i3 in range(1, 22):
                            v1000010 = adv15[-i3]
                            v100001[-i3] = stats.rankdata(v1000010)
                        v10000[-i2] = pd.DataFrame(v100000).rolling(window=21).cov(pd.DataFrame(v100001)).tail(1).as_matrix()[-1]
                    v1000[-i1] = np.argmin(v10000, axis=0)
                v100[-i0] = pd.DataFrame(v1000).rank().tail(1).as_matrix()[-1]
            v10 = (v100 * (np.arange(1.0, 9, 1.0)/36)[:, np.newaxis]).sum(axis=0) # decay_linear
            v1 = stats.rankdata(v10)
            out[:] = v0 - v1

    #  ((rank(correlation(sum(((high + low) / 2), 19.8975), sum(adv60, 19.8975), 8.8136)) < rank(correlation(low, volume, 6.28259))) * -1)
    class Alpha99(CustomFactor):
        adv60_in = AverageDollarVolume(window_length=60)
        adv60_in.window_safe = True
        inputs = [USEquityPricing.high, adv60_in, USEquityPricing.low, USEquityPricing.volume]
        window_length = 19

        def compute(self, today, assets, out, high, adv60, low, volume):
            v0000 = np.empty((9, out.shape[0]))
            for i0 in range(1, 10):
                v00000 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v0000000 = high[-i1]
                    v0000001 = low[-i1]
                    v000000 = v0000000 + v0000001
                    v000001 = np.full(out.shape[0], 2.0)
                    v00000[-i1] = v000000 / v000001
                v0000[-i0] = v00000.sum(axis=0)
            v0001 = np.empty((9, out.shape[0]))
            for i0 in range(1, 10):
                v00010 = np.empty((20, out.shape[0]))
                for i1 in range(1, 21):
                    v00010[-i1] = adv60[-i1]
                v0001[-i0] = v00010.sum(axis=0)
            v000 = pd.DataFrame(v0000).rolling(window=9).cov(pd.DataFrame(v0001)).tail(1).as_matrix()[-1]
            v00 = stats.rankdata(v000)
            v0100 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v0100[-i0] = low[-i0]
            v0101 = np.empty((6, out.shape[0]))
            for i0 in range(1, 7):
                v0101[-i0] = volume[-i0]
            v010 = pd.DataFrame(v0100).rolling(window=6).cov(pd.DataFrame(v0101)).tail(1).as_matrix()[-1]
            v01 = stats.rankdata(v010)
            v0 = v00 < v01
            v1 = np.full(out.shape[0], -1.0)
            out[:] = v0 * v1

    #  ((close - open) / ((high - low) + 0.001))
    class Alpha101(CustomFactor):
        inputs = [USEquityPricing.high, USEquityPricing.close, USEquityPricing.open, USEquityPricing.low]
        window_length = 2

        def compute(self, today, assets, out, high, close, open, low):
            v00 = close[-1]
            v01 = open[-1]
            v0 = v00 - v01
            v100 = high[-1]
            v101 = low[-1]
            v10 = v100 - v101
            v11 = np.full(out.shape[0], 0.001)
            v1 = v10 + v11
            out[:] = v0 / v1
        
        
        all_factors = {
        'Alpha1' : Alpha1,
        'Alpha2' : Alpha2,
        'Alpha3' : Alpha3,
        'Alpha4' : Alpha4,
        'Alpha5' : Alpha5,
        'Alpha6' : Alpha6,
        'Alpha7' : Alpha7,
        'Alpha8' : Alpha8,
        'Alpha9' : Alpha9,
        'Alpha10' : Alpha10,
        'Alpha11' : Alpha11,
        'Alpha12' : Alpha12,
        'Alpha13' : Alpha13,
        'Alpha14' : Alpha14,
        'Alpha15' : Alpha15,
        'Alpha16' : Alpha16,
        'Alpha17' : Alpha17,
        'Alpha18' : Alpha18,
        'Alpha19' : Alpha19,
        'Alpha20' : Alpha20,
        'Alpha21' : Alpha21,
        'Alpha22' : Alpha22,
        'Alpha23' : Alpha23,
        'Alpha24' : Alpha24,
        'Alpha25' : Alpha25,
        'Alpha26' : Alpha26,
        'Alpha27' : Alpha27,
        'Alpha28' : Alpha28,
        'Alpha29' : Alpha29,
        'Alpha30' : Alpha30,
        'Alpha31' : Alpha31,
        'Alpha32' : Alpha32,
        'Alpha33' : Alpha33,
        'Alpha34' : Alpha34,
        'Alpha35' : Alpha35,
        'Alpha36' : Alpha36,
        'Alpha37' : Alpha37,
        'Alpha38' : Alpha38,
        'Alpha39' : Alpha39,
        'Alpha40' : Alpha40,
        'Alpha41' : Alpha41,
        'Alpha42' : Alpha42,
        'Alpha43' : Alpha43,
        'Alpha44' : Alpha44,
        'Alpha45' : Alpha45,
        'Alpha46' : Alpha46,
        'Alpha47' : Alpha47,
        'Alpha49' : Alpha49,
        'Alpha50' : Alpha50,
        'Alpha51' : Alpha51,
        'Alpha52' : Alpha52,
        'Alpha53' : Alpha53,
        'Alpha54' : Alpha54,
        'Alpha55' : Alpha55,
        'Alpha56' : Alpha56,
        'Alpha57' : Alpha57,
        'Alpha60' : Alpha60,
        'Alpha61' : Alpha61,
        'Alpha62' : Alpha62,
        'Alpha64' : Alpha64,
        'Alpha65' : Alpha65,
        'Alpha66' : Alpha66,
        'Alpha68' : Alpha68,
        'Alpha72' : Alpha72,
        'Alpha74' : Alpha74,
        'Alpha75' : Alpha75,
        'Alpha78' : Alpha78,
        'Alpha81' : Alpha81,
        'Alpha83' : Alpha83,
        'Alpha84' : Alpha84,
        'Alpha85' : Alpha85,
        'Alpha86' : Alpha86,
        'Alpha94' : Alpha94,
        'Alpha95' : Alpha95,
        'Alpha98' : Alpha98,
        'Alpha99' : Alpha99,
        'Alpha101' : Alpha101
    }     
    
    return all_factors


