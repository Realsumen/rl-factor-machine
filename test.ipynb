{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f16224",
   "metadata": {},
   "source": [
    "### Ëøô‰∏™ notebook Áî®Êù•ËØªÂèñÊñá‰ª∂ÔºåÂπ∂ÊµãËØï‰∏Ä‰∫õÊñπÊ≥ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcb46bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ ÊâÄÊúâ Python Êñá‰ª∂ÂÜÖÂÆπÂ∑≤ÂÜôÂÖ• src.txtÔºàÂÖ± 10 ‰∏™Êñá‰ª∂Ôºâ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_all_py_files(root_dir: str) -> list:\n",
    "    \"\"\"\n",
    "    Ëé∑ÂèñÊåáÂÆöÁõÆÂΩïÂèäÂÖ∂Â≠êÁõÆÂΩï‰∏ãÁöÑÊâÄÊúâ .py Êñá‰ª∂Ë∑ØÂæÑ„ÄÇ\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Ëµ∑ÂßãÁõÆÂΩïË∑ØÂæÑ„ÄÇ\n",
    "\n",
    "    Returns:\n",
    "        list: ÂåÖÂê´ÊâÄÊúâ .py Êñá‰ª∂ÂÆåÊï¥Ë∑ØÂæÑÁöÑÂàóË°®„ÄÇ\n",
    "    \"\"\"\n",
    "    py_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.endswith(\".py\"):\n",
    "                py_files.append(os.path.join(dirpath, file))\n",
    "    return py_files\n",
    "\n",
    "def write_all_py_contents_to_output(py_files: list, output_path: str = \"src.txt\") -> None:\n",
    "    \"\"\"\n",
    "    Â∞ÜÊâÄÊúâ .py Êñá‰ª∂ÁöÑÂÜÖÂÆπÂÜôÂÖ•‰∏Ä‰∏™ÊñáÊú¨Êñá‰ª∂‰∏≠ÔºåÂπ∂ÊâìÂç∞Êñá‰ª∂Âêç‰Ωú‰∏∫ÂàÜÈöî„ÄÇ\n",
    "\n",
    "    Args:\n",
    "        py_files (list): .py Êñá‰ª∂Ë∑ØÂæÑÂàóË°®„ÄÇ\n",
    "        output_path (str): ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ„ÄÇ\n",
    "    \"\"\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        for path in py_files:\n",
    "            out_file.write(f\"{'=' * 80}\\n\")\n",
    "            out_file.write(f\"File: {path}\\n\")\n",
    "            out_file.write(f\"{'-' * 80}\\n\")\n",
    "            try:\n",
    "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    out_file.write(f.read())\n",
    "            except Exception as e:\n",
    "                out_file.write(f\"‚ö†Ô∏è Error reading {path}: {e}\\n\")\n",
    "            out_file.write(\"\\n\\n\")\n",
    "\n",
    "if True:\n",
    "    root_directory = \".\"  # ÂΩìÂâçÁõÆÂΩï\n",
    "    all_py_files = get_all_py_files(root_directory)\n",
    "    write_all_py_contents_to_output(all_py_files)\n",
    "    print(f\"üìÑ ÊâÄÊúâ Python Êñá‰ª∂ÂÜÖÂÆπÂ∑≤ÂÜôÂÖ• src.txtÔºàÂÖ± {len(all_py_files)} ‰∏™Êñá‰ª∂Ôºâ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65436b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from utility import set_random_seed\n",
    "\n",
    "def reload_components():\n",
    "    \"\"\"\n",
    "    ÈáçÊñ∞Âä†ËΩΩ‰ª•‰∏ãÊ®°ÂùóÔºå‰ª•‰æøÂú®ÂºÄÂèëËøáÁ®ã‰∏≠Âç≥Êó∂ÁîüÊïàÔºö\n",
    "      - data.load_market_data\n",
    "      - tokenizer.AlphaTokenizer\n",
    "      - combination.AlphaCombinationModel\n",
    "      - envs.AlphaGenerationEnv\n",
    "      - generator.RLAlphaGenerator\n",
    "    \"\"\"\n",
    "    import data, tokenizer, combination, alpha_generation_env, generator\n",
    "\n",
    "    importlib.reload(data)\n",
    "    importlib.reload(tokenizer)\n",
    "    importlib.reload(combination)\n",
    "    importlib.reload(alpha_generation_env)\n",
    "    importlib.reload(generator)\n",
    "\n",
    "    # ÈáçÊñ∞ÁªëÂÆöÂà∞Êú¨Âú∞ÂêçÁß∞ÔºàÂèØÈÄâÔºâ\n",
    "    from data import load_market_data\n",
    "    from tokenizer import AlphaTokenizer\n",
    "    from combination import AlphaCombinationModel\n",
    "    from alpha_generation_env import AlphaGenerationEnv\n",
    "    from generator import RLAlphaGenerator\n",
    "\n",
    "    return {\n",
    "        \"load_market_data\": load_market_data,\n",
    "        \"AlphaTokenizer\": AlphaTokenizer,\n",
    "        \"AlphaCombinationModel\": AlphaCombinationModel,\n",
    "        \"AlphaGenerationEnv\": AlphaGenerationEnv,\n",
    "        \"RLAlphaGenerator\": RLAlphaGenerator,\n",
    "    }\n",
    "\n",
    "components = reload_components()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ddfd39",
   "metadata": {},
   "source": [
    "### 1.ÊµãËØï AlphaCombinationModel._compute_alpha_from_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70fb8b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha shape: (64861,)\n",
      "alpha sample: [2971.82 2971.85 2971.83 2971.81 2971.81]\n"
     ]
    }
   ],
   "source": [
    "from combination import AlphaCombinationModel\n",
    "from data import load_market_data\n",
    "\n",
    "df = load_market_data()\n",
    "model = AlphaCombinationModel()\n",
    "model.inject_data(df, target_col='target')\n",
    "\n",
    "# Ë°®ËææÂºèÔºöclose ÁöÑ 100 ÁßíÂùáÂÄº\n",
    "expr = \"close 100 ts_mean\"\n",
    "alpha = model._compute_alpha_from_expr(expr)\n",
    "\n",
    "print(\"alpha shape:\", alpha.shape)\n",
    "print(\"alpha sample:\", alpha[~np.isnan(alpha)][:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0bc3e9",
   "metadata": {},
   "source": [
    "###  2. ÊµãËØï AlphaCombinationModel.add_alpha_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc603c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high low sub 100 ts_max\n",
      "ËØ•Âõ†Â≠êÁöÑ IC ‰∏∫Ôºö 0.028037411051210426\n",
      "ÂΩìÂâçÊ±†‰∏≠Âõ†Â≠êÊï∞Ôºö 1\n"
     ]
    }
   ],
   "source": [
    "ic = model.add_alpha_expr(\"high low sub 100 ts_max\")\n",
    "print(\"ËØ•Âõ†Â≠êÁöÑ IC ‰∏∫Ôºö\", ic)\n",
    "print(\"ÂΩìÂâçÊ±†‰∏≠Âõ†Â≠êÊï∞Ôºö\", len(model.alphas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba8fd7",
   "metadata": {},
   "source": [
    "### 3. ÊµãËØï AlphaTokenizer.encode / decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda7d163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [1, 6, 10, 33, 2]\n",
      "Decoded expr: close 5 ts_mean\n"
     ]
    }
   ],
   "source": [
    "from tokenizer import AlphaTokenizer\n",
    "\n",
    "tokenizer = AlphaTokenizer()\n",
    "\n",
    "expr = \"close 5 ts_mean\"\n",
    "ids = tokenizer.encode(expr)\n",
    "decoded = tokenizer.decode(ids)\n",
    "\n",
    "print(\"Token IDs:\", ids)\n",
    "print(\"Decoded expr:\", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1899091",
   "metadata": {},
   "source": [
    "### 4. ÊµãËØï AlphaGenerationEnv.reset / step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5018150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂàùÂßãÁä∂ÊÄÅ token IDs: [1]\n",
      "Êñ∞Áä∂ÊÄÅ: [1, 4]\n",
      "Reward: 0.0 Done: False\n"
     ]
    }
   ],
   "source": [
    "from alpha_generation_env import AlphaGenerationEnv\n",
    "from combination import AlphaCombinationModel\n",
    "from tokenizer import AlphaTokenizer\n",
    "from data import load_market_data\n",
    "\n",
    "df = load_market_data()\n",
    "combo = AlphaCombinationModel()\n",
    "combo.inject_data(df, target_col='target')\n",
    "tokenizer = AlphaTokenizer()\n",
    "env = AlphaGenerationEnv(combo, tokenizer)\n",
    "\n",
    "obs = env.reset()\n",
    "print(\"ÂàùÂßãÁä∂ÊÄÅ token IDs:\", obs)\n",
    "\n",
    "valid = env.valid_actions()\n",
    "action = valid[1]\n",
    "obs2, reward, done, info = env.step(action)\n",
    "print(\"Êñ∞Áä∂ÊÄÅ:\", obs2)\n",
    "print(\"Reward:\", reward, \"Done:\", done)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1291c",
   "metadata": {},
   "source": [
    "### 5. ÊµãËØï PolicyNetwork / ValueNetwork ËæìÂá∫Áª¥Â∫¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d90c5b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy logits shape: torch.Size([1, 50])\n",
      "Value estimate shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from generator import PolicyNetwork, ValueNetwork\n",
    "\n",
    "vocab_size = 50\n",
    "seq_len = 6\n",
    "hidden_dim = 64\n",
    "device = \"cpu\"\n",
    "\n",
    "x = torch.randint(0, vocab_size, (1, seq_len))  # batch_size=1\n",
    "policy = PolicyNetwork(vocab_size, hidden_dim).to(device)\n",
    "value = ValueNetwork(vocab_size, hidden_dim).to(device)\n",
    "\n",
    "h0_p = policy.init_hidden(1, device)\n",
    "logits, _ = policy(x, h0_p)\n",
    "print(\"Policy logits shape:\", logits.shape)  # Â∫î‰∏∫ (1, vocab_size)\n",
    "\n",
    "h0_v = value.init_hidden(1, device)\n",
    "v, _ = value(x, h0_v)\n",
    "print(\"Value estimate shape:\", v.shape)      # Â∫î‰∏∫ (1,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b7e9d",
   "metadata": {},
   "source": [
    "### 6. ÊµãËØï RLAlphaGenerator._collect_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9518107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 low 20 ts_rank neg add 0.1 div open close high neg div open sub 1 add div mul\n",
      "Sample states shape: torch.Size([32, 20])\n",
      "Sample actions shape: torch.Size([32])\n",
      "Sample rewards (returns): tensor([0.1217, 0.1217, 0.1217, 0.1217, 0.1217])\n"
     ]
    }
   ],
   "source": [
    "from generator import RLAlphaGenerator\n",
    "from alpha_generation_env import AlphaGenerationEnv\n",
    "from combination import AlphaCombinationModel\n",
    "from tokenizer import AlphaTokenizer\n",
    "from data import load_market_data\n",
    "from utility import set_random_seed\n",
    "\n",
    "# reload_components()\n",
    "\n",
    "set_random_seed(9)\n",
    "\n",
    "df = load_market_data()\n",
    "combo = AlphaCombinationModel()\n",
    "combo.inject_data(df, \"target\")\n",
    "tokenizer = AlphaTokenizer()\n",
    "env = AlphaGenerationEnv(combo, tokenizer, max_len=20)\n",
    "\n",
    "cfg = dict(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_dim=64,\n",
    "    batch_size=32,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "agent = RLAlphaGenerator(env, cfg)\n",
    "\n",
    "# TODO: ‰øÆÊ≠£ bug\n",
    "# ‰∏çËÆ≠ÁªÉÔºåÂè™ÈááÊ†∑\n",
    "s, a, logp, ret, adv = agent._collect_trajectories()\n",
    "print(\"Sample states shape:\", s.shape)\n",
    "print(\"Sample actions shape:\", a.shape)\n",
    "print(\"Sample rewards (returns):\", ret[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326d7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          1, 12],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          1, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         14,  6],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,\n",
       "          6, 16],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6,\n",
       "         16, 24],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16,\n",
       "         24,  8],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,\n",
       "          8, 22],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8,\n",
       "         22,  9],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,\n",
       "          9, 16],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9,\n",
       "         16, 19],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16,\n",
       "         19,  9],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,\n",
       "          9, 34],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9,\n",
       "         34, 11],\n",
       "        [ 0,  0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34,\n",
       "         11, 33],\n",
       "        [ 0,  0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34, 11,\n",
       "         33, 14],\n",
       "        [ 0,  0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34, 11, 33,\n",
       "         14,  6],\n",
       "        [ 0,  0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34, 11, 33, 14,\n",
       "          6,  8],\n",
       "        [ 0,  0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34, 11, 33, 14,  6,\n",
       "          8, 41],\n",
       "        [ 0,  1, 14,  6, 16, 24,  8, 22,  9, 16, 19,  9, 34, 11, 33, 14,  6,  8,\n",
       "         41, 18],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          1, 13],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
       "         13,  7],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,\n",
       "          7, 10],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7,\n",
       "         10, 16],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10,\n",
       "         16,  4],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10, 16,\n",
       "          4, 14],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10, 16,  4,\n",
       "         14,  3],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10, 16,  4, 14,\n",
       "          3,  3],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10, 16,  4, 14,  3,\n",
       "          3, 13],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13,  7, 10, 16,  4, 14,  3,  3,\n",
       "         13,  4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
